Whole k-fold eval mode
Source domain: 8, Target domain: 8, Cur_fold 0
Corpus: TOEFL
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-spiece.model HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/minghongxia/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Loading embeddings from: xlnet-base-cased
Model: DIS_Simple Avg Plus Max_Min
Encoder: XLNet
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/minghongxia/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Optimizer: adam
Optimizer: adam
**** Training Begins ****
**** Epoch 0/20 ****
Use CrossEntropyLoss
order_loss: 0.6760338544845581
order_loss: 0.5403715968132019
order_loss: 0.6551857590675354
order_loss: 0.22535313665866852
order_loss: 0.3607310354709625
order_loss: 0.7835508584976196
order_loss: 0.3670082986354828
order_loss: 0.4153726100921631
order_loss: 0.3276784121990204
order_loss: 0.39488744735717773
order_loss: 0.6618453860282898
order_loss: 0.38224905729293823
order_loss: 0.667644739151001
order_loss: 0.426797479391098
order_loss: 0.6147989630699158
15/33-(1.713)
order_loss: 0.47668251395225525
order_loss: 0.42118123173713684
order_loss: 0.2783869802951813
order_loss: 0.5968877673149109
order_loss: 0.6956281065940857
order_loss: 0.37056565284729004
order_loss: 0.30331793427467346
order_loss: 0.32700252532958984
order_loss: 0.27982020378112793
order_loss: 0.15279807150363922
order_loss: 0.13432131707668304
order_loss: 0.31559738516807556
order_loss: 0.005374252330511808
order_loss: 0.07601120322942734
order_loss: 0.06794499605894089
30/33-(0.981)
order_loss: 0.08426054567098618
order_loss: 0.0464930385351181
order_loss: 0.5903709530830383
order_loss: 0.06970612704753876
order_loss: 0.09227347373962402
order_loss: 0.04287346452474594
order_loss: 0.11792673170566559
order_loss: 0.16979975998401642
order_loss: 0.006261217407882214
order_loss: 0.014877481386065483
order_loss: 0.020422914996743202
order_loss: 0.4756743013858795
order_loss: 0.04356507584452629
order_loss: 0.005228126421570778
order_loss: 0.00012020090798614547
12/33-(0.736)
order_loss: 0.029639635235071182
order_loss: 0.0404655858874321
order_loss: 0.019501671195030212
order_loss: 0.011394254863262177
order_loss: 0.0026654598768800497
order_loss: 0.0011300032492727041
order_loss: 3.417346306378022e-06
order_loss: 0.011759842745959759
order_loss: 7.947289191179152e-07
order_loss: 8.685261718710535e-07
order_loss: 0.0001665432791924104
order_loss: 0.0003236722550354898
order_loss: 0.5558608770370483
order_loss: 1.924385514939786e-06
order_loss: 0.004510928876698017
27/33-(1.144)
order_loss: 0.02068149857223034
order_loss: 0.5350738763809204
order_loss: 0.027947844937443733

=== Evaluating Model ===
accuracy on Valid 0.3601190476190476

Best accuracy on Valid 0.3601190476190476
Total valid loss 1.0982769926389058
accuracy on Test 0.38095238095238093
Best accuracy on Test 0.38095238095238093

**** Epoch 0/20 ****
order_loss: 0.0742907002568245
order_loss: 0.09120588004589081
order_loss: 1.5602695941925049
order_loss: 1.8345078229904175
order_loss: 0.00047309097135439515
order_loss: 0.00403550872579217
order_loss: 0.0009777769446372986
order_loss: 0.007279923651367426
order_loss: 0.0010696176905184984
order_loss: 0.004579427186399698
9/33-(1.205)
order_loss: 0.022855322808027267
order_loss: 0.047108180820941925
order_loss: 0.003771196585148573
order_loss: 0.0033926337491720915
order_loss: 0.0007611684850417078
order_loss: 0.00048552328371442854
order_loss: 0.00017800432397052646
order_loss: 0.0008533356012776494
order_loss: 0.00028973992448300123
order_loss: 0.00015663418162148446
order_loss: 1.8971599274664186e-05
order_loss: 1.5531528333667666e-05
order_loss: 0.0004892956931143999
order_loss: 0.0002047568850684911
order_loss: 0.2517755925655365
24/33-(1.354)
order_loss: 0.00030402225092984736
order_loss: 0.00045332039007917047
order_loss: 0.00011222773173358291
order_loss: 0.0009376858361065388
order_loss: 6.6757424974639434e-06
order_loss: 0.00010986937559209764
order_loss: 1.221896354763885e-06
order_loss: 0.0010622080881148577
order_loss: 0.0001929971040226519
order_loss: 0.0003134882135782391
order_loss: 0.0005984308663755655
order_loss: 0.0045392755419015884
order_loss: 0.00024202266649808735
order_loss: 0.004363375715911388
order_loss: 0.0049328855238854885
6/33-(0.826)
order_loss: 0.0026006160769611597
order_loss: 0.0003182059735991061
order_loss: 0.0035172493662685156
order_loss: 0.0006789431790821254
order_loss: 0.006168414372950792
order_loss: 0.0011101611889898777
order_loss: 0.001351540326140821
order_loss: 0.00012952927500009537
order_loss: 0.0035232536029070616
order_loss: 0.00019054781296290457
order_loss: 2.3841860752327193e-07
order_loss: 0.00032882418599911034
order_loss: 0.4538303315639496
order_loss: 0.0038286333438009024
order_loss: 0.000360911653842777
21/33-(0.949)
order_loss: 0.0008060007239691913
order_loss: 0.0026490194723010063
order_loss: 0.001963577466085553
order_loss: 0.00042375962948426604
order_loss: 0.00017552437202539295

=== Evaluating Model ===
accuracy on Valid 0.29464285714285715

Total valid loss 1.3523789615858168
accuracy on Test 0.27380952380952384
Best accuracy on Test 0.38095238095238093

**** Epoch 1/20 ****
order_loss: 1.0629127025604248
order_loss: 5.821667946293019e-05
order_loss: 3.7165009416639805e-05
order_loss: 7.74860836827429e-07
order_loss: 1.2469632565625943e-05
order_loss: 0.0012343856506049633
order_loss: 0.0003612628788687289
order_loss: 0.00020831992151215672
3/33-(0.846)
order_loss: 0.0001695145183475688
order_loss: 0.0021894853562116623
order_loss: 0.011137362569570541
order_loss: 1.272737741470337
order_loss: 1.9868217293605994e-07
order_loss: 2.662472616066225e-05
order_loss: 0.0010946474503725767
order_loss: 1.2576705557876267e-05
order_loss: 3.8303227483993396e-05
order_loss: 0.0003137340536341071
order_loss: 0.0006197702023200691
order_loss: 0.27090001106262207
order_loss: 3.4892524126917124e-05
order_loss: 4.777147842105478e-05
order_loss: 0.00010686743189580739
18/33-(0.974)
order_loss: 2.156792106688954e-05
order_loss: 3.0486966352327727e-05
order_loss: 0.00027950466028414667
order_loss: 0.0004138210497330874
order_loss: 7.67315796110779e-05
order_loss: 8.638288272777572e-05
order_loss: 0.014100001193583012
order_loss: 2.2307569452095777e-05
order_loss: 0.00020333874272182584
order_loss: 3.5267556086182594e-05
order_loss: 2.1593121346086264e-05
order_loss: 8.968282054411247e-05
order_loss: 0.024211345240473747
order_loss: 0.0005863219266757369
order_loss: 1.2231184882693924e-05
0/33-(0.543)
order_loss: 0.00027272984152659774
order_loss: 2.1994639610056765e-05
order_loss: 4.569711563817691e-06
order_loss: 0.00031571995350532234
order_loss: 0.0001493582531111315
order_loss: 8.613608952146024e-05
order_loss: 2.0861680241068825e-06
order_loss: 0.0004172930202912539
order_loss: 0.0002597605634946376
order_loss: 0.000162336858920753
order_loss: 5.1353628805372864e-05
order_loss: 5.6912816944532096e-05
order_loss: 3.0951232474762946e-05
order_loss: 0.00023706778301857412
order_loss: 7.232908683363348e-05
15/33-(0.513)
order_loss: 0.0003719880187418312
order_loss: 4.384108251542784e-05
order_loss: 0.0004448490508366376
order_loss: 0.00026651061489246786
order_loss: 0.4437001943588257
order_loss: 0.00020333137945272028
order_loss: 0.00029332618578337133
order_loss: 0.00020170949574094266
order_loss: 0.0033465013839304447

=== Evaluating Model ===
accuracy on Valid 0.5863095238095238

Best accuracy on Valid 0.5863095238095238
Total valid loss 0.7882244104430789
accuracy on Test 0.5833333333333334
Best accuracy on Test 0.5833333333333334

**** Epoch 2/20 ****
order_loss: 0.0008845303091220558
order_loss: 0.0016682539135217667
order_loss: 0.019351372495293617
order_loss: 5.920764579059323e-06
order_loss: 0.0014862173702567816
order_loss: 0.004838794469833374
30/33-(0.827)
order_loss: 0.02477247826755047
order_loss: 0.032508183270692825
order_loss: 7.152561920520384e-07
order_loss: 0.006267856806516647
order_loss: 0.006114177871495485
order_loss: 0.004366866312921047
order_loss: 0.0015295803314074874
order_loss: 0.0035272836685180664
order_loss: 0.001560425153002143
order_loss: 0.0009419881389476359
order_loss: 0.0018092275131493807
order_loss: 0.0010072913719341159
order_loss: 0.001026685000397265
order_loss: 3.0160856113070622e-05
order_loss: 5.235055505181663e-05
12/33-(0.891)
order_loss: 1.4563711374648847e-05
order_loss: 0.0002832148165907711
order_loss: 0.0016809037188068032
order_loss: 2.9637531042681076e-05
order_loss: 0.00011813297169283032
order_loss: 7.140693924156949e-06
order_loss: 0.0004838483582716435
order_loss: 7.373210246441886e-05
order_loss: 8.783206430962309e-05
order_loss: 2.2342363081406802e-05
order_loss: 6.318148734862916e-06
order_loss: 2.5103632651735097e-05
order_loss: 1.9292547221994027e-05
order_loss: 6.218410999281332e-05
order_loss: 9.818191756494343e-05
27/33-(0.760)
order_loss: 1.480186597291322e-06
order_loss: 1.6212910850299522e-05
order_loss: 9.242552914656699e-05
order_loss: 5.292949481372489e-06
order_loss: 6.556514904332289e-07
order_loss: 0.0010014534927904606
order_loss: 5.1409324441920035e-06
order_loss: 1.60932825110649e-06
order_loss: 1.8859207557397895e-05
order_loss: 2.2158674255479127e-05
order_loss: 3.874303331485862e-07
order_loss: 5.365972901927307e-05
order_loss: 2.0861628513557662e-07
order_loss: 1.08779559013783e-05
order_loss: 2.2053777684050146e-06
9/33-(0.609)
order_loss: 1.9689676264533773e-05
order_loss: 7.549928113803617e-07
order_loss: 3.973644311372482e-07
order_loss: 1.3292223229655065e-05
order_loss: 6.412583752535284e-05
order_loss: 2.1885509340791032e-05
order_loss: 4.017369064968079e-06
order_loss: 0.00013619204401038587
order_loss: 7.71297072788002e-06
order_loss: 1.8724718756857328e-05
order_loss: 9.13449730433058e-06
order_loss: 5.761845386587083e-06

=== Evaluating Model ===
accuracy on Valid 0.7023809523809523

Best accuracy on Valid 0.7023809523809523
Total valid loss 0.6333803903488886
accuracy on Test 0.7261904761904762
Best accuracy on Test 0.7261904761904762

**** Epoch 3/20 ****
order_loss: 2.0931698600179516e-05
order_loss: 0.00013230972399469465
order_loss: 2.9792576242471114e-05
24/33-(0.671)
order_loss: 1.1920930376163597e-07
order_loss: 7.890307642810512e-06
order_loss: 1.6659694665577263e-05
order_loss: 7.525190540036419e-06
order_loss: 7.39136739866808e-05
order_loss: 3.953785835619783e-06
order_loss: 5.1691684348043054e-05
order_loss: 2.145767439287738e-07
order_loss: 0.0002069714100798592
order_loss: 2.294783371326048e-06
order_loss: 3.6955150335415965e-06
order_loss: 6.020127329975367e-06
order_loss: 1.4841773008811288e-05
order_loss: 7.665258635825012e-06
order_loss: 9.281305324293498e-07
6/33-(0.577)
order_loss: 3.7002017052145675e-05
order_loss: 2.107150612573605e-05
order_loss: 2.0862218661932275e-05
order_loss: 5.960468456578383e-07
order_loss: 1.788145368664118e-06
order_loss: 1.6647209122311324e-05
order_loss: 3.3707143302308396e-05
order_loss: 0.0011555443052202463
order_loss: 7.301622190425405e-06
order_loss: 1.1131344763271045e-05
order_loss: 0.4320662319660187
order_loss: 1.0207304512732662e-06
order_loss: 7.54992697693524e-07
order_loss: 8.738156793697271e-06
order_loss: 0.0001448234834242612
21/33-(0.517)
order_loss: 0.00010067534458357841
order_loss: 6.833377119619399e-05
order_loss: 6.342100095935166e-05
order_loss: 0.00025602072128094733
order_loss: 0.00010514006862649694
order_loss: 0.0001478224148740992
order_loss: 3.8819936889922246e-05
order_loss: 0.00036893042852170765
order_loss: 0.0008537803660146892
order_loss: 4.843158967560157e-05
order_loss: 0.0006275119376368821
order_loss: 7.877526513766497e-05
order_loss: 6.606301758438349e-05
order_loss: 1.6093276826723013e-06
order_loss: 5.066396511210769e-07
3/33-(0.523)
order_loss: 0.0007443127105943859
order_loss: 0.002173700835555792
order_loss: 9.059946933120955e-06
order_loss: 0.0008706176886335015
order_loss: 6.697029311908409e-05
order_loss: 1.5497238337047747e-06
order_loss: 4.957470446242951e-05
order_loss: 0.0003496333956718445
order_loss: 1.9967610569437966e-06
order_loss: 9.042982128448784e-05
order_loss: 0.0009294929914176464
order_loss: 0.001002680859528482
order_loss: 1.8224778614239767e-05
order_loss: 9.641284123063087e-05
order_loss: 2.3841860752327193e-07
18/33-(0.369)

=== Evaluating Model ===
accuracy on Valid 0.7023809523809523

Best accuracy on Valid 0.7023809523809523
Total valid loss 0.6012004727408999
accuracy on Test 0.7142857142857143
Best accuracy on Test 0.7261904761904762

**** Epoch 4/20 ****
order_loss: 0.00035054009640589356
order_loss: 0.00019463837088551372
order_loss: 0.0003212322772014886
order_loss: 0.00020019756630063057
order_loss: 4.529963462118758e-06
order_loss: 9.420444985153154e-05
order_loss: 0.0004227706522215158
order_loss: 4.735813126899302e-05
order_loss: 4.655328666558489e-05
order_loss: 1.4225943232304417e-05
order_loss: 0.0007273772498592734
order_loss: 0.00011476275540189818
order_loss: 2.7807038350147195e-05
order_loss: 1.118596537708072e-05
order_loss: 0.00017429908621124923
0/33-(0.523)
order_loss: 0.0001981500827241689
order_loss: 5.181433152756654e-05
order_loss: 0.0001871674321591854
order_loss: 0.0003255487827118486
order_loss: 5.6354940170422196e-05
order_loss: 2.2351787265506573e-06
order_loss: 5.650563252856955e-06
order_loss: 0.0001229737972607836
order_loss: 0.0006238179048523307
order_loss: 0.0003865764883812517
order_loss: 4.172326271145721e-07
order_loss: 2.7130015951115638e-05
order_loss: 0.008086211048066616
order_loss: 1.7881427538668504e-06
order_loss: 4.6368098992388695e-05
15/33-(0.462)
order_loss: 0.00011616964911809191
order_loss: 1.7881409348774469e-06
order_loss: 1.8000657746597426e-06
order_loss: 1.5765805073897354e-05
order_loss: 1.5361383702838793e-05
order_loss: 7.679670670768246e-05
order_loss: 1.8428563635097817e-05
order_loss: 4.7298555728048086e-05
order_loss: 1.1920931797249068e-07
order_loss: 3.0994578992249444e-06
order_loss: 7.286726940947119e-06
order_loss: 1.2798333045793697e-05
order_loss: 1.2612625141628087e-05
order_loss: 2.40366152866045e-05
order_loss: 1.287484155909624e-05
30/33-(0.482)
order_loss: 1.4047120203031227e-05
order_loss: 2.4885014227038482e-06
order_loss: 9.095737368625123e-06
order_loss: 2.9176930183894e-05
order_loss: 1.0212350389338098e-05
order_loss: 1.2350387805781793e-05
order_loss: 1.2914358649140922e-06
order_loss: 2.009580930462107e-05
order_loss: 2.9206325962150004e-06
order_loss: 3.925407781935064e-06
order_loss: 6.055887752154376e-06
order_loss: 2.8700573238893412e-05
order_loss: 9.238724487659056e-07
order_loss: 2.7179810331290355e-06
order_loss: 9.934115041687619e-07
12/33-(0.574)
order_loss: 6.020097316650208e-06
order_loss: 1.0728851975727594e-06
order_loss: 0.00010276457760483027

=== Evaluating Model ===
accuracy on Valid 0.6994047619047619

Total valid loss 0.6384432031994774
accuracy on Test 0.7172619047619048
Best accuracy on Test 0.7261904761904762

**** Epoch 5/20 ****
order_loss: 0.036375995725393295
order_loss: 0.00012323251576162875
order_loss: 6.703422695863992e-05
order_loss: 1.4305124977909145e-06
order_loss: 2.799633875838481e-05
order_loss: 8.344653679159819e-07
order_loss: 0.00012893578968942165
order_loss: 1.2179408258816693e-05
order_loss: 5.027027509640902e-05
order_loss: 5.960466182841628e-07
order_loss: 3.2173564250115305e-05
order_loss: 6.347934231598629e-06
27/33-(0.361)
order_loss: 0.0025522296782583
order_loss: 1.7488473531557247e-05
order_loss: 1.4245611964724958e-05
order_loss: 8.69579307618551e-05
order_loss: 1.655050800764002e-05
order_loss: 3.3676733437459916e-06
order_loss: 2.3841860752327193e-07
order_loss: 6.794955879740883e-06
order_loss: 2.7001267881132662e-05
order_loss: 0.0001199230900965631
order_loss: 0.00012611459533218294
order_loss: 4.7150337195489556e-05
order_loss: 9.340484393760562e-05
order_loss: 5.203630280448124e-05
order_loss: 9.94224683381617e-06
9/33-(0.436)
order_loss: 5.960467319710006e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.883151607122272e-05
order_loss: 2.0683237380580977e-05
order_loss: 0.0009162200731225312
order_loss: 2.611994386825245e-05
order_loss: 8.524469012627378e-05
order_loss: 1.1324892739139614e-06
order_loss: 4.996532516088337e-05
order_loss: 6.658193888142705e-05
order_loss: 7.194941281341016e-05
order_loss: 0.00021376690710894763
order_loss: 3.973660568590276e-06
order_loss: 7.748608936708479e-07
order_loss: 1.1920930376163597e-07
24/33-(0.617)
order_loss: 3.973644595589576e-07
order_loss: 1.116108069254551e-05
order_loss: 0.0003731870383489877
order_loss: 0.00019081267237197608
order_loss: 6.5565143358981e-07
order_loss: 0.000291350792394951
order_loss: 2.098154800478369e-05
order_loss: 4.742431701743044e-05
order_loss: 1.4220187040336896e-05
order_loss: 2.2720392735209316e-05
order_loss: 2.9802374683640664e-06
order_loss: 3.5630881029646844e-05
order_loss: 6.914200639585033e-06
order_loss: 7.925468526082113e-05
6/33-(0.457)
order_loss: 3.1948227388056694e-06
order_loss: 8.940700695347914e-07
order_loss: 7.385400385828689e-05
order_loss: 3.7849088130315067e-06
order_loss: 1.9332066585775465e-05
order_loss: 2.5889276002999395e-05

=== Evaluating Model ===
accuracy on Valid 0.625

Total valid loss 0.7785048257736933
accuracy on Test 0.6309523809523809
Best accuracy on Test 0.7261904761904762

**** Epoch 6/20 ****
order_loss: 1.1682619515340775e-05
order_loss: 1.5497246295126388e-06
order_loss: 1.698769847280346e-05
order_loss: 1.1920931797249068e-07
order_loss: 6.127428150648484e-06
order_loss: 2.253066440971452e-06
order_loss: 0.000511359772644937
order_loss: 1.1920930376163597e-07
order_loss: 3.0593375413445756e-05
21/33-(0.610)
order_loss: 2.4066524929367006e-05
order_loss: 0.00010831031249836087
order_loss: 4.768372718899627e-07
order_loss: 1.6450912880827673e-06
order_loss: 1.3351467487154878e-06
order_loss: 8.761952813074458e-06
order_loss: 8.411153976339847e-05
order_loss: 2.32466099987505e-05
order_loss: 2.3841860752327193e-07
order_loss: 2.5769440981093794e-05
order_loss: 0.00017137803661171347
order_loss: 2.4021508579608053e-05
order_loss: 6.449430657085031e-05
3/33-(0.679)
order_loss: 1.651062302698847e-05
order_loss: 2.3841860752327193e-07
order_loss: 0.00010022520291386172
order_loss: 8.344653679159819e-07
order_loss: 2.563002908573253e-06
order_loss: 3.218658548576059e-06
order_loss: 5.761786496805144e-07
order_loss: 6.318118721537758e-06
order_loss: 1.6749105270719156e-05
order_loss: 4.1723259869286267e-07
order_loss: 1.788139627478813e-07
order_loss: 7.82537699706154e-06
order_loss: 7.3016090027522296e-06
order_loss: 1.1920930376163597e-07
order_loss: 8.940708653426555e-07
18/33-(0.454)
order_loss: 2.3559738110634498e-05
order_loss: 1.8149907191400416e-05
order_loss: 7.197295872174436e-06
order_loss: 2.296890852448996e-05
order_loss: 1.1920948281840538e-06
order_loss: 3.0041639547562227e-05
order_loss: 8.37451807456091e-06
order_loss: 8.165869985532481e-06
order_loss: 1.698750384093728e-05
order_loss: 8.593552047386765e-05
order_loss: 2.0861628513557662e-07
order_loss: 2.70208329311572e-06
order_loss: 2.3314494683290832e-05
order_loss: 1.66893391906342e-06
order_loss: 2.006692284339806e-06
0/33-(0.623)
order_loss: 5.167880590306595e-05
order_loss: 6.3181314544635825e-06
order_loss: 5.710161985916784e-06
order_loss: 1.1250504030613229e-05
order_loss: 4.768372718899627e-07
order_loss: 4.002742934972048e-05
order_loss: 0.000819578708615154
order_loss: 5.145896921021631e-06

=== Evaluating Model ===
accuracy on Valid 0.6994047619047619

Total valid loss 0.7629164641811734
accuracy on Test 0.6994047619047619
Best accuracy on Test 0.7261904761904762

**** Epoch 7/20 ****
order_loss: 5.407095159171149e-05
order_loss: 0.00040227299905382097
order_loss: 0.00015152529522310942
order_loss: 1.4985162124503404e-05
order_loss: 1.915348184411414e-05
order_loss: 2.8119802664150484e-05
15/33-(0.389)
order_loss: 7.844279025448486e-05
order_loss: 0.06953340023756027
order_loss: 5.304991645971313e-05
order_loss: 9.868177585303783e-05
order_loss: 1.8835524315363728e-05
order_loss: 4.947197794535896e-06
order_loss: 5.215408691583434e-07
order_loss: 1.6093399608507752e-05
order_loss: 1.2516983360910672e-06
order_loss: 9.834900993155316e-06
order_loss: 4.038244696857873e-06
order_loss: 1.6421392501797527e-05
order_loss: 6.357831239256484e-07
order_loss: 5.471744316309923e-06
30/33-(0.273)
order_loss: 3.5762795391747204e-07
order_loss: 2.980233091420814e-07
order_loss: 3.0636933843197767e-06
order_loss: 2.4636692614876665e-06
order_loss: 2.109306115016807e-05
order_loss: 4.371009936221526e-07
order_loss: 6.842699349363102e-06
order_loss: 3.0122697353363037e-05
order_loss: 0.00016628454613965005
order_loss: 1.9809192963293754e-05
order_loss: 8.225502824643627e-06
order_loss: 7.748610073576856e-07
order_loss: 2.7815574412670685e-06
order_loss: 3.5233133530709893e-06
order_loss: 1.8335156710236333e-05
12/33-(0.401)
order_loss: 3.6955125324311666e-06
order_loss: 8.066581358434632e-06
order_loss: 5.165738343748671e-07
order_loss: 1.20202821562998e-06
order_loss: 1.5676390830776654e-05
order_loss: 1.788139627478813e-07
order_loss: 3.178915619628242e-07
order_loss: 3.1590557227900717e-06
order_loss: 1.1920941460630274e-06
order_loss: 1.664978299231734e-05
order_loss: 1.1026870652131038e-06
order_loss: 0.00012177917960798368
order_loss: 7.234891381813213e-05
order_loss: 3.1292524909076747e-06
order_loss: 0.00031113869044929743
27/33-(0.500)
order_loss: 1.2417658581398427e-06
order_loss: 1.1920930376163597e-07
order_loss: 6.914145274095063e-07
order_loss: 2.956405751319835e-06
order_loss: 1.3709161976294126e-05
order_loss: 4.112737769901287e-06
order_loss: 1.0927529956461512e-06
order_loss: 9.775177431947668e-07
order_loss: 1.4901221447871649e-06
order_loss: 2.3841860752327193e-07
order_loss: 7.15256362582295e-07

=== Evaluating Model ===
accuracy on Valid 0.6964285714285714

Total valid loss 0.6191125093471437
accuracy on Test 0.7172619047619048
Best accuracy on Test 0.7261904761904762

**** Epoch 8/20 ****
order_loss: 1.442436655452184e-06
order_loss: 7.19735407983535e-06
order_loss: 2.699246806514566e-06
9/33-(0.550)
order_loss: 2.3841912479838356e-06
order_loss: 1.0132954230357427e-05
order_loss: 3.144154561596224e-06
order_loss: 1.074100327969063e-05
order_loss: 3.084612399106845e-05
order_loss: 5.126027645019349e-06
order_loss: 7.152560215217818e-07
order_loss: 2.0176375983282924e-05
order_loss: 1.2636264727916569e-05
order_loss: 2.384194431215292e-06
order_loss: 4.768373287333816e-07
order_loss: 5.7400920923100784e-05
order_loss: 1.0550077604420949e-05
order_loss: 2.3841863594498136e-07
24/33-(0.129)
order_loss: 9.53675112214114e-07
order_loss: 1.1131307473988272e-05
order_loss: 3.1193208087643143e-06
order_loss: 2.2173016986926086e-06
order_loss: 7.152561920520384e-07
order_loss: 9.059911576514423e-07
order_loss: 7.351243311859434e-07
order_loss: 7.886005187174305e-05
order_loss: 6.715490599162877e-06
order_loss: 3.465170448180288e-05
order_loss: 4.986940439266618e-06
order_loss: 6.556513199029723e-07
order_loss: 3.2186608223128133e-06
order_loss: 2.046435156444204e-06
6/33-(0.280)
order_loss: 3.427268211453338e-07
order_loss: 2.0435882674973982e-07
order_loss: 0.0002467551385052502
order_loss: 1.609328592167003e-06
order_loss: 2.582868319223053e-07
order_loss: 3.1888598641671706e-06
order_loss: 1.1340007404214703e-05
order_loss: 3.6359019759402145e-06
order_loss: 2.98023280720372e-07
order_loss: 3.5961591038358165e-06
order_loss: 4.768399776367005e-06
order_loss: 8.940703537518857e-07
order_loss: 4.688918124884367e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.038824734678201e-06
21/33-(0.828)
order_loss: 1.1920930376163597e-07
order_loss: 2.145769940398168e-06
order_loss: 5.6448170653311536e-05
order_loss: 5.066397079644958e-07
order_loss: 1.1920930376163597e-07
order_loss: 0.00034463382326066494
order_loss: 2.722011413425207e-05
order_loss: 3.2782563152977673e-07
order_loss: 0.0007541700033470988
order_loss: 1.705750764813274e-05
order_loss: 8.234008419094607e-06
order_loss: 9.191185199597385e-06
order_loss: 1.547751708130818e-05
order_loss: 5.56310226329515e-07
order_loss: 5.409153800428612e-06
3/33-(0.400)

=== Evaluating Model ===
accuracy on Valid 0.5773809523809523

Total valid loss 0.948002720162982
accuracy on Test 0.6636904761904762
Best accuracy on Test 0.7261904761904762

**** Epoch 9/20 ****
order_loss: 8.51857039378956e-05
order_loss: 7.153180195018649e-05
order_loss: 1.0877857903324184e-06
order_loss: 5.220143066253513e-05
order_loss: 3.3529766369611025e-05
order_loss: 1.0550221304583829e-05
order_loss: 1.104405691876309e-05
order_loss: 4.649213224183768e-06
order_loss: 3.4422046155668795e-06
order_loss: 5.30484112459817e-06
order_loss: 4.390901267470326e-06
order_loss: 2.3841863594498136e-07
order_loss: 1.1920938050025143e-06
order_loss: 2.3841860752327193e-07
order_loss: 5.172399141883943e-06
18/33-(0.617)
order_loss: 2.179261173296254e-05
order_loss: 2.53319797138829e-07
order_loss: 2.6822251584235346e-06
order_loss: 1.2666001794059412e-06
order_loss: 1.5497238337047747e-06
order_loss: 1.1324978004267905e-05
order_loss: 1.8791000911733136e-05
order_loss: 3.637625923147425e-05
order_loss: 8.559321940992959e-06
order_loss: 1.3907752816066932e-07
order_loss: 5.225402674113866e-06
order_loss: 1.7136377437054762e-06
order_loss: 1.3709254744753707e-05
order_loss: 6.079677632442326e-07
order_loss: 3.397473619770608e-06
0/33-(0.475)
order_loss: 2.673702965694247e-06
order_loss: 1.654032530495897e-06
order_loss: 2.264980139443651e-06
order_loss: 1.0132799843631801e-06
order_loss: 2.960369556603837e-06
order_loss: 1.430511673561341e-07
order_loss: 2.53319797138829e-07
order_loss: 3.6955011637473945e-06
order_loss: 4.291536868095136e-07
order_loss: 3.7998208881617757e-06
order_loss: 4.023315227641433e-07
order_loss: 4.553815870167455e-06
order_loss: 1.788139485370266e-07
order_loss: 6.258490543586959e-07
order_loss: 7.4109184424742125e-06
15/33-(0.317)
order_loss: 3.8147150007716846e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.563102831729339e-07
order_loss: 5.6028775361482985e-06
order_loss: 3.610356316130492e-06
order_loss: 1.4603157296733116e-06
order_loss: 1.761372732289601e-05
order_loss: 2.145773123629624e-06
order_loss: 5.165737775314483e-07
order_loss: 5.3197418310446665e-06
order_loss: 4.8578162932244595e-06
order_loss: 6.303585541900247e-05
order_loss: 9.84487087407615e-06
order_loss: 5.483669156092219e-06
30/33-(0.184)
order_loss: 1.2546880498121027e-05
order_loss: 3.755106718017487e-06
order_loss: 0.00067797617521137

=== Evaluating Model ===
accuracy on Valid 0.7232142857142857

Best accuracy on Valid 0.7232142857142857
Total valid loss 0.7797197429906755
accuracy on Test 0.6994047619047619
Best accuracy on Test 0.7261904761904762

**** Epoch 10/20 ****
order_loss: 1.2785344551957678e-05
order_loss: 1.3673548892256804e-05
order_loss: 1.1026866104657529e-06
order_loss: 7.480437943740981e-06
order_loss: 8.377213089261204e-05
order_loss: 8.225484634749591e-06
order_loss: 9.715606211102568e-06
order_loss: 2.396135460003279e-05
order_loss: 0.00022003268531989306
order_loss: 3.159051175316563e-06
order_loss: 3.099463356193155e-06
12/33-(0.919)
order_loss: 5.563102831729339e-07
order_loss: 3.2633654427627334e-06
order_loss: 9.834860975388438e-06
order_loss: 2.9921979148639366e-05
order_loss: 9.139388907897228e-07
order_loss: 1.0028645192505792e-05
order_loss: 3.973644311372482e-07
order_loss: 8.126899774651974e-05
order_loss: 9.894572031043936e-06
order_loss: 3.859420303342631e-06
order_loss: 3.5166963243682403e-06
order_loss: 5.960464477539063e-08
order_loss: 2.3008160496829078e-05
order_loss: 5.987985787214711e-05
27/33-(0.323)
order_loss: 4.4703620005748235e-06
order_loss: 3.0795790735282935e-06
order_loss: 1.1920930376163597e-07
order_loss: 8.404291293118149e-06
order_loss: 1.6987351045827381e-06
order_loss: 5.260161742626224e-06
order_loss: 4.604494733939646e-06
order_loss: 9.536747711536009e-07
order_loss: 4.231938873999752e-06
order_loss: 4.768373287333816e-07
order_loss: 2.0861628513557662e-07
order_loss: 7.599599030072568e-07
order_loss: 1.5894606804067735e-06
order_loss: 1.4454144547926262e-06
order_loss: 3.904119239450665e-06
9/33-(0.511)
order_loss: 6.357833512993238e-07
order_loss: 4.998340955353342e-05
order_loss: 7.351276053668698e-06
order_loss: 8.881206667865627e-06
order_loss: 1.9431490727583878e-05
order_loss: 1.1920930376163597e-07
order_loss: 4.386936325317947e-06
order_loss: 1.3113034356138087e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.4795593314338475e-05
order_loss: 4.619398168870248e-06
order_loss: 1.4196261872712057e-05
order_loss: 9.328242413175758e-06
order_loss: 3.3974863526964327e-06
order_loss: 1.6391704775742255e-05
24/33-(0.293)
order_loss: 2.4437949832645245e-06
order_loss: 2.3841860752327193e-07
order_loss: 6.780102921766229e-06
order_loss: 9.894389449982555e-07
order_loss: 1.3709085351365502e-06
order_loss: 3.3974704365391517e-06

=== Evaluating Model ===
accuracy on Valid 0.5803571428571429

Total valid loss 1.1148900574161893
accuracy on Test 0.6309523809523809
Best accuracy on Test 0.7261904761904762

**** Epoch 11/20 ****
order_loss: 2.3841860752327193e-07
order_loss: 5.543288807530189e-06
order_loss: 2.682213562366087e-06
order_loss: 7.152560215217818e-07
order_loss: 5.662495368596865e-06
order_loss: 2.205374357799883e-06
order_loss: 1.2715670436591608e-06
6/33-(0.379)
order_loss: 2.3841860752327193e-07
order_loss: 5.74919831706211e-05
order_loss: 6.198903520271415e-06
order_loss: 7.808268492226489e-06
order_loss: 3.8743027630516735e-07
order_loss: 5.722105470340466e-06
order_loss: 3.1590636808687123e-06
order_loss: 2.543143409639015e-06
order_loss: 8.732155947654974e-06
order_loss: 3.894181190844392e-06
order_loss: 4.649190486816224e-06
order_loss: 3.3775978636185755e-07
order_loss: 2.3841860752327193e-07
order_loss: 3.096543514402583e-05
21/33-(0.236)
order_loss: 8.265262295026332e-06
order_loss: 1.0430823067508754e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.7865314677910646e-06
order_loss: 1.037122160596482e-06
order_loss: 4.768372718899627e-07
order_loss: 1.917323243105784e-05
order_loss: 3.5762905099545605e-06
order_loss: 7.351245017162e-07
order_loss: 8.761952813074458e-06
order_loss: 4.768372718899627e-07
order_loss: 1.929757127072662e-05
order_loss: 3.1441563805856276e-06
order_loss: 1.013279643302667e-06
order_loss: 1.0758740245364606e-05
3/33-(0.302)
order_loss: 6.198886239872081e-07
order_loss: 4.497354166232981e-05
order_loss: 3.57628505298635e-06
order_loss: 9.884570317808539e-06
order_loss: 1.3858107195119374e-06
order_loss: 5.165737775314483e-07
order_loss: 5.543285169551382e-06
order_loss: 2.533203314669663e-06
order_loss: 3.107315205852501e-05
order_loss: 4.529971647571074e-06
order_loss: 3.561389348760713e-06
order_loss: 1.788139627478813e-07
order_loss: 4.336265646998072e-06
order_loss: 5.349560979084345e-06
order_loss: 1.809033528843429e-05
18/33-(0.462)
order_loss: 8.344655384462385e-07
order_loss: 1.1175882264069514e-06
order_loss: 2.801425807774649e-06
order_loss: 6.079677632442326e-07
order_loss: 3.1590557227900717e-06
order_loss: 2.086168706227909e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.4373671951470897e-05
order_loss: 3.814704541582614e-06

=== Evaluating Model ===
accuracy on Valid 0.7202380952380952

Total valid loss 0.9456634720166525
accuracy on Test 0.6845238095238095
Best accuracy on Test 0.7261904761904762

**** Epoch 12/20 ****
order_loss: 1.5020861610537395e-05
order_loss: 1.1324897286613123e-06
order_loss: 5.116100510349497e-06
order_loss: 2.7440035410108976e-05
order_loss: 1.5497220147153712e-06
order_loss: 9.34319723455701e-06
0/33-(0.043)
order_loss: 6.139297511253972e-06
order_loss: 3.874323738273233e-06
order_loss: 4.768373287333816e-07
order_loss: 1.6519039718332351e-06
order_loss: 4.768372718899627e-07
order_loss: 3.9696969906799495e-06
order_loss: 5.137946118338732e-06
order_loss: 1.4134841421764577e-06
order_loss: 1.4106446997175226e-06
order_loss: 1.877563954622019e-05
order_loss: 6.159149847917433e-07
order_loss: 1.3113030945532955e-06
order_loss: 9.575806325301528e-05
order_loss: 9.934119589161128e-07
15/33-(0.317)
order_loss: 3.919027221854776e-06
order_loss: 5.364420303521911e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.8974230897583766e-06
order_loss: 1.8378134427621262e-06
order_loss: 9.586622581991833e-06
order_loss: 5.662444095833052e-07
order_loss: 4.808127414435148e-06
order_loss: 2.181536274292739e-06
order_loss: 0.00010881601338041946
order_loss: 3.7352347135310993e-06
order_loss: 2.3841860752327193e-07
order_loss: 5.7164113968610764e-05
order_loss: 9.199136911774985e-06
30/33-(0.736)
order_loss: 6.556517178069043e-07
order_loss: 3.4272877655894263e-06
order_loss: 3.144155016343575e-06
order_loss: 2.026560423473711e-06
order_loss: 9.139386634160473e-07
order_loss: 8.881171197572257e-06
order_loss: 1.4603153886127984e-06
order_loss: 1.0490429076526198e-06
order_loss: 7.51029892853694e-06
order_loss: 0.04851025342941284
order_loss: 4.957144938089186e-06
order_loss: 1.0530161489441525e-06
order_loss: 8.265238648164086e-06
order_loss: 1.4469368579739239e-05
order_loss: 1.710682045086287e-05
12/33-(0.703)
order_loss: 2.3841860752327193e-07
order_loss: 1.7285395870203502e-06
order_loss: 2.4120794478221796e-05
order_loss: 1.768273136804055e-06
order_loss: 1.285097278014291e-05
order_loss: 3.0398464332392905e-06
order_loss: 4.291543518775143e-06
order_loss: 1.3754112842434552e-05
order_loss: 6.309656782832462e-06
order_loss: 9.03014461073326e-06
order_loss: 1.1026920219592284e-05
order_loss: 1.4543689758284017e-05

=== Evaluating Model ===
accuracy on Valid 0.5952380952380952

Total valid loss 1.075506941193626
accuracy on Test 0.6398809523809523
Best accuracy on Test 0.7261904761904762

**** Epoch 13/20 ****
order_loss: 5.802786472486332e-05
order_loss: 2.676284384506289e-05
order_loss: 7.3761725616350304e-06
27/33-(0.248)
order_loss: 6.981716433074325e-05
order_loss: 6.675751592410961e-06
order_loss: 3.7125396374904085e-06
order_loss: 8.94069742685133e-08
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.0033462558567408e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.671676040539751e-06
order_loss: 8.725222141947597e-05
order_loss: 9.358096576761454e-06
order_loss: 5.960467319710006e-07
order_loss: 4.858013562625274e-05
order_loss: 0.00017118375399149954
9/33-(0.497)
order_loss: 4.768373287333816e-07
order_loss: 7.212187938421266e-06
order_loss: 6.839693469373742e-06
order_loss: 4.589663149090484e-05
order_loss: 2.525761829019757e-06
order_loss: 2.406105340924114e-05
order_loss: 1.1523654393386096e-05
order_loss: 9.934115041687619e-07
order_loss: 2.787622725008987e-05
order_loss: 2.3841860752327193e-07
order_loss: 2.745893652900122e-05
order_loss: 3.576279254957626e-07
order_loss: 9.65600338531658e-06
order_loss: 1.3858096963303979e-06
order_loss: 2.7219546154810814e-06
24/33-(0.204)
order_loss: 8.344655384462385e-07
order_loss: 8.642679745207715e-07
order_loss: 5.2274641348049045e-05
order_loss: 1.5239114873111248e-05
order_loss: 5.304841579345521e-06
order_loss: 4.231938873999752e-06
order_loss: 2.741820026130881e-06
order_loss: 1.5894755051704124e-05
order_loss: 0.0001104894035961479
order_loss: 3.7849088130315067e-06
6/33-(0.319)
order_loss: 4.768373287333816e-07
order_loss: 3.820761776296422e-05
order_loss: 1.4543676115863491e-05
order_loss: 1.4603343515773304e-05
order_loss: 9.558169404044747e-05
order_loss: 3.8100282836239785e-05
order_loss: 3.3776756026782095e-05
order_loss: 4.559783519653138e-06
order_loss: 3.089629899477586e-05
order_loss: 4.8043380957096815e-05
order_loss: 5.741955646954011e-06
order_loss: 6.44550018478185e-05
order_loss: 1.6093266594907618e-06
order_loss: 9.795101505005732e-06
21/33-(0.950)

=== Evaluating Model ===
accuracy on Valid 0.6636904761904762

Total valid loss 1.1554204104911714
accuracy on Test 0.6636904761904762
Best accuracy on Test 0.7261904761904762

**** Epoch 14/20 ****
order_loss: 7.23206812835997e-06
order_loss: 0.0001359766611130908
order_loss: 0.0004214894725009799
order_loss: 8.940702969084668e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.371008799353149e-07
order_loss: 0.00015319566591642797
order_loss: 1.314297696808353e-05
order_loss: 0.004102052189409733
order_loss: 4.068033831572393e-06
order_loss: 7.98708242655266e-06
3/33-(0.156)
order_loss: 5.960466182841628e-07
order_loss: 9.7463715064805e-05
order_loss: 3.4173460790043464e-06
order_loss: 0.00017968278552871197
order_loss: 1.907352270791307e-06
order_loss: 6.5565143358981e-07
order_loss: 9.655958592702518e-07
order_loss: 1.475217004553997e-06
order_loss: 2.741922617133241e-05
order_loss: 5.090366175863892e-05
order_loss: 3.0458882974926382e-05
order_loss: 4.434683796716854e-05
order_loss: 1.0609683158691041e-05
order_loss: 6.63603532302659e-06
order_loss: 7.510213436034974e-06
18/33-(0.226)
order_loss: 0.001177094061858952
order_loss: 2.2053782231523655e-06
order_loss: 1.084806399376248e-06
order_loss: 7.152561920520384e-07
order_loss: 4.768372718899627e-07
order_loss: 7.00354917171353e-07
order_loss: 1.1920930376163597e-07
order_loss: 7.74863383412594e-06
order_loss: 9.059960575541481e-06
order_loss: 7.033372639853042e-06
order_loss: 1.2914358649140922e-06
order_loss: 2.3841860752327193e-07
0/33-(0.156)
order_loss: 4.1127350414171815e-06
order_loss: 4.1723259869286267e-07
order_loss: 4.172333774477011e-06
order_loss: 5.06639594277658e-07
order_loss: 5.364419735087722e-07
order_loss: 6.854538696643431e-07
order_loss: 5.960464477539063e-08
order_loss: 1.4702500266139396e-06
order_loss: 3.576279254957626e-07
order_loss: 3.159059360768879e-06
order_loss: 3.0398423405131325e-06
order_loss: 2.938552097475622e-05
order_loss: 1.788139485370266e-07
15/33-(0.332)
order_loss: 1.132489046540286e-06
order_loss: 1.9073536350333598e-06
order_loss: 1.3709084214497125e-06

=== Evaluating Model ===
accuracy on Valid 0.6934523809523809

Total valid loss 0.9442659715811411
accuracy on Test 0.7172619047619048
Best accuracy on Test 0.7261904761904762

**** Epoch 15/20 ****
order_loss: 1.1920930376163597e-07
order_loss: 1.89346719707828e-05
order_loss: 3.570491389837116e-05
order_loss: 3.576291192075587e-06
order_loss: 0.0046954890713095665
order_loss: 5.145890099811368e-06
order_loss: 1.0132800980500178e-06
order_loss: 1.356007146569027e-06
order_loss: 3.874303047268768e-07
order_loss: 8.702347258804366e-06
order_loss: 5.960466751275817e-07
order_loss: 2.741817297646776e-06
30/33-(0.060)
order_loss: 3.0558065191144124e-05
order_loss: 3.695494797284482e-06
order_loss: 5.960464477539063e-08
order_loss: 8.523502401658334e-06
order_loss: 0.0006667024572379887
order_loss: 3.576279254957626e-07
order_loss: 4.768372718899627e-07
order_loss: 2.8908316380693577e-06
order_loss: 7.351244448727812e-07
order_loss: 4.172326271145721e-07
order_loss: 6.407502723959624e-07
order_loss: 2.6822095833267667e-07
order_loss: 1.311303321926971e-06
12/33-(0.603)
order_loss: 4.669060217565857e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.245222382654902e-06
order_loss: 1.788139627478813e-07
order_loss: 1.1324889328534482e-06
order_loss: 2.0861628513557662e-07
order_loss: 4.136593815928791e-06
order_loss: 4.867746611125767e-06
order_loss: 2.3841860752327193e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.6689314179529902e-06
order_loss: 2.3245856937137432e-06
27/33-(0.207)
order_loss: 3.337865791763761e-06
order_loss: 6.556514904332289e-07
order_loss: 1.1920930376163597e-07
order_loss: 9.536749985272763e-07
order_loss: 1.788139627478813e-07
order_loss: 1.3967619452159852e-05
order_loss: 2.6226080080959946e-06
order_loss: 6.288328677328536e-06
order_loss: 7.092987743817503e-06
order_loss: 5.960464477539063e-08
order_loss: 1.120569550039363e-06
order_loss: 3.0001169761817437e-06
9/33-(0.712)
order_loss: 1.5258837038345519e-06
order_loss: 1.1026871788999415e-06
order_loss: 5.81145513933734e-07
order_loss: 1.1920930376163597e-07
order_loss: 8.344653679159819e-07
order_loss: 1.8080118024954572e-06

=== Evaluating Model ===
accuracy on Valid 0.6369047619047619

Total valid loss 1.22422133457093
accuracy on Test 0.6220238095238095
Best accuracy on Test 0.7261904761904762

**** Epoch 16/20 ****
order_loss: 2.0861650682491018e-06
order_loss: 1.5944262941047782e-06
order_loss: 5.900893938814988e-06
order_loss: 5.960464477539063e-08
order_loss: 8.61293483467307e-06
order_loss: 8.94069742685133e-08
order_loss: 2.175573627027916e-06
order_loss: 5.364420871956099e-07
order_loss: 1.788139627478813e-07
24/33-(0.093)
order_loss: 1.3709084214497125e-06
order_loss: 5.722074547520606e-06
order_loss: 5.960464477539063e-08
order_loss: 3.536558097039233e-06
order_loss: 2.98023280720372e-07
order_loss: 7.15256760486227e-07
order_loss: 4.6193611069611507e-07
order_loss: 5.960466182841628e-07
order_loss: 5.960464477539063e-08
order_loss: 1.4901180520610069e-06
order_loss: 1.1523575267347042e-06
order_loss: 1.788139627478813e-07
6/33-(0.033)
order_loss: 2.98023280720372e-07
order_loss: 5.960464477539063e-08
order_loss: 0.07917702198028564
order_loss: 1.8775496073430986e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.483642325998517e-06
order_loss: 8.627866009192076e-06
order_loss: 2.712018385864212e-06
order_loss: 2.3245838747243397e-06
order_loss: 5.438944299385184e-06
order_loss: 1.3113030945532955e-06
order_loss: 4.375024218461476e-06
order_loss: 4.708777851192281e-06
21/33-(0.097)
order_loss: 2.0265599687263602e-06
order_loss: 2.1636720703099854e-05
order_loss: 0.0018819983815774322
order_loss: 0.0002369271678617224
order_loss: 3.814709089056123e-06
order_loss: 2.424768354103435e-05
order_loss: 8.046659786486998e-06
order_loss: 1.788139627478813e-07
order_loss: 0.5733758211135864
order_loss: 5.960464477539063e-08
order_loss: 2.563002908573253e-06
3/33-(0.497)
order_loss: 1.1920930376163597e-07
order_loss: 8.344656521330762e-07
order_loss: 4.1723265553628153e-07
order_loss: 4.1723259869286267e-07

=== Evaluating Model ===
accuracy on Valid 0.6726190476190477

Total valid loss 1.8659888874916803
accuracy on Test 0.6815476190476191
Best accuracy on Test 0.7261904761904762

**** Epoch 17/20 ****
order_loss: 3.178915619628242e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.2815014542866265e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.509986987002776e-06
18/33-(0.124)
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.3841860752327193e-07
order_loss: 2.205376404162962e-06
order_loss: 0.00025612686295062304
order_loss: 3.159144762321375e-05
order_loss: 0.0002138699492206797
order_loss: 7.033391739241779e-06
order_loss: 5.960466182841628e-07
order_loss: 3.5762795391747204e-07
order_loss: 2.3841863594498136e-07
0/33-(0.077)
order_loss: 3.576279254957626e-07
order_loss: 1.2874764252046589e-05
order_loss: 2.858830885088537e-05
order_loss: 8.940814041125122e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 0.0001205017397296615
order_loss: 1.005355989036616e-05
order_loss: 5.9008934840676375e-06
order_loss: 3.337868292874191e-06
order_loss: 6.357831807690673e-07
15/33-(0.618)
order_loss: 8.344656521330762e-07
order_loss: 2.4557415599701926e-05
order_loss: 1.1920930376163597e-07
order_loss: 0.00632571941241622
order_loss: 1.1920930376163597e-07
order_loss: 2.4617229428258725e-05
order_loss: 9.258714271709323e-06
order_loss: 2.0265611055947375e-06
order_loss: 1.7881422991194995e-06
order_loss: 2.3841860752327193e-07
30/33-(0.123)
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.2649790025752736e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07

=== Evaluating Model ===
accuracy on Valid 0.7351190476190477

Best accuracy on Valid 0.7351190476190477
Total valid loss 0.9981093037696112
accuracy on Test 0.7083333333333334
Best accuracy on Test 0.7261904761904762

**** Epoch 18/20 ****
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
12/33-(0.192)
order_loss: 1.5497220147153712e-06
order_loss: 7.152560215217818e-07
order_loss: 6.5565143358981e-07
order_loss: 5.776005127700046e-05
order_loss: 5.960464477539063e-08
order_loss: 2.0861628513557662e-07
order_loss: 4.768372718899627e-07
27/33-(0.022)
order_loss: 4.768382950715022e-06
order_loss: 9.536747711536009e-07
9/33-(0.020)
order_loss: 5.006802894058637e-06
order_loss: 4.768372718899627e-07
order_loss: 3.576279254957626e-07
24/33-(0.005)
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.576279254957626e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.025201072479831e-06
order_loss: 1.4007114259584341e-06
order_loss: 7.152560783652007e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
order_loss: 9.059946933120955e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.3841860752327193e-07
6/33-(0.161)

=== Evaluating Model ===
accuracy on Valid 0.6815476190476191

Total valid loss 1.3326807880685443
accuracy on Test 0.6845238095238095
Best accuracy on Test 0.7261904761904762

**** Epoch 19/20 ****
order_loss: 5.960466182841628e-07
order_loss: 3.576279254957626e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.95906322915107e-05
order_loss: 5.364419735087722e-07
21/33-(0.144)
order_loss: 5.960466182841628e-07
order_loss: 1.3411056443146663e-06
Best accuracy on Test 0.7261904761904762

Source domain: 8, Target domain: 8, Cur_fold 1
Corpus: TOEFL
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-spiece.model HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/minghongxia/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Loading embeddings from: xlnet-base-cased
Model: DIS_Simple Avg Plus Max_Min
Encoder: XLNet
Starting new HTTPS connection (1): s3.amazonaws.com:443
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Starting new HTTPS connection (1): s3.amazonaws.com:443
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/minghongxia/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Optimizer: adam
Optimizer: adam
**** Training Begins ****
**** Epoch 0/20 ****
Use CrossEntropyLoss
order_loss: 0.626643180847168
order_loss: 0.5786015391349792
order_loss: 0.4162152409553528
order_loss: 1.0533356666564941
order_loss: 0.16941814124584198
order_loss: 0.7170048952102661
order_loss: 0.23529082536697388
order_loss: 1.071967601776123
order_loss: 0.6241649985313416
order_loss: 0.4649654030799866
order_loss: 0.32700487971305847
order_loss: 0.7600095868110657
order_loss: 0.6215099692344666
order_loss: 0.4589325189590454
15/33-(1.191)
order_loss: 0.48323172330856323
order_loss: 0.408314049243927
order_loss: 0.622046172618866
order_loss: 0.3734907805919647
order_loss: 0.4020715355873108
order_loss: 0.3598770797252655
order_loss: 0.3170199394226074
order_loss: 0.22909574210643768
order_loss: 0.18246866762638092
order_loss: 0.2345878779888153
order_loss: 0.1421833038330078
order_loss: 0.13074660301208496
order_loss: 0.09525306522846222
order_loss: 0.04237690567970276
order_loss: 0.11048375070095062
30/33-(1.142)
order_loss: 0.05963269993662834
order_loss: 0.04488441348075867
order_loss: 0.0029596425592899323
order_loss: 0.0005608353530988097
order_loss: 0.9989044666290283
order_loss: 0.022757824510335922
order_loss: 0.01534312404692173
order_loss: 0.0031281504780054092
order_loss: 0.3568015396595001
order_loss: 0.03511364012956619
order_loss: 0.004177507013082504
order_loss: 0.0007985298288986087
order_loss: 0.004292259458452463
order_loss: 0.0011326419189572334
order_loss: 0.003132290905341506
12/33-(1.136)
order_loss: 1.0848147212527692e-05
order_loss: 2.512518403818831e-05
order_loss: 0.10043789446353912
order_loss: 1.3510405096894829e-06
order_loss: 0.15715527534484863
order_loss: 4.0614682802697644e-05
order_loss: 0.0015737575013190508
order_loss: 0.0013705483870580792
order_loss: 0.0007818831945769489
order_loss: 0.00011723744682967663
order_loss: 0.3914717137813568
order_loss: 0.0007061634678393602
order_loss: 1.966138916031923e-05
order_loss: 7.174986239988357e-05
order_loss: 9.456762199988589e-05
27/33-(0.745)
order_loss: 0.0002354613388888538
order_loss: 6.071113602956757e-05
order_loss: 3.576294830054394e-06

=== Evaluating Model ===
accuracy on Valid 0.56973293768546

Best accuracy on Valid 0.56973293768546
Total valid loss 0.7949463739281609
accuracy on Test 0.5952380952380952
Best accuracy on Test 0.5952380952380952

**** Epoch 0/20 ****
order_loss: 7.033372639853042e-06
order_loss: 0.0006650533759966493
order_loss: 0.0002915389777626842
order_loss: 0.000414733134675771
order_loss: 9.721023525344208e-05
order_loss: 1.900475581351202e-05
order_loss: 0.0004867643292527646
order_loss: 8.346571121364832e-05
order_loss: 3.973644311372482e-07
order_loss: 8.204346522688866e-05
order_loss: 0.00047546668793074787
order_loss: 0.00045300929923541844
9/33-(0.840)
order_loss: 0.0003555350413080305
order_loss: 8.702327249920927e-06
order_loss: 3.671840386232361e-05
order_loss: 5.761810825788416e-06
order_loss: 3.4372146728856023e-06
order_loss: 0.001248575048521161
order_loss: 0.0004096846387255937
order_loss: 0.0007240618579089642
order_loss: 0.0001871339773060754
order_loss: 2.4766846763668582e-05
order_loss: 4.500172053667484e-06
order_loss: 0.00037274687201716006
order_loss: 0.00031068798853084445
order_loss: 1.5676601833547466e-05
order_loss: 5.960466182841628e-07
24/33-(0.727)
order_loss: 2.2990667819976807
order_loss: 1.9998507923446596e-05
order_loss: 0.4258090555667877
order_loss: 6.669657159363851e-05
order_loss: 6.69934306642972e-05
order_loss: 0.00018681098299566656
order_loss: 0.023578180000185966
order_loss: 3.9236452721524984e-05
order_loss: 0.005835174582898617
order_loss: 0.00021198207105044276
order_loss: 3.507937799440697e-05
order_loss: 8.338525367435068e-05
order_loss: 7.808272130205296e-06
order_loss: 0.01225072331726551
order_loss: 0.0014323696959763765
6/33-(0.878)
order_loss: 0.003250101814046502
order_loss: 0.00011282829655101523
order_loss: 0.001754460739903152
order_loss: 0.013014590367674828
order_loss: 0.002043178305029869
order_loss: 0.11914568394422531
order_loss: 0.0002376976190134883
order_loss: 6.222772299224744e-06
order_loss: 1.3685616977454629e-05
order_loss: 3.6401761462911963e-05
order_loss: 5.4466232541017234e-05
order_loss: 2.014657366089523e-05
order_loss: 3.6747907870449126e-05
order_loss: 0.00019091191643383354
order_loss: 1.9779701688094065e-05
21/33-(0.798)
order_loss: 1.4901172562531428e-06
order_loss: 0.00017687819490674883
order_loss: 2.920635552072781e-06
order_loss: 0.0003987913078162819
order_loss: 0.000904334825463593

=== Evaluating Model ===
accuracy on Valid 0.5727002967359051

Best accuracy on Valid 0.5727002967359051
Total valid loss 0.8731688119116283
accuracy on Test 0.5982142857142857
Best accuracy on Test 0.5982142857142857

**** Epoch 1/20 ****
order_loss: 5.8298268413636833e-05
order_loss: 0.0003874955582432449
order_loss: 5.677370609191712e-06
order_loss: 0.000830653531011194
order_loss: 0.002434085588902235
order_loss: 6.527129153255373e-05
order_loss: 0.0002471406478434801
order_loss: 0.0014276953879743814
3/33-(0.582)
order_loss: 0.00023497627989854664
order_loss: 1.2656242688535713e-05
order_loss: 0.00046091509284451604
order_loss: 0.019316066056489944
order_loss: 0.00016333007079083472
order_loss: 0.0016605956479907036
order_loss: 5.872971814824268e-05
order_loss: 0.0004814453423023224
order_loss: 2.185508265029057e-06
order_loss: 1.388805867463816e-05
order_loss: 0.00012227398110553622
order_loss: 0.0016594963381066918
order_loss: 9.238820894097444e-06
order_loss: 2.5033987185452133e-06
order_loss: 4.291548066248652e-06
18/33-(0.864)
order_loss: 0.0019101114012300968
order_loss: 7.762767927488312e-05
order_loss: 1.3113191926095169e-05
order_loss: 1.4454150232268148e-06
order_loss: 0.0001558409130666405
order_loss: 1.8716205886448734e-05
order_loss: 7.015712617430836e-05
order_loss: 0.00015270343283191323
order_loss: 5.124773451825604e-05
order_loss: 3.76632742700167e-05
order_loss: 4.103564060642384e-05
order_loss: 7.359448500210419e-05
order_loss: 0.0007527213892899454
order_loss: 0.0003416443651076406
order_loss: 0.00449740793555975
0/33-(0.699)
order_loss: 5.871118901268346e-06
order_loss: 0.001018386916257441
order_loss: 9.798350947676226e-05
order_loss: 6.854565071989782e-06
order_loss: 2.7538499125512317e-05
order_loss: 0.00034889549715444446
order_loss: 0.0025124181993305683
order_loss: 0.005159136839210987
order_loss: 2.408038199064322e-06
order_loss: 3.105479845544323e-05
order_loss: 0.000648826127871871
order_loss: 0.0003981435438618064
order_loss: 0.16627085208892822
order_loss: 1.6212696209549904e-05
order_loss: 0.00012964601046405733
15/33-(1.680)
order_loss: 0.022662168368697166
order_loss: 2.0921448594890535e-05
order_loss: 0.6186316013336182
order_loss: 0.0004565170675050467
order_loss: 2.75976381090004e-05
order_loss: 1.5229130440275185e-05
order_loss: 0.001403720467351377
order_loss: 8.73051249072887e-05
order_loss: 5.3140352974878624e-05

=== Evaluating Model ===
accuracy on Valid 0.6973293768545994

Best accuracy on Valid 0.6973293768545994
Total valid loss 0.6497210505462828
accuracy on Test 0.6964285714285714
Best accuracy on Test 0.6964285714285714

**** Epoch 2/20 ****
order_loss: 3.502913023112342e-05
order_loss: 3.2782704693090636e-06
order_loss: 2.6018566131824628e-05
order_loss: 2.1457744878716767e-06
order_loss: 6.516836037917528e-06
30/33-(0.654)
order_loss: 4.1872576730384026e-06
order_loss: 9.238724487659056e-07
order_loss: 9.000414138427004e-06
order_loss: 3.3974786219914677e-06
order_loss: 2.6822092991096724e-07
order_loss: 4.768373287333816e-07
order_loss: 8.066563168540597e-06
order_loss: 2.4636667603772366e-06
order_loss: 2.893886085075792e-05
order_loss: 1.5497230378969107e-06
order_loss: 7.450585144397337e-07
order_loss: 1.7881422991194995e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.3841860752327193e-07
order_loss: 3.576279254957626e-07
12/33-(0.717)
order_loss: 2.3841863594498136e-07
order_loss: 7.83810446591815e-06
order_loss: 1.4901181657478446e-06
order_loss: 3.959968307754025e-05
order_loss: 1.8477485355106182e-06
order_loss: 7.152560783652007e-07
order_loss: 0.00030944589525461197
order_loss: 5.364420303521911e-07
order_loss: 1.341107349617232e-06
order_loss: 1.788139485370266e-07
order_loss: 5.453865924209822e-06
order_loss: 2.9962608095956966e-05
order_loss: 9.020272045745514e-06
order_loss: 7.152561920520384e-07
27/33-(0.564)
order_loss: 1.1920942597498652e-06
order_loss: 2.761690666375216e-06
order_loss: 2.7815558496513404e-06
order_loss: 0.001181408646516502
order_loss: 8.940702969084668e-07
order_loss: 5.0664216360019054e-06
order_loss: 1.0877860177060938e-06
order_loss: 1.1920930376163597e-07
order_loss: 9.000342288345564e-06
order_loss: 4.5696910433434823e-07
order_loss: 5.483642325998517e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.576288236217806e-06
order_loss: 4.425671704666456e-06
order_loss: 1.8477485355106182e-06
9/33-(0.629)
order_loss: 4.4703497792397684e-07
order_loss: 8.344653679159819e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.5696910433434823e-07
order_loss: 1.1920935776288388e-06
order_loss: 1.8954802726511844e-05
order_loss: 8.94069742685133e-08
order_loss: 5.960464477539063e-08
order_loss: 1.788139627478813e-07
order_loss: 4.589766831486486e-05
order_loss: 8.94069742685133e-08
order_loss: 8.682516636326909e-06

=== Evaluating Model ===
accuracy on Valid 0.7032640949554896

Best accuracy on Valid 0.7032640949554896
Total valid loss 0.6982433057966686
accuracy on Test 0.6964285714285714
Best accuracy on Test 0.6964285714285714

**** Epoch 3/20 ****
order_loss: 4.1723259869286267e-07
order_loss: 8.344656521330762e-07
order_loss: 3.5252064662927296e-06
24/33-(1.028)
order_loss: 2.3841860752327193e-07
order_loss: 0.00017991992353927344
order_loss: 4.768372718899627e-07
order_loss: 4.967087079421617e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.5894573834884795e-07
order_loss: 2.0861628513557662e-07
order_loss: 3.0895334930391982e-06
order_loss: 2.712018385864212e-06
order_loss: 4.1723419599293265e-06
order_loss: 5.364432581700385e-06
order_loss: 3.635896064224653e-06
order_loss: 6.556513199029723e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.5696910433434823e-07
6/33-(0.306)
order_loss: 0.00011549721239134669
order_loss: 1.9073520434176316e-06
order_loss: 8.64267803990515e-07
order_loss: 1.0430818520035245e-06
order_loss: 3.0696469366375823e-06
order_loss: 7.152560215217818e-07
order_loss: 1.4901174836268183e-06
order_loss: 3.516680180837284e-06
order_loss: 5.960466751275817e-07
order_loss: 1.0728841743912199e-06
order_loss: 4.768372718899627e-07
order_loss: 7.748606662971724e-07
order_loss: 5.960464477539063e-08
21/33-(0.451)
order_loss: 4.470349495022674e-07
order_loss: 8.344653679159819e-07
order_loss: 1.6093276826723013e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1126210210932186e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.1933175301237497e-05
order_loss: 5.117466935189441e-05
order_loss: 1.0331481234970852e-06
order_loss: 2.6822095833267667e-07
order_loss: 8.344653679159819e-07
order_loss: 1.6391280155403365e-07
order_loss: 2.98023280720372e-07
order_loss: 3.2186608223128133e-06
order_loss: 0.001272497233003378
3/33-(0.904)
order_loss: 7.152560215217818e-07
order_loss: 5.602852525044e-06
order_loss: 5.960464477539063e-08
order_loss: 1.10269793367479e-05
order_loss: 2.6226080080959946e-06
order_loss: 2.3841860752327193e-07
order_loss: 2.7120186132378876e-06
order_loss: 5.960466751275817e-07
order_loss: 2.98023280720372e-07
order_loss: 6.9142110987741034e-06
order_loss: 6.526750894408906e-06
order_loss: 2.32318361668149e-05
order_loss: 5.364421440390288e-07
order_loss: 7.74860836827429e-07
order_loss: 3.099449486398953e-06
18/33-(0.585)

=== Evaluating Model ===
accuracy on Valid 0.7329376854599406

Best accuracy on Valid 0.7329376854599406
Total valid loss 0.6464788402829852
accuracy on Test 0.6904761904761905
Best accuracy on Test 0.6964285714285714

**** Epoch 4/20 ****
order_loss: 1.2159362086094916e-06
order_loss: 3.7253032587614143e-06
order_loss: 1.2278632311790716e-05
order_loss: 1.4206065316102467e-05
order_loss: 9.9723540188279e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.3709080803891993e-06
order_loss: 8.940702969084668e-07
order_loss: 0.00018872508371714503
order_loss: 3.2782704693090636e-06
order_loss: 8.344653679159819e-07
0/33-(0.506)
order_loss: 5.761786496805144e-07
order_loss: 1.788139627478813e-07
order_loss: 0.0009406368480995297
order_loss: 3.1292444191421964e-07
order_loss: 4.768373855768004e-07
order_loss: 2.598769015094149e-06
order_loss: 2.3841860752327193e-07
order_loss: 4.7683893171779346e-06
order_loss: 0.00035827886313199997
order_loss: 1.5894590887910454e-06
order_loss: 8.940774932852946e-06
order_loss: 1.4752172319276724e-06
order_loss: 1.6987346498353872e-06
order_loss: 8.344653679159819e-07
order_loss: 1.2218986285006395e-06
15/33-(1.030)
order_loss: 2.7815505632133863e-07
order_loss: 4.768372718899627e-07
order_loss: 3.0398432500078343e-06
order_loss: 9.238729035132565e-07
order_loss: 1.6689360791133367e-06
order_loss: 8.642679176773527e-07
order_loss: 6.5565143358981e-07
order_loss: 5.761785359936766e-07
order_loss: 4.172326271145721e-07
order_loss: 0.00013326384942047298
order_loss: 2.582868319223053e-07
order_loss: 8.94069742685133e-08
order_loss: 1.2218965821375605e-06
30/33-(0.607)
order_loss: 9.77526815404417e-06
order_loss: 2.206894896517042e-05
order_loss: 5.364420303521911e-07
order_loss: 4.2021374611067586e-06
order_loss: 1.5894573834884795e-07
order_loss: 5.531345323106507e-06
order_loss: 2.207812576671131e-05
order_loss: 3.993525297119049e-06
order_loss: 3.889231720677344e-06
order_loss: 5.447906005429104e-06
order_loss: 8.225447345466819e-07
order_loss: 1.727084963931702e-05
order_loss: 2.4636647140141577e-06
order_loss: 2.5556781110935844e-05
order_loss: 3.774962067382148e-07
12/33-(0.655)
order_loss: 4.559775788948173e-06
order_loss: 1.844789949245751e-05
order_loss: 1.5497219010285335e-06

=== Evaluating Model ===
accuracy on Valid 0.5875370919881305

Total valid loss 1.0345362566766285
accuracy on Test 0.6011904761904762
Best accuracy on Test 0.6964285714285714

**** Epoch 5/20 ****
order_loss: 1.7881409348774469e-06
order_loss: 1.9441948097664863e-05
order_loss: 1.921907823998481e-05
order_loss: 0.000489831727463752
order_loss: 1.2715670436591608e-06
order_loss: 6.407502155525435e-07
order_loss: 2.0861628513557662e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.7881418443721486e-06
order_loss: 2.0265599687263602e-06
27/33-(0.451)
order_loss: 2.1219316295173485e-06
order_loss: 1.7643411410972476e-05
order_loss: 3.516680180837284e-06
order_loss: 9.238725624527433e-07
order_loss: 4.619363096480811e-07
order_loss: 9.13938379198953e-07
order_loss: 3.6927751352777705e-05
order_loss: 1.5795246781635797e-06
order_loss: 4.124810948269442e-05
order_loss: 5.960464477539063e-08
order_loss: 6.79500590194948e-06
order_loss: 8.344654816028196e-07
order_loss: 8.344653679159819e-07
order_loss: 3.969885074184276e-05
9/33-(0.418)
order_loss: 3.476938843505195e-07
order_loss: 7.814740092726424e-05
order_loss: 8.213642104237806e-06
order_loss: 1.788139627478813e-07
order_loss: 2.98023280720372e-07
order_loss: 1.9192755189578747e-06
order_loss: 2.2053754946682602e-06
order_loss: 1.788139627478813e-07
order_loss: 3.3140274808829417e-06
order_loss: 0.0005134569364599884
order_loss: 3.218656047465629e-06
order_loss: 1.4762583305127919e-05
order_loss: 8.106264431262389e-06
order_loss: 3.2782563152977673e-07
order_loss: 8.64274534251308e-06
24/33-(0.596)
order_loss: 2.264980821564677e-06
order_loss: 6.894316811667522e-06
order_loss: 1.8676162198971724e-06
order_loss: 5.225380846241023e-06
order_loss: 8.10632627690211e-06
order_loss: 7.629399192410347e-07
order_loss: 2.518302380849491e-06
order_loss: 4.6193619596124336e-07
order_loss: 9.834773209149716e-07
order_loss: 0.0005329879932105541
order_loss: 3.0994508506410057e-06
order_loss: 2.0742470496770693e-06
order_loss: 1.9669569155666977e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920948281840538e-06
6/33-(0.396)
order_loss: 3.5762795391747204e-07
order_loss: 4.768373287333816e-07
order_loss: 4.291558980185073e-06
order_loss: 4.857800831814529e-06
order_loss: 1.2218965821375605e-06

=== Evaluating Model ===
accuracy on Valid 0.6706231454005934

Total valid loss 0.7413786635512397
accuracy on Test 0.6636904761904762
Best accuracy on Test 0.6964285714285714

**** Epoch 6/20 ****
order_loss: 1.0728841743912199e-06
order_loss: 3.576279254957626e-07
order_loss: 6.357833512993238e-07
order_loss: 4.619362243829528e-07
order_loss: 8.94069742685133e-08
order_loss: 3.576279254957626e-07
order_loss: 3.57628505298635e-06
order_loss: 9.954153938451782e-06
21/33-(0.679)
order_loss: 0.00013972305168863386
order_loss: 4.1723259869286267e-07
order_loss: 4.4703500634568627e-07
order_loss: 0.0008025177521631122
order_loss: 1.9669725588755682e-05
order_loss: 1.927219727804186e-06
order_loss: 1.1920930376163597e-07
order_loss: 9.089714012588956e-07
order_loss: 9.934108646802997e-08
order_loss: 9.834773209149716e-07
order_loss: 5.225377208262216e-06
order_loss: 1.4901177110004937e-06
order_loss: 8.344653679159819e-07
order_loss: 3.2782563152977673e-07
order_loss: 1.4901162614933128e-07
3/33-(1.251)
order_loss: 7.45058400752896e-07
order_loss: 7.152561920520384e-07
order_loss: 8.940700695347914e-07
order_loss: 5.06639594277658e-07
order_loss: 4.768372718899627e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.960464477539063e-08
order_loss: 1.5695925412728684e-06
order_loss: 1.3232258879725123e-06
order_loss: 1.192093918689352e-06
order_loss: 1.5497228105232352e-06
order_loss: 9.32819693844067e-06
order_loss: 1.788139485370266e-07
18/33-(0.420)
order_loss: 7.152560215217818e-07
order_loss: 4.1723259869286267e-07
order_loss: 2.98023280720372e-07
order_loss: 5.960467319710006e-07
order_loss: 4.0382442421105225e-06
order_loss: 3.576279254957626e-07
order_loss: 7.470487616956234e-06
order_loss: 2.2848516891826876e-06
order_loss: 4.172339231445221e-06
order_loss: 5.215408691583434e-07
order_loss: 4.0233146592072444e-07
order_loss: 1.986824599953252e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.7404707250534557e-05
0/33-(0.620)
order_loss: 5.960466751275817e-07
order_loss: 3.842733713099733e-05
order_loss: 9.536747711536009e-07
order_loss: 1.9868268736900063e-06
order_loss: 2.98023280720372e-07
order_loss: 4.768372718899627e-07

=== Evaluating Model ===
accuracy on Valid 0.6943620178041543

Total valid loss 0.6597377572740827
accuracy on Test 0.6994047619047619
Best accuracy on Test 0.6994047619047619

**** Epoch 7/20 ****
order_loss: 8.94069742685133e-08
order_loss: 1.4901181657478446e-06
order_loss: 3.5762795391747204e-07
order_loss: 2.5033982637978625e-06
order_loss: 2.3841860752327193e-07
15/33-(0.354)
order_loss: 1.1920930376163597e-07
order_loss: 2.98023280720372e-07
order_loss: 1.9073504518019035e-06
order_loss: 6.794953151256777e-06
order_loss: 6.556513767463912e-07
order_loss: 1.3510407370631583e-06
order_loss: 1.788139627478813e-07
order_loss: 1.1920930376163597e-07
30/33-(0.269)
order_loss: 0.00020254777336958796
order_loss: 1.1920930376163597e-07
order_loss: 1.6689314179529902e-06
order_loss: 3.576279254957626e-07
order_loss: 1.788139627478813e-07
order_loss: 1.1920938050025143e-06
order_loss: 5.364421440390288e-07
order_loss: 1.1920930376163597e-07
order_loss: 8.791760592430364e-06
order_loss: 2.229220626759343e-06
12/33-(0.444)
order_loss: 1.1920930376163597e-07
order_loss: 1.788139627478813e-07
order_loss: 1.9868218714691466e-07
order_loss: 2.980233091420814e-07
order_loss: 4.3710085151360545e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.0994488042779267e-06
order_loss: 7.629439096490387e-06
order_loss: 2.3841860752327193e-07
order_loss: 5.960464477539063e-08
order_loss: 2.2053777684050146e-06
order_loss: 7.391003236989491e-06
order_loss: 5.960464477539063e-08
order_loss: 1.3907752816066932e-07
27/33-(0.893)
order_loss: 5.215409260017623e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.9014238205272704e-05
order_loss: 8.94069742685133e-08
order_loss: 2.3245856937137432e-06
order_loss: 3.57628505298635e-06
order_loss: 1.7434789697290398e-05
order_loss: 9.536749985272763e-07
order_loss: 9.735438197822077e-07
order_loss: 2.133888119715266e-05
order_loss: 2.582868319223053e-07

=== Evaluating Model ===
accuracy on Valid 0.7418397626112759

Best accuracy on Valid 0.7418397626112759
Total valid loss 0.6824202956188292
accuracy on Test 0.7083333333333334
Best accuracy on Test 0.7083333333333334

**** Epoch 8/20 ****
order_loss: 1.9868217293605994e-07
order_loss: 1.6093279100459768e-06
order_loss: 3.576279254957626e-07
9/33-(0.369)
order_loss: 1.3113030945532955e-06
order_loss: 4.768372718899627e-07
order_loss: 1.1920930376163597e-07
order_loss: 9.357972885482013e-06
order_loss: 0.0013537625782191753
order_loss: 4.768372718899627e-07
order_loss: 1.1920930376163597e-07
order_loss: 7.152560215217818e-07
order_loss: 5.960464477539063e-08
24/33-(0.589)
order_loss: 2.9802417884639e-06
order_loss: 9.735431376611814e-07
order_loss: 1.8656428437680006e-05
order_loss: 1.4603158433601493e-06
order_loss: 7.152560783652007e-07
order_loss: 1.8477456933396752e-06
order_loss: 1.1473902077341336e-06
order_loss: 2.6822095833267667e-07
order_loss: 1.0877856766455807e-06
order_loss: 5.960464477539063e-08
6/33-(0.362)
order_loss: 6.258491112021147e-07
order_loss: 2.3841860752327193e-07
order_loss: 2.712017703743186e-06
order_loss: 2.8849064619862475e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.563103968597716e-07
order_loss: 1.1920930376163597e-07
order_loss: 8.94069742685133e-08
order_loss: 5.960464477539063e-08
order_loss: 1.1920944871235406e-06
order_loss: 3.576279254957626e-07
order_loss: 7.152560215217818e-07
21/33-(0.926)
order_loss: 2.3841860752327193e-07
order_loss: 3.814709089056123e-06
order_loss: 9.53675112214114e-07
order_loss: 2.2918507966096513e-05
order_loss: 5.066396511210769e-07
order_loss: 5.12613078171853e-05
order_loss: 1.5894573834884795e-07
order_loss: 6.556513767463912e-07
order_loss: 7.152560783652007e-07
order_loss: 2.98023280720372e-07
order_loss: 7.927470505819656e-06
3/33-(0.310)

=== Evaluating Model ===
accuracy on Valid 0.6409495548961425

Total valid loss 0.8005216873827434
accuracy on Test 0.6547619047619048
Best accuracy on Test 0.7083333333333334

**** Epoch 9/20 ****
order_loss: 2.1656414901372045e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.788139485370266e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.7255841157748364e-05
order_loss: 2.3841860752327193e-07
order_loss: 1.9729419364011846e-05
order_loss: 1.1920930376163597e-07
order_loss: 8.94069742685133e-08
order_loss: 5.960464477539063e-08
order_loss: 1.8030725186690688e-05
order_loss: 1.1920930376163597e-07
18/33-(0.406)
order_loss: 1.1920930376163597e-07
order_loss: 6.75519629567134e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.960467319710006e-07
order_loss: 2.7815505632133863e-07
order_loss: 5.364420303521911e-07
order_loss: 1.3411071222435567e-06
order_loss: 1.1920930376163597e-07
0/33-(0.541)
order_loss: 1.3411063264356926e-06
order_loss: 9.983789368561702e-07
order_loss: 5.960464477539063e-08
order_loss: 1.1920930376163597e-07
order_loss: 3.4123788736906135e-06
order_loss: 1.418592887603154e-06
order_loss: 0.022240566089749336
order_loss: 5.960466182841628e-07
order_loss: 3.933920652343659e-06
order_loss: 2.18550411545948e-07
order_loss: 4.127653937757714e-06
order_loss: 1.3907772427046439e-06
order_loss: 1.7881409348774469e-06
order_loss: 9.059946933120955e-06
15/33-(0.338)
order_loss: 2.467721060384065e-05
order_loss: 2.98023280720372e-07
order_loss: 1.1523574130478664e-06
order_loss: 1.3510401686289697e-06
order_loss: 3.159053221679642e-06
order_loss: 3.814708179561421e-06
order_loss: 3.1789153354111477e-07
order_loss: 1.7583397493581288e-06
order_loss: 1.013280439110531e-06
order_loss: 4.092834205948748e-05
order_loss: 3.820761412498541e-05
order_loss: 6.357831239256484e-07
order_loss: 0.00013925429084338248
30/33-(0.456)
order_loss: 3.2782565995148616e-07
order_loss: 0.00023727890220470726
order_loss: 3.6955057112209033e-06

=== Evaluating Model ===
accuracy on Valid 0.7537091988130564

Best accuracy on Valid 0.7537091988130564
Total valid loss 0.6433364408356803
accuracy on Test 0.7142857142857143
Best accuracy on Test 0.7142857142857143

**** Epoch 10/20 ****
order_loss: 1.1920941460630274e-06
order_loss: 7.15256760486227e-07
order_loss: 0.00012704680557362735
order_loss: 0.0001542805985081941
order_loss: 1.8597003872855566e-05
order_loss: 1.1920930376163597e-07
order_loss: 5.960467888144194e-07
order_loss: 5.722062269342132e-06
order_loss: 4.11603796237614e-05
order_loss: 2.3841860752327193e-07
order_loss: 4.291548975743353e-06
12/33-(0.573)
order_loss: 6.755196864105528e-07
order_loss: 1.2964218512934167e-05
order_loss: 3.039843704755185e-06
order_loss: 1.5954821719788015e-05
order_loss: 6.616157861571992e-06
order_loss: 0.0003350903280079365
order_loss: 9.139384360423719e-07
order_loss: 3.993524387624348e-06
order_loss: 2.086240056087263e-05
order_loss: 8.344658226633328e-07
order_loss: 7.975419430295005e-05
order_loss: 1.136475293606054e-05
order_loss: 4.5719621994066983e-05
order_loss: 1.788139627478813e-07
27/33-(0.234)
order_loss: 2.7816651709144935e-05
order_loss: 1.1622917099884944e-06
order_loss: 8.344653679159819e-07
order_loss: 5.1856195568689145e-06
order_loss: 7.728877790214028e-06
order_loss: 5.2574017900042236e-05
order_loss: 5.543502629734576e-05
order_loss: 4.1723265553628153e-07
order_loss: 1.7484062482253648e-06
order_loss: 7.163202099036425e-05
order_loss: 2.38419102061016e-06
order_loss: 0.00014065047434996814
order_loss: 2.9206357794464566e-06
order_loss: 9.159399269265123e-06
order_loss: 3.5537974326871336e-05
9/33-(0.638)
order_loss: 2.145769485650817e-06
order_loss: 1.0430823067508754e-06
order_loss: 3.099442551501852e-07
order_loss: 1.4305126114777522e-06
order_loss: 2.98023280720372e-07
order_loss: 1.4543744327966124e-05
order_loss: 1.1920930376163597e-07
order_loss: 3.590344567783177e-05
order_loss: 4.768373855768004e-07
order_loss: 2.6425685064168647e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920935776288388e-06
order_loss: 6.914144137226685e-07
order_loss: 4.768373287333816e-07
24/33-(0.255)
order_loss: 4.768372718899627e-07
order_loss: 5.058773240307346e-05
order_loss: 1.579527406647685e-06
order_loss: 2.3841860752327193e-07

=== Evaluating Model ===
accuracy on Valid 0.7002967359050445

Total valid loss 0.7255950690734954
accuracy on Test 0.6696428571428571
Best accuracy on Test 0.7142857142857143

**** Epoch 11/20 ****
order_loss: 1.1920930376163597e-07
order_loss: 5.165737775314483e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.2954281373822596e-05
order_loss: 0.0007046558894217014
order_loss: 2.000411768676713e-05
order_loss: 1.4027229553903453e-05
order_loss: 3.5762798233918147e-07
6/33-(0.444)
order_loss: 4.232019273331389e-05
order_loss: 2.98023280720372e-07
order_loss: 3.81471272703493e-06
order_loss: 1.5894593161647208e-06
order_loss: 1.2516990182120935e-06
order_loss: 5.811481059936341e-06
order_loss: 1.788139627478813e-07
order_loss: 3.417346306378022e-06
order_loss: 2.622607780722319e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.8239259588881396e-05
order_loss: 3.57628505298635e-06
order_loss: 1.788139627478813e-07
21/33-(0.659)
order_loss: 2.08616665986483e-06
order_loss: 1.2516997003331198e-06
order_loss: 5.16573891218286e-07
order_loss: 8.583141607232392e-06
order_loss: 1.0132797569895047e-06
order_loss: 4.619389528670581e-06
order_loss: 2.7418175250204513e-06
order_loss: 1.788139627478813e-07
order_loss: 1.2318311064518639e-06
order_loss: 1.5894573834884795e-07
order_loss: 5.761825377703644e-06
order_loss: 2.520432872188394e-06
order_loss: 1.1920930376163597e-07
order_loss: 7.152560215217818e-07
3/33-(0.175)
order_loss: 4.562654430628754e-05
order_loss: 2.3841860752327193e-07
order_loss: 1.072884515451733e-06
order_loss: 2.3245859210874187e-06
order_loss: 3.0398448416235624e-06
order_loss: 3.159051175316563e-06
order_loss: 7.033390829747077e-06
order_loss: 9.536747711536009e-07
order_loss: 1.65307483257493e-05
order_loss: 2.4437949832645245e-06
order_loss: 1.788139627478813e-07
order_loss: 4.1723265553628153e-07
order_loss: 2.7815505632133863e-07
18/33-(0.574)
order_loss: 1.1920930376163597e-07
order_loss: 3.31125374941621e-05
order_loss: 7.152560783652007e-07
order_loss: 1.6689314179529902e-06
order_loss: 3.178914766976959e-07
order_loss: 1.758340090418642e-06
order_loss: 4.768373287333816e-07
order_loss: 3.576279254957626e-07

=== Evaluating Model ===
accuracy on Valid 0.685459940652819

Total valid loss 0.8645708362261454
accuracy on Test 0.6488095238095238
Best accuracy on Test 0.7142857142857143

**** Epoch 12/20 ****
order_loss: 0.00012377576786093414
order_loss: 9.53675112214114e-07
order_loss: 2.1696556359529495e-05
order_loss: 3.263563849031925e-05
order_loss: 8.940701263782103e-07
order_loss: 5.960466182841628e-07
0/33-(0.288)
order_loss: 9.65612616710132e-06
order_loss: 2.288870200573001e-05
order_loss: 3.576279254957626e-07
order_loss: 4.983196049579419e-05
order_loss: 9.775255421118345e-06
order_loss: 4.768373287333816e-07
order_loss: 5.138135747984052e-05
order_loss: 9.834842785494402e-06
order_loss: 4.967069799022283e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.3340267691528425e-05
order_loss: 1.093766240956029e-05
order_loss: 0.00010813197877723724
order_loss: 1.8209535483038053e-05
15/33-(0.393)
order_loss: 1.9479228285490535e-05
order_loss: 3.5762795391747204e-07
order_loss: 2.0861664324911544e-06
order_loss: 8.742019304008863e-07
order_loss: 5.722048967982118e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.066397648079146e-07
order_loss: 2.7418175250204513e-06
order_loss: 7.748607231405913e-07
order_loss: 1.7086692878365284e-06
order_loss: 6.079717422835529e-06
order_loss: 2.4518838472431526e-05
order_loss: 1.1920950555577292e-06
order_loss: 1.1920930376163597e-07
30/33-(0.405)
order_loss: 1.1205795999558177e-05
order_loss: 3.874303331485862e-07
order_loss: 1.192113631987013e-05
order_loss: 1.192094714497216e-06
order_loss: 1.5020508726593107e-05
order_loss: 4.49024355475558e-06
order_loss: 2.6822095833267667e-07
order_loss: 2.5630060918047093e-06
order_loss: 7.152560215217818e-07
order_loss: 1.1086641279689502e-05
order_loss: 2.3841860752327193e-07
order_loss: 4.1723265553628153e-07
order_loss: 5.165738343748671e-07
order_loss: 2.2649790025752736e-06
order_loss: 5.841286565555492e-06
12/33-(0.415)
order_loss: 1.1920930376163597e-07
order_loss: 1.0728844017648953e-06
order_loss: 1.7881413896247977e-06
order_loss: 3.4968179534189403e-06
order_loss: 6.98440198902972e-05
order_loss: 9.298368240706623e-06
order_loss: 1.6689314179529902e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.5762795391747204e-07
order_loss: 8.94069742685133e-08
order_loss: 3.576279254957626e-07

=== Evaluating Model ===
accuracy on Valid 0.6676557863501483

Total valid loss 0.7501540836833772
accuracy on Test 0.6815476190476191
Best accuracy on Test 0.7142857142857143

**** Epoch 13/20 ****
order_loss: 3.242693856009282e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.6524166969466023e-06
27/33-(0.390)
order_loss: 8.923678251449019e-05
order_loss: 4.609451025316957e-06
order_loss: 2.3841887468734058e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.177192871182342e-06
order_loss: 5.692299055226613e-06
order_loss: 1.2715674984065117e-06
order_loss: 1.4305124977909145e-06
order_loss: 2.384189428994432e-06
order_loss: 7.748607231405913e-07
order_loss: 1.788139627478813e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.3841860752327193e-07
9/33-(0.272)
order_loss: 6.616157861571992e-06
order_loss: 4.768372718899627e-07
order_loss: 2.940508238680195e-06
order_loss: 5.364432581700385e-06
order_loss: 8.583187991462182e-06
order_loss: 1.3709084214497125e-06
order_loss: 2.3841863594498136e-07
order_loss: 4.887606337433681e-06
order_loss: 0.00020255833806004375
24/33-(0.460)
order_loss: 2.1457708498928696e-06
order_loss: 8.145976835294277e-07
order_loss: 4.291561253921827e-06
order_loss: 2.3841860752327193e-07
order_loss: 3.576279254957626e-07
order_loss: 7.152560215217818e-07
order_loss: 2.70208579422615e-06
order_loss: 1.251698790838418e-06
order_loss: 5.960466182841628e-07
order_loss: 6.119438239693409e-06
order_loss: 8.940703537518857e-07
order_loss: 1.0132798706763424e-06
order_loss: 5.602852525044e-06
order_loss: 1.5894587477305322e-06
6/33-(0.165)
order_loss: 3.325994475744665e-05
order_loss: 1.1920930376163597e-07
order_loss: 6.556513199029723e-07
order_loss: 6.854538128209242e-07
order_loss: 2.98023280720372e-07
order_loss: 1.1920940323761897e-06
order_loss: 2.0265599687263602e-06
order_loss: 2.4437961201329017e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.264981276312028e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.933914285880746e-06
order_loss: 1.1920930376163597e-07
21/33-(0.278)

=== Evaluating Model ===
accuracy on Valid 0.7032640949554896

Total valid loss 0.831629087527593
accuracy on Test 0.6934523809523809
Best accuracy on Test 0.7142857142857143

**** Epoch 14/20 ****
order_loss: 1.1920930376163597e-07
order_loss: 2.05636456485081e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.3676767543511232e-06
order_loss: 2.2649794573226245e-06
order_loss: 5.960466182841628e-07
order_loss: 1.4305137483461294e-06
order_loss: 5.662444095833052e-07
order_loss: 9.536747711536009e-07
order_loss: 6.675724080196233e-07
order_loss: 3.9816695789340883e-05
order_loss: 5.960469025012571e-07
3/33-(1.004)
order_loss: 3.576279254957626e-07
order_loss: 7.152560783652007e-07
order_loss: 1.9073504518019035e-06
order_loss: 3.278256031080673e-07
order_loss: 5.245233751338674e-06
order_loss: 1.3828373084834311e-05
order_loss: 1.4901173699399806e-06
order_loss: 4.768372718899627e-07
order_loss: 5.364419735087722e-07
order_loss: 2.98023280720372e-07
order_loss: 0.0005852504400536418
order_loss: 2.2233027266338468e-05
18/33-(0.484)
order_loss: 4.768372718899627e-07
order_loss: 1.639130687181023e-06
order_loss: 6.755198569408094e-07
order_loss: 1.6093394151539542e-05
order_loss: 1.6689336916897446e-06
order_loss: 2.3245859210874187e-06
order_loss: 3.874303047268768e-07
order_loss: 2.3841860752327193e-07
order_loss: 5.364420303521911e-07
order_loss: 9.934120726029505e-07
order_loss: 4.768372718899627e-07
order_loss: 2.5153960450552404e-05
order_loss: 4.430082844919525e-05
order_loss: 1.7285382227782975e-06
order_loss: 2.2649790025752736e-06
0/33-(0.205)
order_loss: 9.536747711536009e-07
order_loss: 1.3510397138816188e-06
order_loss: 1.3113030945532955e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.43051272516459e-06
order_loss: 2.3841860752327193e-07
order_loss: 2.1755749912699685e-06
order_loss: 2.0861709799646633e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.0490519343875349e-05
order_loss: 2.98023280720372e-07
order_loss: 1.5894573834884795e-07
order_loss: 1.0538263268244918e-05
order_loss: 9.238727898264187e-07
15/33-(0.309)
order_loss: 2.801424216158921e-06
order_loss: 9.775229045771994e-06
order_loss: 4.172327123797004e-07

=== Evaluating Model ===
accuracy on Valid 0.6023738872403561

Total valid loss 1.0403848063378107
accuracy on Test 0.5714285714285714
Best accuracy on Test 0.7142857142857143

**** Epoch 15/20 ****
order_loss: 2.861027041944908e-06
order_loss: 9.099708222493064e-06
order_loss: 4.1723259869286267e-07
order_loss: 4.887700197286904e-05
order_loss: 1.0132842362509109e-05
order_loss: 1.788139627478813e-07
order_loss: 2.4637482056277804e-05
order_loss: 8.726500527700409e-05
order_loss: 4.442827048478648e-05
order_loss: 2.2590422304347157e-05
order_loss: 4.649191851058276e-06
30/33-(0.330)
order_loss: 1.168252993011265e-06
order_loss: 4.410760084283538e-06
order_loss: 1.1920931797249068e-07
order_loss: 0.0002777366025839001
order_loss: 5.722077730752062e-06
order_loss: 4.2142255551880226e-05
order_loss: 1.0132795296158292e-06
order_loss: 3.576279254957626e-07
order_loss: 1.3411060990620172e-06
order_loss: 1.430513066225103e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.5894573834884795e-07
12/33-(0.653)
order_loss: 2.98023280720372e-07
order_loss: 8.026841896935366e-06
order_loss: 3.139190766887623e-06
order_loss: 1.0728846291385707e-06
order_loss: 9.179191692965105e-06
order_loss: 1.49011640360186e-07
order_loss: 5.523404979612678e-06
order_loss: 1.7881409348774469e-06
order_loss: 0.00029966048896312714
order_loss: 5.960466751275817e-07
order_loss: 3.2782565995148616e-07
order_loss: 7.152560783652007e-07
order_loss: 2.98023280720372e-07
27/33-(0.245)
order_loss: 1.788139627478813e-07
order_loss: 2.2053761767892865e-06
order_loss: 2.3841860752327193e-07
order_loss: 4.808135599887464e-06
order_loss: 1.5497228105232352e-06
order_loss: 1.1920930376163597e-07
order_loss: 8.225507372117136e-06
order_loss: 6.91416835252312e-06
order_loss: 1.5894573834884795e-07
order_loss: 2.7815505632133863e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.3113030945532955e-06
9/33-(0.067)
order_loss: 7.4506310738797765e-06
order_loss: 1.764313128660433e-05
order_loss: 2.3841887468734058e-06
order_loss: 6.2883641476219054e-06
order_loss: 3.5762798233918147e-07
order_loss: 9.298336749452574e-07

=== Evaluating Model ===
accuracy on Valid 0.6706231454005934

Total valid loss 0.9790076187678746
accuracy on Test 0.6964285714285714
Best accuracy on Test 0.7142857142857143

**** Epoch 16/20 ****
order_loss: 2.9267281206557527e-05
order_loss: 6.2466037888953e-06
order_loss: 7.152560215217818e-07
order_loss: 2.3841860752327193e-07
order_loss: 6.5565143358981e-07
order_loss: 5.165738343748671e-07
order_loss: 1.5894573834884795e-07
24/33-(0.197)
order_loss: 2.455744288454298e-05
order_loss: 1.931195583892986e-06
order_loss: 6.8744539021281525e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.5762795391747204e-07
order_loss: 2.3365087145066354e-06
order_loss: 1.3113037766743219e-06
order_loss: 1.4126499081612565e-05
order_loss: 1.1920938050025143e-06
order_loss: 1.788139627478813e-07
order_loss: 3.178915619628242e-07
order_loss: 7.015724258963019e-05
6/33-(0.249)
order_loss: 1.1920930376163597e-07
order_loss: 4.172326271145721e-07
order_loss: 3.2186603675654624e-06
order_loss: 1.7881409348774469e-06
order_loss: 3.1651037716073915e-05
order_loss: 1.1920930376163597e-07
order_loss: 3.1889496312942356e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.269590029551182e-05
order_loss: 7.94740753917722e-06
order_loss: 2.4963359464891255e-05
order_loss: 9.457387932343408e-06
21/33-(0.089)
order_loss: 2.3841860752327193e-07
order_loss: 3.4492961276555434e-05
order_loss: 2.682213107618736e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.0728841743912199e-06
order_loss: 2.5332087716378737e-06
order_loss: 1.0776787348731887e-05
order_loss: 1.0728848565122462e-06
order_loss: 1.6641863112454303e-05
order_loss: 1.4603152749259607e-06
order_loss: 4.768373287333816e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.8676166746445233e-06
order_loss: 4.410796464071609e-06
order_loss: 2.7815505632133863e-07
3/33-(0.119)
order_loss: 1.1920930376163597e-07
order_loss: 5.722062269342132e-06
order_loss: 5.423111724667251e-05
order_loss: 1.5258810890372843e-06
order_loss: 6.55653229841846e-06
order_loss: 1.6093271142381127e-06
order_loss: 1.788139627478813e-07
order_loss: 1.072884970199084e-06

=== Evaluating Model ===
accuracy on Valid 0.6913946587537092

Total valid loss 0.7757180886609214
accuracy on Test 0.6964285714285714
Best accuracy on Test 0.7142857142857143

**** Epoch 17/20 ****
order_loss: 1.788139627478813e-07
order_loss: 2.4636642592668068e-06
order_loss: 8.940701263782103e-07
order_loss: 5.126022188051138e-06
order_loss: 2.3245904685609275e-06
order_loss: 3.2901969007070875e-06
18/33-(0.100)
order_loss: 1.7881409348774469e-06
order_loss: 4.768373287333816e-07
order_loss: 1.0728841743912199e-06
order_loss: 7.152560215217818e-07
order_loss: 1.3709092172575765e-06
order_loss: 3.218656047465629e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.2835109373554587e-05
order_loss: 1.3113030945532955e-06
order_loss: 1.0103181011800189e-05
order_loss: 3.576279254957626e-07
0/33-(0.149)
order_loss: 6.51681648378144e-06
order_loss: 5.66244523270143e-07
order_loss: 1.5894606804067735e-06
order_loss: 5.364420303521911e-07
order_loss: 1.966956460819347e-06
order_loss: 4.768372718899627e-07
order_loss: 1.4305131799119408e-06
order_loss: 2.6226387490169145e-05
order_loss: 1.033160060615046e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.0862487872364e-05
order_loss: 9.536749985272763e-07
order_loss: 1.907352270791307e-06
order_loss: 7.092993655533064e-06
15/33-(0.100)
order_loss: 2.6226089175906964e-06
order_loss: 2.3245852389663924e-06
order_loss: 5.960466182841628e-07
order_loss: 1.4901162614933128e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.2186603675654624e-06
order_loss: 7.549928682237805e-07
order_loss: 2.4437961201329017e-06
order_loss: 3.576279254957626e-07
order_loss: 6.437322554120328e-06
order_loss: 4.768373287333816e-07
order_loss: 3.3378689749952173e-06
30/33-(0.054)
order_loss: 3.337865791763761e-06
order_loss: 7.152560215217818e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 8.344656521330762e-07
order_loss: 3.576279254957626e-07
order_loss: 2.3841863594498136e-07
order_loss: 1.1920930376163597e-07

=== Evaluating Model ===
accuracy on Valid 0.7032640949554896

Total valid loss 0.879770998443876
accuracy on Test 0.7142857142857143
Best accuracy on Test 0.7142857142857143

**** Epoch 18/20 ****
order_loss: 1.132489387600799e-06
order_loss: 8.344653679159819e-07
12/33-(0.076)
order_loss: 1.7881418443721486e-06
order_loss: 4.371033355710097e-06
order_loss: 4.708781489171088e-06
order_loss: 1.788139627478813e-07
order_loss: 3.576279254957626e-07
order_loss: 1.9073515886702808e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.910217128577642e-05
order_loss: 3.659792128019035e-05
order_loss: 2.026560878221062e-06
order_loss: 2.2649810489383526e-06
order_loss: 9.536747711536009e-07
order_loss: 3.576279254957626e-07
order_loss: 1.1920930376163597e-07
27/33-(0.246)
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.3782815333106555e-05
order_loss: 1.895445711852517e-05
order_loss: 1.609327796359139e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.0994503958936548e-06
order_loss: 1.847747853389592e-06
order_loss: 5.960466182841628e-07
order_loss: 8.106239306471252e-07
order_loss: 4.768372718899627e-07
order_loss: 1.5497230378969107e-06
order_loss: 3.57628505298635e-06
9/33-(0.116)
order_loss: 2.0265611055947375e-06
order_loss: 5.960466751275817e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.0398423405131325e-06
order_loss: 1.6451016563223675e-05
order_loss: 1.788139627478813e-07
order_loss: 3.4570753086882178e-06
order_loss: 4.3710085151360545e-07
order_loss: 2.819451765390113e-05
order_loss: 3.874303047268768e-07
24/33-(0.227)
order_loss: 2.6226152840536088e-06
order_loss: 7.689057383686304e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.0160405003698543e-05
order_loss: 6.63604032524745e-06
order_loss: 1.1920930376163597e-07
order_loss: 7.510240720876027e-06
order_loss: 5.960466182841628e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.0265599687263602e-06
6/33-(0.045)

=== Evaluating Model ===
accuracy on Valid 0.6735905044510386

Total valid loss 1.0859419540280388
accuracy on Test 0.6398809523809523
Best accuracy on Test 0.7142857142857143

**** Epoch 19/20 ****
order_loss: 8.344653679159819e-07
order_loss: 1.7464464690419845e-05
order_loss: 2.98023280720372e-07
order_loss: 5.364419735087722e-07
order_loss: 1.0371261851105373e-05
order_loss: 2.2053761767892865e-06
order_loss: 2.3841860752327193e-07
21/33-(0.609)
order_loss: 2.3841860752327193e-07
order_loss: 2.861027041944908e-06
order_loss: 2.086165295622777e-06
Best accuracy on Test 0.7142857142857143

Source domain: 8, Target domain: 8, Cur_fold 2
Corpus: TOEFL
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-spiece.model HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/minghongxia/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Loading embeddings from: xlnet-base-cased
Model: DIS_Simple Avg Plus Max_Min
Encoder: XLNet
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/minghongxia/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Optimizer: adam
Optimizer: adam
**** Training Begins ****
**** Epoch 0/20 ****
Use CrossEntropyLoss
order_loss: 0.6814591288566589
order_loss: 0.6301716566085815
order_loss: 0.675334632396698
order_loss: 0.6291059851646423
order_loss: 0.6371895670890808
order_loss: 0.6705049276351929
order_loss: 0.6167460680007935
order_loss: 0.4104118049144745
order_loss: 0.5997005701065063
order_loss: 0.10749776661396027
order_loss: 0.624168336391449
order_loss: 0.6013805866241455
order_loss: 0.6769346594810486
order_loss: 0.7222129702568054
order_loss: 1.1287510395050049
15/33-(2.430)
order_loss: 0.6420387625694275
order_loss: 0.64784836769104
order_loss: 0.5798476338386536
order_loss: 0.6108302474021912
order_loss: 0.6155322194099426
order_loss: 0.6445180773735046
order_loss: 0.7661223411560059
order_loss: 0.6792497634887695
order_loss: 0.5291710495948792
order_loss: 0.3781081438064575
order_loss: 0.754483699798584
order_loss: 0.46966490149497986
order_loss: 0.4188041687011719
order_loss: 0.5699822902679443
order_loss: 1.4520082473754883
30/33-(2.577)
order_loss: 0.3572789132595062
order_loss: 0.5197620391845703
order_loss: 0.15768146514892578
order_loss: 0.5478336215019226
order_loss: 0.28807932138442993
order_loss: 0.18711161613464355
order_loss: 0.3912566602230072
order_loss: 0.5023341774940491
order_loss: 0.25322866439819336
order_loss: 0.4905664026737213
order_loss: 0.3706452250480652
order_loss: 0.34331876039505005
order_loss: 0.2530052065849304
order_loss: 0.23548834025859833
order_loss: 0.28392404317855835
12/33-(1.133)
order_loss: 0.2195381075143814
order_loss: 0.16240273416042328
order_loss: 0.29926955699920654
order_loss: 0.12680409848690033
order_loss: 0.10349881649017334
order_loss: 0.09963042289018631
order_loss: 0.38194742798805237
order_loss: 0.11183935403823853
order_loss: 0.09954428672790527
order_loss: 0.014852486550807953
order_loss: 0.004893596284091473
order_loss: 0.1532544493675232
order_loss: 0.18314793705940247
order_loss: 0.0030784057453274727
order_loss: 0.004123746417462826
27/33-(1.031)
order_loss: 0.01069004274904728
order_loss: 0.01267274096608162
order_loss: 0.02508709207177162

=== Evaluating Model ===
accuracy on Valid 0.5400593471810089

Best accuracy on Valid 0.5400593471810089
Total valid loss 1.0320560769601301
accuracy on Test 0.5667655786350149
Best accuracy on Test 0.5667655786350149

**** Epoch 0/20 ****
order_loss: 0.011900732293725014
order_loss: 0.0058507840149104595
order_loss: 0.0036581093445420265
order_loss: 0.003936802502721548
order_loss: 0.0008321133791469038
order_loss: 0.00040809583151713014
order_loss: 5.7071869377978146e-05
order_loss: 0.0002073745708912611
order_loss: 0.00011472075857454911
order_loss: 0.00022214205819182098
order_loss: 0.005613669753074646
9/33-(1.218)
order_loss: 7.557885692222044e-05
order_loss: 2.3067554138833657e-05
order_loss: 6.50577712804079e-05
order_loss: 8.80453171703266e-06
order_loss: 4.768372718899627e-07
order_loss: 3.075818676734343e-05
order_loss: 1.1882617473602295
order_loss: 1.9530792997102253e-05
order_loss: 9.77421150309965e-05
order_loss: 0.0028358844574540854
order_loss: 5.586752376984805e-05
order_loss: 3.887425918946974e-05
order_loss: 1.5199572771962266e-05
order_loss: 1.0622456073760986
order_loss: 0.0002190130326198414
24/33-(0.770)
order_loss: 0.004701666533946991
order_loss: 0.018304163590073586
order_loss: 0.0030312046874314547
order_loss: 0.013692355714738369
order_loss: 0.6300169229507446
order_loss: 0.00036170356906950474
order_loss: 0.2002614438533783
order_loss: 0.005213088355958462
order_loss: 2.0563831640174612e-05
order_loss: 0.0012847317848354578
order_loss: 0.00039336297777481377
order_loss: 0.006047424394637346
order_loss: 0.00038500764640048146
order_loss: 0.006131268106400967
order_loss: 0.00011995980457868427
6/33-(0.843)
order_loss: 0.0006410495843738317
order_loss: 0.0022115479223430157
order_loss: 0.0006816604873165488
order_loss: 0.0006629538838751614
order_loss: 0.00034754638909362257
order_loss: 0.00034588028211146593
order_loss: 0.0007019256590865552
order_loss: 0.001276158494874835
order_loss: 4.84604861412663e-05
order_loss: 0.0004925113171339035
order_loss: 0.0011184687027707696
order_loss: 0.018387949094176292
order_loss: 0.12350432574748993
order_loss: 0.00032772551639936864
order_loss: 0.0006922977627255023
21/33-(0.707)
order_loss: 0.0008189479704014957
order_loss: 0.00012234164751134813
order_loss: 0.0009845742024481297
order_loss: 0.0011473636841401458
order_loss: 0.0006514872657135129
order_loss: 0.0009713539620861411

=== Evaluating Model ===
accuracy on Valid 0.6023738872403561

Best accuracy on Valid 0.6023738872403561
Total valid loss 0.9337942695075815
accuracy on Test 0.6112759643916914
Best accuracy on Test 0.6112759643916914

**** Epoch 1/20 ****
order_loss: 0.00020628742640838027
order_loss: 0.0005499310209415853
order_loss: 2.900852996390313e-05
order_loss: 0.00010858901805477217
order_loss: 0.0011906540021300316
order_loss: 0.0007549662259407341
order_loss: 0.00027146193315275013
order_loss: 0.000706953345797956
3/33-(0.926)
order_loss: 0.009840255603194237
order_loss: 0.00013848321395926178
order_loss: 6.743616540916264e-05
order_loss: 0.00018915344844572246
order_loss: 0.0001679502020124346
order_loss: 0.012716475874185562
order_loss: 0.0006781971314921975
order_loss: 0.0013738939305767417
order_loss: 7.997818465810269e-05
order_loss: 5.5149961553979665e-05
order_loss: 0.0009584585786797106
order_loss: 0.0003513602714519948
order_loss: 9.417792171007022e-06
order_loss: 1.704721580608748e-05
order_loss: 0.0002466918667778373
18/33-(0.505)
order_loss: 0.0002995976828970015
order_loss: 2.39814689848572e-05
order_loss: 0.00014850501611363143
order_loss: 1.7315425793640316e-05
order_loss: 5.4479119171446655e-06
order_loss: 0.00016136774502228945
order_loss: 0.0005494299111887813
order_loss: 0.00020454505283851177
order_loss: 0.0003956125001423061
order_loss: 0.000207170145586133
order_loss: 0.00014406592526938766
order_loss: 0.00011098396498709917
order_loss: 0.0007647281745448709
order_loss: 7.883647049311548e-05
order_loss: 4.077110133948736e-05
0/33-(0.801)
order_loss: 7.346304482780397e-05
order_loss: 6.68688298901543e-05
order_loss: 0.00030179662280716
order_loss: 0.00020532056805677712
order_loss: 2.4901073629735038e-05
order_loss: 9.484681868343614e-06
order_loss: 2.0563634279824328e-06
order_loss: 0.010892100632190704
order_loss: 0.00013227843737695366
order_loss: 1.3311728253029287e-06
order_loss: 1.1920941460630274e-06
order_loss: 0.00017300239414907992
order_loss: 0.00010258353722747415
order_loss: 2.1564157577813603e-05
order_loss: 3.8724771002307534e-05
15/33-(0.649)
order_loss: 0.17416900396347046
order_loss: 2.8890659450553358e-05
order_loss: 7.010845001786947e-05
order_loss: 1.8359061868977733e-05
order_loss: 0.0002606995403766632
order_loss: 4.053142220072914e-06
order_loss: 0.0001301516022067517
order_loss: 8.64273988554487e-06
order_loss: 7.398551679216325e-05

=== Evaluating Model ===
accuracy on Valid 0.7091988130563798

Best accuracy on Valid 0.7091988130563798
Total valid loss 0.6020822809501127
accuracy on Test 0.712166172106825
Best accuracy on Test 0.712166172106825

**** Epoch 2/20 ****
order_loss: 0.0003758777747862041
order_loss: 6.228738129721023e-06
order_loss: 2.98023678624304e-06
order_loss: 2.6226109639537754e-06
order_loss: 0.0003359034890308976
30/33-(0.620)
order_loss: 0.00057818996720016
order_loss: 6.114087591413409e-05
order_loss: 0.0004783359181601554
order_loss: 0.0011048067826777697
order_loss: 6.199836934683844e-05
order_loss: 1.1920930376163597e-07
order_loss: 0.0026588544715195894
order_loss: 0.0016623230185359716
order_loss: 0.00011226315109524876
order_loss: 0.00025735070812515914
order_loss: 0.0002470981271471828
order_loss: 0.00010725420725066215
order_loss: 0.0003229956782888621
order_loss: 0.0008500564727000892
order_loss: 0.0016643260605633259
12/33-(1.131)
order_loss: 6.639282946707681e-05
order_loss: 0.002587288385257125
order_loss: 9.536749985272763e-07
order_loss: 0.005154793616384268
order_loss: 9.402818977832794e-05
order_loss: 0.00010672069765860215
order_loss: 0.00024387097801081836
order_loss: 0.00035930820740759373
order_loss: 0.00017350513371638954
order_loss: 0.0005682712071575224
order_loss: 0.00013649264292325824
order_loss: 0.0007592149777337909
order_loss: 8.058660569076892e-06
order_loss: 2.561060682637617e-05
order_loss: 2.381326339673251e-05
27/33-(0.507)
order_loss: 0.000459133560070768
order_loss: 0.0005243246559984982
order_loss: 4.373190313344821e-05
order_loss: 0.00016212793707381934
order_loss: 0.00011494808131828904
order_loss: 4.5094107917975634e-05
order_loss: 4.041476859129034e-05
order_loss: 0.006669080350548029
order_loss: 1.5986344806151465e-05
order_loss: 3.6557762541633565e-06
order_loss: 0.0002913478820119053
order_loss: 8.772272121859714e-05
order_loss: 3.759245737455785e-05
9/33-(0.352)
order_loss: 0.0001255423849215731
order_loss: 6.416010728571564e-05
order_loss: 3.4198608773294836e-05
order_loss: 0.00027076771948486567
order_loss: 0.000993165303952992
order_loss: 1.3649674656335264e-05
order_loss: 8.934468496590853e-05
order_loss: 0.00010561277304077521
order_loss: 2.0337885871413164e-05
order_loss: 2.5720175472088158e-05
order_loss: 3.264734550612047e-05
order_loss: 3.3810767490649596e-05

=== Evaluating Model ===
accuracy on Valid 0.7002967359050445

Total valid loss 0.6292664151300084
accuracy on Test 0.7240356083086054
Best accuracy on Test 0.7240356083086054

**** Epoch 3/20 ****
order_loss: 1.4615524378314149e-05
order_loss: 2.3802951545803808e-05
order_loss: 3.51668586517917e-06
24/33-(0.892)
order_loss: 0.0002791060833260417
order_loss: 4.947212346451124e-06
order_loss: 9.449604112887755e-05
order_loss: 7.450589123436657e-07
order_loss: 8.691844413988292e-05
order_loss: 2.882970147766173e-05
order_loss: 1.9416816940065473e-05
order_loss: 2.2495267330668867e-05
order_loss: 0.00016464173677377403
order_loss: 0.000583276036195457
order_loss: 0.0038083232939243317
order_loss: 7.791280950186774e-06
order_loss: 0.00011719713802449405
order_loss: 6.25917746219784e-05
6/33-(0.450)
order_loss: 9.318282536696643e-06
order_loss: 1.4233813089958858e-05
order_loss: 4.3611130422505084e-06
order_loss: 8.690508366271388e-06
order_loss: 1.2636264727916569e-05
order_loss: 1.1920930376163597e-07
order_loss: 6.697388016618788e-05
order_loss: 1.5894573834884795e-07
order_loss: 8.281711780000478e-05
order_loss: 9.114255954045802e-05
order_loss: 0.00021387187007348984
order_loss: 4.9025238695321605e-06
order_loss: 4.546249328996055e-05
order_loss: 3.655823093140498e-05
order_loss: 4.055465979035944e-05
21/33-(0.538)
order_loss: 0.0001377002045046538
order_loss: 0.00010612193727865815
order_loss: 3.2484663279319648e-06
order_loss: 0.0003496723365969956
order_loss: 5.984936797176488e-05
order_loss: 9.119588867179118e-06
order_loss: 1.2755593161273282e-05
order_loss: 3.130851109744981e-05
order_loss: 0.012865839526057243
order_loss: 0.0001922754745464772
order_loss: 4.927795089315623e-05
order_loss: 0.00015904706378933042
order_loss: 1.4722455489390995e-05
order_loss: 4.1723265553628153e-07
order_loss: 8.40535358292982e-05
3/33-(0.733)
order_loss: 3.974330684286542e-05
order_loss: 2.3841860752327193e-07
order_loss: 1.0282018592988607e-05
order_loss: 5.5315955250989646e-05
order_loss: 0.00023368242545984685
order_loss: 7.004215149208903e-05
order_loss: 4.133747279411182e-05
order_loss: 1.3470802514348179e-05
order_loss: 3.03546530631138e-05
order_loss: 2.6941413580061635e-06
order_loss: 0.00019028161477763206
order_loss: 1.1920930376163597e-07
order_loss: 0.0007600578246638179
order_loss: 1.1920930376163597e-07
order_loss: 7.364538760157302e-05
18/33-(1.049)

=== Evaluating Model ===
accuracy on Valid 0.6379821958456974

Total valid loss 0.826186902821064
accuracy on Test 0.6231454005934718
Best accuracy on Test 0.7240356083086054

**** Epoch 4/20 ****
order_loss: 0.009135197848081589
order_loss: 0.00014332107093650848
order_loss: 5.8787245507119223e-05
order_loss: 0.00015783424896653742
order_loss: 9.438974666409194e-05
order_loss: 1.5092074136191513e-05
order_loss: 0.0001072607992682606
order_loss: 1.795858406694606e-05
order_loss: 4.035438905702904e-05
order_loss: 0.00037618257920257747
order_loss: 6.606709212064743e-05
order_loss: 0.0002446864382363856
order_loss: 7.23206812835997e-06
order_loss: 0.003654350293800235
0/33-(0.571)
order_loss: 3.8743036157029564e-07
order_loss: 2.371608752582688e-05
order_loss: 2.3365560991805978e-05
order_loss: 2.6661291485652328e-05
order_loss: 2.07945176953217e-05
order_loss: 2.485577715560794e-05
order_loss: 2.6048728614114225e-05
order_loss: 7.123503746697679e-05
order_loss: 1.4196026313584298e-05
order_loss: 6.318175110209268e-06
order_loss: 7.917622497188859e-06
order_loss: 2.7180087272427045e-05
order_loss: 3.281343015260063e-05
order_loss: 1.466278376938135e-06
order_loss: 1.1920930376163597e-07
15/33-(0.476)
order_loss: 1.0907809155469295e-05
order_loss: 7.164547696447698e-06
order_loss: 1.7136371752712876e-06
order_loss: 3.642380397650413e-05
order_loss: 0.00020050058083143085
order_loss: 2.424788362986874e-05
order_loss: 1.260070985154016e-05
order_loss: 8.320075721712783e-05
order_loss: 4.657787940232083e-05
order_loss: 6.616137397941202e-06
order_loss: 7.669135084142908e-05
order_loss: 2.6524166969466023e-06
order_loss: 0.0004408248350955546
order_loss: 2.0632107407436706e-05
order_loss: 1.704744136077352e-05
30/33-(0.366)
order_loss: 6.1790669860783964e-06
order_loss: 4.977009211870609e-06
order_loss: 2.709558430069592e-05
order_loss: 3.2676078262738883e-05
order_loss: 9.981475886888802e-05
order_loss: 1.7881409348774469e-06
order_loss: 0.00012846305617131293
order_loss: 3.7513273127842695e-05
order_loss: 4.798202553502051e-06
order_loss: 5.430750752566382e-05
order_loss: 3.2664131140336394e-05
order_loss: 1.221063757839147e-05
order_loss: 3.5256773116998374e-05
order_loss: 4.755265035782941e-05
order_loss: 7.753463432891294e-05
12/33-(0.563)
order_loss: 3.180008570780046e-05
order_loss: 3.337865791763761e-06
order_loss: 7.563416875200346e-05

=== Evaluating Model ===
accuracy on Valid 0.6824925816023739

Total valid loss 0.6254722218621861
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7240356083086054

**** Epoch 5/20 ****
order_loss: 6.430877692764625e-05
order_loss: 2.1040661522420123e-05
order_loss: 6.440695869969204e-05
order_loss: 0.00012047394557157531
order_loss: 3.6557680687110405e-06
order_loss: 2.1088462744955905e-05
order_loss: 3.904145614797017e-06
order_loss: 0.00013058084005024284
order_loss: 2.2202771106094588e-06
order_loss: 7.665741577511653e-05
order_loss: 2.0663003397203283e-06
27/33-(0.623)
order_loss: 1.08083941086079e-05
order_loss: 3.3469685149611905e-05
order_loss: 0.00010881894559133798
order_loss: 2.2933907530386932e-05
order_loss: 1.4662958164990414e-05
order_loss: 2.6811630959855393e-05
order_loss: 1.5044711290101986e-05
order_loss: 1.1945030564675108e-05
order_loss: 3.933914285880746e-06
order_loss: 3.576279254957626e-07
order_loss: 2.4080565708572976e-05
order_loss: 0.00011951037595281377
order_loss: 0.0011070908512920141
order_loss: 9.536747711536009e-07
order_loss: 8.742023283048184e-07
9/33-(0.461)
order_loss: 1.430513066225103e-06
order_loss: 3.522890619933605e-05
order_loss: 3.622596705099568e-05
order_loss: 2.3771504856995307e-05
order_loss: 1.1036975593015086e-05
order_loss: 8.145974561557523e-07
order_loss: 3.5067587305093184e-06
order_loss: 2.5199118681484833e-05
order_loss: 0.00019880093168467283
order_loss: 1.5894593161647208e-06
order_loss: 8.58313524076948e-06
order_loss: 4.48527816843125e-06
order_loss: 5.233314368524589e-06
order_loss: 1.9371536836843006e-06
order_loss: 4.220307891955599e-05
24/33-(0.674)
order_loss: 2.622667670948431e-05
order_loss: 9.866162145044655e-05
order_loss: 5.364420303521911e-07
order_loss: 1.1920930376163597e-07
order_loss: 0.00010052217112388462
order_loss: 1.927218818309484e-06
order_loss: 2.309754563611932e-05
order_loss: 5.563103968597716e-07
order_loss: 1.966958052435075e-06
order_loss: 1.4209906112228055e-05
order_loss: 1.832297130022198e-05
order_loss: 9.472222154727206e-05
order_loss: 1.79675316758221e-05
order_loss: 5.6940814829431474e-05
order_loss: 5.269089797366178e-06
6/33-(0.837)
order_loss: 7.367214038822567e-06
order_loss: 3.029920435437816e-06
order_loss: 2.1387151718954556e-05
order_loss: 2.408035697953892e-06
order_loss: 1.1871553397213574e-05
order_loss: 8.344653679159819e-07

=== Evaluating Model ===
accuracy on Valid 0.685459940652819

Total valid loss 0.7168071513826196
accuracy on Test 0.6172106824925816
Best accuracy on Test 0.7240356083086054

**** Epoch 6/20 ****
order_loss: 4.482369695324451e-05
order_loss: 2.481266164977569e-05
order_loss: 1.0132802117368556e-06
order_loss: 0.0001884744269773364
order_loss: 3.6507997265289305e-06
order_loss: 0.000224497722228989
order_loss: 1.788139485370266e-07
order_loss: 6.218820999492891e-06
order_loss: 7.510223440476693e-06
21/33-(0.582)
order_loss: 4.7236862883437425e-06
order_loss: 5.355931079975562e-06
order_loss: 2.0861628513557662e-07
order_loss: 6.153304275358096e-05
order_loss: 0.00038796704029664397
order_loss: 6.278412456595106e-06
order_loss: 1.0609715900500305e-05
order_loss: 4.224872827762738e-05
order_loss: 0.027135511860251427
order_loss: 9.536752259009518e-07
order_loss: 1.3113040040479973e-06
order_loss: 7.107903002179228e-06
order_loss: 2.2411393274524016e-06
order_loss: 8.806699952401686e-06
order_loss: 0.0003230546717531979
3/33-(0.479)
order_loss: 2.235174747511337e-07
order_loss: 8.344656521330762e-07
order_loss: 1.281501681660302e-06
order_loss: 0.000527860363945365
order_loss: 4.2574768599479285e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.2915362996609474e-07
order_loss: 5.170726581127383e-06
order_loss: 3.010042973983218e-06
order_loss: 3.973644595589576e-07
order_loss: 3.5762795391747204e-07
order_loss: 1.147391230915673e-06
order_loss: 4.341594103607349e-05
order_loss: 2.7865253287018277e-06
18/33-(0.288)
order_loss: 4.768414328282233e-06
order_loss: 8.84149812918622e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.4543553561452427e-06
order_loss: 1.1603168786677998e-05
order_loss: 1.5497222420890466e-06
order_loss: 3.957776243623812e-06
order_loss: 1.3902969840273727e-05
order_loss: 3.45133084920235e-05
order_loss: 2.0265599687263602e-06
order_loss: 6.640020728809759e-06
order_loss: 4.271695615898352e-06
order_loss: 3.6160322451905813e-06
order_loss: 1.0860222573683131e-05
order_loss: 0.0004084156535100192
0/33-(0.687)
order_loss: 1.531855741632171e-05
order_loss: 6.121955084381625e-05
order_loss: 8.970608178060502e-06
order_loss: 5.558187694987282e-06
order_loss: 1.3462557035381906e-05
order_loss: 1.0141624443349428e-05
order_loss: 1.1682756849040743e-05
order_loss: 3.52663801095332e-06
order_loss: 1.2715670436591608e-06

=== Evaluating Model ===
accuracy on Valid 0.7062314540059347

Total valid loss 0.6317721896550872
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7240356083086054

**** Epoch 7/20 ****
order_loss: 3.933914285880746e-06
order_loss: 4.996907591703348e-06
order_loss: 8.304986295115668e-06
order_loss: 2.980255658258102e-06
order_loss: 1.4952634046494495e-05
15/33-(0.934)
order_loss: 6.894324087625137e-06
order_loss: 2.1972806280246004e-05
order_loss: 9.969061466108542e-06
order_loss: 3.0313344723253977e-06
order_loss: 4.4327680370770395e-05
order_loss: 1.5735657825644012e-06
order_loss: 9.894380355035537e-07
order_loss: 2.1100102003401844e-06
order_loss: 7.951392035465688e-06
order_loss: 5.364419735087722e-07
order_loss: 3.8743036157029564e-07
order_loss: 3.277306313975714e-05
order_loss: 3.010042973983218e-06
order_loss: 9.179157132166438e-06
30/33-(0.373)
order_loss: 1.2517129107436631e-05
order_loss: 3.814698175119702e-07
order_loss: 1.1920930376163597e-07
order_loss: 8.344653679159819e-07
order_loss: 1.9982937374152243e-05
order_loss: 1.221897150571749e-06
order_loss: 4.005446498922538e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.132489387600799e-06
order_loss: 1.40071063015057e-06
order_loss: 2.4240085622295737e-05
order_loss: 1.1563312227735878e-06
order_loss: 6.25848997515277e-07
order_loss: 9.556304576108232e-05
12/33-(0.584)
order_loss: 3.7153708944970276e-06
order_loss: 2.8411657240212662e-06
order_loss: 9.934115041687619e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.102686951526266e-06
order_loss: 3.973644311372482e-07
order_loss: 5.165737775314483e-07
order_loss: 6.0320558077364694e-06
order_loss: 9.139386065726285e-07
order_loss: 2.1934588403382804e-06
order_loss: 6.9439824983419385e-06
order_loss: 0.00010951170406769961
order_loss: 5.533339390240144e-06
order_loss: 2.0265599687263602e-06
order_loss: 1.0530167173783411e-06
27/33-(0.324)
order_loss: 8.174357049028913e-07
order_loss: 3.993519385403488e-06
order_loss: 2.9563977932411944e-06
order_loss: 5.165738343748671e-07
order_loss: 4.847870059165871e-06
order_loss: 2.6396417069918243e-06
order_loss: 4.271680609235773e-06
order_loss: 1.648718534852378e-05
order_loss: 0.0003698056098073721
order_loss: 8.940703537518857e-07
order_loss: 2.6027444164355984e-06
order_loss: 0.0007560890517197549

=== Evaluating Model ===
accuracy on Valid 0.7240356083086054

Best accuracy on Valid 0.7240356083086054
Total valid loss 0.5782252103090286
accuracy on Test 0.7359050445103857
Best accuracy on Test 0.7359050445103857

**** Epoch 8/20 ****
order_loss: 4.768373855768004e-07
order_loss: 2.861030679923715e-06
order_loss: 3.787592504522763e-05
9/33-(0.526)
order_loss: 4.688922217610525e-06
order_loss: 1.2874619415015331e-06
order_loss: 6.854537559775054e-07
order_loss: 1.132506804424338e-05
order_loss: 1.3769271390629001e-05
order_loss: 1.7046965012923465e-06
order_loss: 1.5326967286455329e-06
order_loss: 2.765666749837692e-06
order_loss: 3.0280676583060995e-05
order_loss: 8.717295713722706e-06
order_loss: 7.063195425871527e-06
order_loss: 2.598775154183386e-06
order_loss: 0.00012547986989375204
order_loss: 1.3709077393286861e-06
24/33-(0.607)
order_loss: 1.5249133866745979e-05
order_loss: 5.920774128753692e-06
order_loss: 1.9868218714691466e-07
order_loss: 7.528840797021985e-05
order_loss: 1.8477480807632674e-06
order_loss: 2.67522300418932e-05
order_loss: 1.2069958756910637e-06
order_loss: 4.430626631801715e-06
order_loss: 2.0027223399665672e-06
order_loss: 6.596295861527324e-06
order_loss: 1.890325620479416e-06
order_loss: 1.5571743006148608e-06
order_loss: 3.904359618900344e-05
order_loss: 7.748607231405913e-07
order_loss: 7.271842605405254e-06
6/33-(0.185)
order_loss: 7.152561920520384e-07
order_loss: 1.7881418443721486e-06
order_loss: 6.556516609634855e-07
order_loss: 3.8743146433262154e-06
order_loss: 6.407502723959624e-07
order_loss: 2.1607054804917425e-05
order_loss: 5.662443527398864e-07
order_loss: 1.4106448134043603e-06
order_loss: 1.2076150596840307e-05
order_loss: 4.529963916866109e-06
order_loss: 2.0504037365753902e-06
order_loss: 2.5392302632099018e-05
order_loss: 2.98023280720372e-07
order_loss: 2.6747657102532685e-06
order_loss: 9.53675112214114e-07
21/33-(0.295)
order_loss: 7.689079211559147e-06
order_loss: 1.2718387552013155e-05
order_loss: 8.344654816028196e-07
order_loss: 5.890965894650435e-06
order_loss: 0.00016537928604520857
order_loss: 9.417545925316517e-07
order_loss: 7.152561920520384e-07
order_loss: 1.1801730579463765e-06
order_loss: 2.920633505709702e-06
order_loss: 6.556515472766478e-07
order_loss: 7.450585144397337e-07
order_loss: 5.890954525966663e-06
order_loss: 1.291435182793066e-06
order_loss: 1.788145368664118e-06
3/33-(0.166)

=== Evaluating Model ===
accuracy on Valid 0.7151335311572701

Total valid loss 0.6081110327081247
accuracy on Test 0.7270029673590505
Best accuracy on Test 0.7359050445103857

**** Epoch 9/20 ****
order_loss: 2.2888236799190054e-06
order_loss: 1.6450912880827673e-06
order_loss: 3.8504781514348e-06
order_loss: 2.3841860752327193e-07
order_loss: 2.175573627027916e-06
order_loss: 4.291548975743353e-06
order_loss: 1.1026879747078056e-06
order_loss: 2.7815508474304806e-07
order_loss: 6.2670956140209455e-06
order_loss: 2.5555559659551363e-06
order_loss: 1.788139485370266e-07
order_loss: 1.106666422856506e-05
order_loss: 9.179124731417687e-07
order_loss: 1.0490431350262952e-06
18/33-(0.297)
order_loss: 1.1920931797249068e-07
order_loss: 7.450624707416864e-06
order_loss: 1.4156127008391195e-06
order_loss: 1.3709085351365502e-06
order_loss: 3.2931768600974465e-06
order_loss: 1.5467803677893244e-05
order_loss: 8.344653679159819e-07
order_loss: 9.644106285122689e-06
order_loss: 6.922752618265804e-06
order_loss: 7.256920071085915e-06
order_loss: 7.351245017162e-07
order_loss: 0.01849101483821869
order_loss: 3.973643742938293e-07
order_loss: 1.5298550124498433e-06
order_loss: 6.392649993358646e-06
0/33-(0.222)
order_loss: 2.0265601961000357e-06
order_loss: 3.2186578664550325e-06
order_loss: 1.3733143532590475e-05
order_loss: 1.887484131657402e-06
order_loss: 5.960482212685747e-06
order_loss: 1.2600542504515033e-05
order_loss: 5.513433052328764e-07
order_loss: 9.372947715746704e-06
order_loss: 1.0132794159289915e-06
order_loss: 1.5795478248037398e-05
order_loss: 8.428188266407233e-06
order_loss: 2.8809006380470237e-06
order_loss: 1.612021696928423e-05
order_loss: 1.2616333151527215e-06
order_loss: 1.990005694096908e-05
15/33-(0.898)
order_loss: 2.264981276312028e-06
order_loss: 8.940703537518857e-07
order_loss: 4.239353438606486e-05
order_loss: 8.493761015415657e-06
order_loss: 2.1457701677718433e-06
order_loss: 1.9550363958842354e-06
order_loss: 7.093025942594977e-06
order_loss: 1.4086670489632525e-05
order_loss: 1.430513520972454e-06
order_loss: 5.111127393320203e-06
order_loss: 4.1425346353207715e-06
order_loss: 7.132755399652524e-06
order_loss: 2.2530632577399956e-06
order_loss: 2.98023280720372e-07
order_loss: 1.0689417649700772e-05
30/33-(0.491)
order_loss: 1.4901162614933128e-07
order_loss: 1.6391280155403365e-07
order_loss: 1.3609980669571087e-05

=== Evaluating Model ===
accuracy on Valid 0.7240356083086054

Best accuracy on Valid 0.7240356083086054
Total valid loss 0.6139234141869978
accuracy on Test 0.7151335311572701
Best accuracy on Test 0.7359050445103857

**** Epoch 10/20 ****
order_loss: 2.336510078748688e-06
order_loss: 1.9818596683762735e-06
order_loss: 1.847767453000415e-05
order_loss: 1.0359380212321412e-05
order_loss: 1.0430814256778831e-07
order_loss: 0.00026894494658336043
order_loss: 0.00022759784769732505
order_loss: 2.1627558453474194e-05
order_loss: 1.582997356308624e-05
order_loss: 1.341105758001504e-06
order_loss: 8.940700695347914e-07
order_loss: 6.655855031567626e-07
12/33-(0.534)
order_loss: 1.1920930376163597e-07
order_loss: 1.4424555047298782e-05
order_loss: 1.74346369021805e-05
order_loss: 3.377597295184387e-07
order_loss: 1.2367979707050836e-06
order_loss: 1.1920948281840538e-06
order_loss: 3.159055268042721e-06
order_loss: 5.7816951084532775e-06
order_loss: 1.0144847692572512e-05
order_loss: 3.486894001980545e-06
order_loss: 5.698243967344752e-06
order_loss: 8.801778676570393e-06
order_loss: 9.82756773737492e-06
order_loss: 9.191139724862296e-06
order_loss: 5.15583815285936e-06
27/33-(0.481)
order_loss: 2.1219300379016204e-06
order_loss: 0.00014013962936587632
order_loss: 5.722047831113741e-07
order_loss: 5.563103400163527e-07
order_loss: 2.00873600988416e-05
order_loss: 9.536747711536009e-07
order_loss: 1.2159365496700048e-06
order_loss: 2.3484269604523433e-06
order_loss: 6.949951966817025e-06
order_loss: 2.460836185491644e-06
order_loss: 6.377733370754868e-06
order_loss: 1.4424545042857062e-05
order_loss: 4.3710093677873374e-07
order_loss: 1.6204427083721384e-05
order_loss: 1.400711084897921e-06
9/33-(0.360)
order_loss: 5.126020823809085e-06
order_loss: 9.53675112214114e-07
order_loss: 4.827998509426834e-06
order_loss: 4.744571924675256e-06
order_loss: 2.5321220164187253e-05
order_loss: 3.07957975564932e-06
order_loss: 1.5139808965614066e-05
order_loss: 2.041465904767392e-06
order_loss: 9.962507192540215e-07
order_loss: 2.622604995394795e-07
order_loss: 1.2815223271900322e-05
order_loss: 4.9173995648743585e-06
order_loss: 1.4682914297736716e-05
order_loss: 3.1292444191421964e-07
24/33-(0.275)
order_loss: 1.788139627478813e-07
order_loss: 5.4766758694313467e-05
order_loss: 3.051895328098908e-05
order_loss: 5.960467319710006e-07
order_loss: 1.0013728569902014e-05
order_loss: 6.775129349989584e-06

=== Evaluating Model ===
accuracy on Valid 0.6201780415430267

Total valid loss 0.8163820694793354
accuracy on Test 0.6528189910979229
Best accuracy on Test 0.7359050445103857

**** Epoch 11/20 ****
order_loss: 4.759915100294165e-06
order_loss: 0.0002118028060067445
order_loss: 1.634416366869118e-05
order_loss: 8.344654816028196e-07
order_loss: 8.940771294874139e-06
order_loss: 1.2715670436591608e-06
order_loss: 9.53675112214114e-07
order_loss: 2.3841863594498136e-07
order_loss: 1.5532019460806623e-05
6/33-(0.467)
order_loss: 5.364420871956099e-07
order_loss: 4.64917320641689e-06
order_loss: 5.168623374629533e-06
order_loss: 1.5497220147153712e-06
order_loss: 5.165772563486826e-06
order_loss: 2.7569320081965998e-05
order_loss: 2.7716232580132782e-06
order_loss: 1.0331480098102475e-06
order_loss: 3.059725486309617e-06
order_loss: 4.3710093677873374e-07
order_loss: 4.4703497792397684e-07
order_loss: 5.722083642467624e-06
order_loss: 1.3113046861690236e-06
order_loss: 8.046633865887998e-07
21/33-(0.192)
order_loss: 4.768373287333816e-07
order_loss: 1.6689322137608542e-06
order_loss: 3.5762864172284026e-06
order_loss: 5.066419817012502e-06
order_loss: 9.107697223953437e-06
order_loss: 3.059712753383792e-06
order_loss: 2.041462721535936e-06
order_loss: 2.702158053580206e-05
order_loss: 6.675744771200698e-06
order_loss: 1.981857394639519e-06
order_loss: 3.278256031080673e-07
order_loss: 3.8309110095724463e-05
order_loss: 5.722050673284684e-07
order_loss: 0.00033130653901025653
order_loss: 3.973878483520821e-05
3/33-(0.413)
order_loss: 9.934311492543202e-06
order_loss: 1.5259134670486674e-05
order_loss: 2.9802333756379085e-07
order_loss: 1.2772453601428424e-06
order_loss: 3.437207396927988e-06
order_loss: 6.258491112021147e-07
order_loss: 2.8163285605842248e-06
order_loss: 2.3841860752327193e-07
order_loss: 7.39098084068246e-07
order_loss: 3.475011180853471e-05
order_loss: 2.3841863594498136e-07
order_loss: 7.4804629548452795e-06
order_loss: 8.94069742685133e-08
order_loss: 1.1920930376163597e-07
order_loss: 2.920631914093974e-06
18/33-(0.518)
order_loss: 5.861128329343046e-07
order_loss: 1.3113038903611596e-06
order_loss: 4.371009936221526e-07
order_loss: 2.0265584055323416e-07
order_loss: 2.4040618882281706e-06
order_loss: 1.4901162614933128e-07
order_loss: 1.4305124977909145e-06
order_loss: 8.42825829749927e-06
order_loss: 2.414002210571198e-06

=== Evaluating Model ===
accuracy on Valid 0.655786350148368

Total valid loss 1.0862357047471134
accuracy on Test 0.6201780415430267
Best accuracy on Test 0.7359050445103857

**** Epoch 12/20 ****
order_loss: 4.547990101855248e-05
order_loss: 3.471988520686864e-06
order_loss: 9.139386065726285e-07
order_loss: 2.622620058900793e-06
order_loss: 9.934124136634637e-07
order_loss: 1.966955096577294e-06
0/33-(0.701)
order_loss: 5.364420303521911e-07
order_loss: 1.5993954320947523e-06
order_loss: 4.667472967412323e-05
order_loss: 2.3841860752327193e-07
order_loss: 6.953878255444579e-07
order_loss: 7.003549740147719e-07
order_loss: 5.960469025012571e-07
order_loss: 9.139384928857908e-07
order_loss: 2.125911123584956e-06
order_loss: 7.301575806195615e-07
order_loss: 1.678897206147667e-05
order_loss: 4.172335593466414e-06
order_loss: 1.1801745358752669e-06
order_loss: 1.6689327821950428e-06
15/33-(0.149)
order_loss: 1.341105758001504e-06
order_loss: 3.874326012009988e-06
order_loss: 1.9073513612966053e-06
order_loss: 2.3007492018223274e-06
order_loss: 7.549926408501051e-07
order_loss: 7.593700047436869e-06
order_loss: 2.953582770715002e-05
order_loss: 2.4437965748802526e-06
order_loss: 8.940700695347914e-07
order_loss: 1.1920930376163597e-07
order_loss: 6.109478363214293e-07
order_loss: 2.0010199932585238e-06
order_loss: 9.805085937841795e-06
order_loss: 2.9653454021172365e-06
order_loss: 0.0001180012768600136
30/33-(0.231)
order_loss: 3.397472710275906e-06
order_loss: 4.152481324126711e-06
order_loss: 5.364420303521911e-07
order_loss: 1.927219727804186e-06
order_loss: 9.834776619754848e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.689833698037546e-05
order_loss: 1.7980762549996143e-06
order_loss: 9.83477548288647e-07
order_loss: 1.3907752816066932e-07
order_loss: 1.8179447351940325e-06
order_loss: 1.8924523601526744e-06
order_loss: 4.3710093677873374e-07
order_loss: 2.98023280720372e-07
order_loss: 2.6464538223081036e-06
12/33-(0.228)
order_loss: 9.934120726029505e-07
order_loss: 7.152560215217818e-07
order_loss: 6.258491112021147e-07
order_loss: 4.529955219823023e-07
order_loss: 1.037121705849131e-06
order_loss: 1.3907752816066932e-07
order_loss: 2.0861629934643133e-07
order_loss: 7.609589374624193e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.5894573834884795e-07
order_loss: 8.791689651843626e-07

=== Evaluating Model ===
accuracy on Valid 0.685459940652819

Total valid loss 0.962967227128419
accuracy on Test 0.6706231454005934
Best accuracy on Test 0.7359050445103857

**** Epoch 13/20 ****
order_loss: 7.847950200812193e-07
order_loss: 1.4901162614933128e-07
order_loss: 1.1324892739139614e-06
27/33-(0.556)
order_loss: 8.344656521330762e-07
order_loss: 6.556513199029723e-07
order_loss: 5.424057235359214e-06
order_loss: 1.4901162614933128e-07
order_loss: 1.6887985054836463e-07
order_loss: 3.7749714465462603e-06
order_loss: 1.937197521328926e-05
order_loss: 5.364432581700385e-06
order_loss: 1.0371261851105373e-05
order_loss: 7.411598926410079e-05
order_loss: 1.3709093309444143e-06
order_loss: 5.960466182841628e-07
order_loss: 8.94069742685133e-08
order_loss: 7.947291464915907e-07
9/33-(0.065)
order_loss: 3.874303047268768e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.9868217293605994e-07
order_loss: 1.2795351722161286e-05
order_loss: 8.046635002756375e-07
order_loss: 4.3809868657263e-06
order_loss: 4.3710085151360545e-07
order_loss: 1.8974201339005958e-06
order_loss: 4.142538273299579e-06
order_loss: 2.1100102003401844e-06
order_loss: 1.370908648823388e-06
order_loss: 6.631085398112191e-06
order_loss: 5.143064299772959e-06
order_loss: 3.5762795391747204e-07
order_loss: 2.0265599687263602e-06
24/33-(0.366)
order_loss: 4.1574421629775316e-06
order_loss: 5.619870648843062e-07
order_loss: 1.0331626981496811e-05
order_loss: 1.1396637091820594e-05
order_loss: 3.0795790735282935e-06
order_loss: 9.33806575176277e-07
order_loss: 6.129420398792718e-06
order_loss: 1.7285376543441089e-06
order_loss: 6.4373416535090655e-06
order_loss: 3.37759814783567e-07
order_loss: 1.4801842098677298e-06
order_loss: 7.280608406290412e-05
order_loss: 3.923983058484737e-06
order_loss: 2.3841863594498136e-07
order_loss: 2.4736011710047023e-06
6/33-(0.136)
order_loss: 2.3841860752327193e-07
order_loss: 3.719467713381164e-05
order_loss: 7.74860836827429e-07
order_loss: 1.6490639609401114e-06
order_loss: 2.160671783713042e-06
order_loss: 5.563102831729339e-07
order_loss: 0.004637520294636488
order_loss: 8.1459756984259e-07
order_loss: 4.577659183269134e-06
order_loss: 2.3841860752327193e-07
order_loss: 7.98713881522417e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.6391280155403365e-07
order_loss: 5.960464477539063e-08
order_loss: 1.8239046539747505e-06
21/33-(0.229)

=== Evaluating Model ===
accuracy on Valid 0.6735905044510386

Total valid loss 0.9678622518073429
accuracy on Test 0.6617210682492581
Best accuracy on Test 0.7359050445103857

**** Epoch 14/20 ****
order_loss: 2.980233091420814e-07
order_loss: 1.0419152204121929e-05
order_loss: 3.0497826628561597e-06
order_loss: 3.1292602216126397e-06
order_loss: 4.036104201077251e-06
order_loss: 3.0517651339323493e-06
order_loss: 6.1542500588984694e-06
order_loss: 0.00012314599007368088
order_loss: 1.6093274552986259e-06
order_loss: 6.328077688522171e-06
order_loss: 4.76840750707197e-06
order_loss: 1.5010737115517259e-05
order_loss: 2.2245598302106373e-05
order_loss: 1.0728848565122462e-06
3/33-(0.237)
order_loss: 2.2649835500487825e-06
order_loss: 5.841257006977685e-07
order_loss: 2.165643763873959e-06
order_loss: 4.4703497792397684e-07
order_loss: 1.0530168310651788e-06
order_loss: 4.112736860406585e-06
order_loss: 4.896120572084328e-06
order_loss: 3.0100391086307354e-06
order_loss: 2.622613919811556e-06
order_loss: 4.3623160308925435e-05
order_loss: 5.960464477539063e-08
order_loss: 2.0457342543522827e-05
order_loss: 3.5762798233918147e-07
order_loss: 1.1175882264069514e-06
order_loss: 3.417345851630671e-06
18/33-(0.328)
order_loss: 6.854538696643431e-07
order_loss: 1.261633087779046e-06
order_loss: 9.536749985272763e-07
order_loss: 2.222413286290248e-06
order_loss: 2.2072274077800103e-05
order_loss: 2.3543871066067368e-06
order_loss: 1.3411055306278286e-06
order_loss: 3.540539864843595e-06
order_loss: 8.344653679159819e-07
order_loss: 8.145974561557523e-07
order_loss: 4.559773515211418e-06
order_loss: 4.231944330967963e-06
order_loss: 2.5332024051749613e-06
order_loss: 2.1816667867824435e-05
0/33-(0.275)
order_loss: 2.694142722248216e-06
order_loss: 1.260214389731118e-06
order_loss: 2.849110387614928e-06
order_loss: 4.768373287333816e-07
order_loss: 3.705354538396932e-05
order_loss: 1.3411060990620172e-06
order_loss: 2.266278170282021e-05
order_loss: 4.569690759126388e-07
order_loss: 5.960464477539063e-08
order_loss: 1.1920930376163597e-07
order_loss: 4.569691895994765e-07
order_loss: 4.569691895994765e-07
order_loss: 1.3709085351365502e-06
order_loss: 3.079574071307434e-07
order_loss: 9.194215635943692e-06
15/33-(0.321)
order_loss: 2.121929355780594e-06
order_loss: 6.854538696643431e-07
order_loss: 3.8743036157029564e-07

=== Evaluating Model ===
accuracy on Valid 0.685459940652819

Total valid loss 0.8916070368140936
accuracy on Test 0.7329376854599406
Best accuracy on Test 0.7359050445103857

**** Epoch 15/20 ****
order_loss: 1.0331484645575983e-06
order_loss: 5.53471977582376e-07
order_loss: 7.45058400752896e-07
order_loss: 1.2367975159577327e-06
order_loss: 9.139389476331417e-07
order_loss: 7.450583439094771e-07
order_loss: 4.1723501453816425e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.084551735810237e-06
order_loss: 3.2186583212023834e-06
order_loss: 3.178914766976959e-07
order_loss: 1.104686816688627e-05
30/33-(0.625)
order_loss: 2.98023678624304e-06
order_loss: 5.841259280714439e-07
order_loss: 2.9147933673812076e-05
order_loss: 5.573060661845375e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.3411062127488549e-06
order_loss: 3.5762798233918147e-07
order_loss: 3.576279254957626e-07
order_loss: 9.536749985272763e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.4551307685906067e-05
order_loss: 1.2378131032164674e-05
order_loss: 1.072884515451733e-06
order_loss: 6.556513199029723e-07
12/33-(0.089)
order_loss: 5.761785359936766e-07
order_loss: 1.2767696716764476e-05
order_loss: 3.5961720641353168e-06
order_loss: 2.1159685275051743e-06
order_loss: 1.132491092903365e-06
order_loss: 4.827993507205974e-06
order_loss: 1.0788635336211883e-05
order_loss: 4.148645166424103e-05
order_loss: 2.245697396574542e-05
order_loss: 1.8686536350287497e-05
order_loss: 3.1060772016644478e-06
order_loss: 7.83215909905266e-06
order_loss: 2.1457717593875714e-06
order_loss: 1.788139627478813e-07
order_loss: 8.359676030522678e-06
27/33-(0.399)
order_loss: 2.533202177801286e-06
order_loss: 8.106237032734498e-07
order_loss: 8.43412726680981e-06
order_loss: 8.940702969084668e-07
order_loss: 3.7210495520412223e-06
order_loss: 7.947293170218472e-07
order_loss: 1.2516991318989312e-06
order_loss: 1.466278376938135e-06
order_loss: 1.0984293794535915e-06
order_loss: 3.293174586360692e-06
order_loss: 3.2305808872479247e-06
order_loss: 1.0430814256778831e-07
order_loss: 1.877553927442932e-06
order_loss: 4.179819370619953e-06
order_loss: 4.1723265553628153e-07
9/33-(0.112)
order_loss: 2.2649846869171597e-06
order_loss: 4.986942258256022e-06
order_loss: 7.450588555002469e-07
order_loss: 1.5169824109761976e-05
order_loss: 1.1920948281840538e-06
order_loss: 1.460316752854851e-06

=== Evaluating Model ===
accuracy on Valid 0.6468842729970327

Total valid loss 0.9887597260319374
accuracy on Test 0.685459940652819
Best accuracy on Test 0.7359050445103857

**** Epoch 16/20 ****
order_loss: 2.6987119781551883e-05
order_loss: 1.303869612456765e-05
order_loss: 5.203621549298987e-05
order_loss: 1.81797040568199e-05
order_loss: 7.224200089694932e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.165737775314483e-07
order_loss: 1.5422722299263114e-06
order_loss: 6.556513199029723e-07
24/33-(0.138)
order_loss: 6.467167168011656e-06
order_loss: 0.00010997612116625533
order_loss: 3.919032678822987e-06
order_loss: 5.06639594277658e-07
order_loss: 3.218662641302217e-06
order_loss: 5.364420303521911e-07
order_loss: 7.450585144397337e-07
order_loss: 5.364419735087722e-07
order_loss: 7.420885594910942e-06
order_loss: 1.1580347063500085e-06
order_loss: 4.124655333725968e-06
order_loss: 2.1100133835716406e-06
order_loss: 1.505021032244258e-06
order_loss: 1.5099892607395304e-06
6/33-(0.333)
order_loss: 7.152561920520384e-07
order_loss: 1.5497222420890466e-06
order_loss: 1.132489046540286e-06
order_loss: 8.493669838571805e-07
order_loss: 1.5894573834884795e-07
order_loss: 1.0728844017648953e-06
order_loss: 1.0748874046839774e-05
order_loss: 5.764097295468673e-05
order_loss: 4.923394953948446e-06
order_loss: 7.8339235187741e-06
order_loss: 5.975403837510385e-06
order_loss: 1.326205165241845e-06
order_loss: 1.788139627478813e-07
order_loss: 2.6822095833267667e-07
order_loss: 1.6689336916897446e-06
21/33-(0.014)
order_loss: 1.811983793231775e-06
order_loss: 9.089714012588956e-07
order_loss: 1.0579833542578854e-06
order_loss: 1.2815158697776496e-05
order_loss: 4.1723259869286267e-07
order_loss: 3.774961783165054e-07
order_loss: 1.0331481234970852e-06
order_loss: 4.163835910730995e-06
order_loss: 1.5497220147153712e-06
order_loss: 6.775111160095548e-06
order_loss: 5.801591669296613e-06
order_loss: 7.152560215217818e-07
order_loss: 3.2931634450505953e-06
order_loss: 3.0398566650546854e-06
order_loss: 1.0530164900046657e-06
3/33-(0.435)
order_loss: 6.571486665052362e-06
order_loss: 1.0235305126116145e-05
order_loss: 1.752378921082709e-06
order_loss: 7.987054232216906e-06
order_loss: 7.291693691513501e-06
order_loss: 3.95782662963029e-05
order_loss: 1.1920931797249068e-07
order_loss: 3.576279254957626e-07
order_loss: 1.010307369142538e-05

=== Evaluating Model ===
accuracy on Valid 0.6231454005934718

Total valid loss 1.5903083682060242
accuracy on Test 0.655786350148368
Best accuracy on Test 0.7359050445103857

**** Epoch 17/20 ****
order_loss: 5.960466182841628e-07
order_loss: 8.940706948123989e-07
order_loss: 9.536747711536009e-07
order_loss: 2.8014269446430262e-06
order_loss: 2.5779086172406096e-06
order_loss: 4.683254701376427e-06
18/33-(0.096)
order_loss: 6.416062387870625e-05
order_loss: 4.768372718899627e-07
order_loss: 5.066396511210769e-07
order_loss: 3.5762795391747204e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.041463176283287e-06
order_loss: 4.804160653293366e-06
order_loss: 7.301618552446598e-06
order_loss: 4.482283657125663e-06
order_loss: 3.576280107608909e-07
order_loss: 1.2815009995392757e-06
order_loss: 2.2649790025752736e-06
order_loss: 1.4702507087349659e-06
0/33-(0.085)
order_loss: 3.3775978636185755e-07
order_loss: 4.629338036465924e-06
order_loss: 1.9953347873524763e-05
order_loss: 7.301574100893049e-07
order_loss: 2.6822095833267667e-07
order_loss: 1.4156115639707423e-06
order_loss: 2.554496404627571e-06
order_loss: 4.768372718899627e-07
order_loss: 3.2186649150389712e-06
order_loss: 4.321338451518386e-07
order_loss: 9.685767281553126e-07
order_loss: 5.841260417582816e-07
order_loss: 9.703814612294082e-06
order_loss: 1.1906230611202773e-05
order_loss: 3.5464986467559356e-06
15/33-(0.291)
order_loss: 1.1410043043724727e-06
order_loss: 1.049042793965782e-06
order_loss: 2.3841863594498136e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.13248984234815e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.086170297843637e-06
order_loss: 4.1723268395799096e-07
order_loss: 1.0490563909115735e-05
order_loss: 3.576279254957626e-07
order_loss: 6.95388166604971e-07
order_loss: 1.9371545931790024e-06
order_loss: 5.960468456578383e-07
order_loss: 4.634412471204996e-05
order_loss: 2.08616665986483e-06
30/33-(0.404)
order_loss: 8.642682587378658e-07
order_loss: 9.775171747605782e-07
order_loss: 1.6888216123334132e-05
order_loss: 2.1159687548788497e-06
order_loss: 7.735502003924921e-05
order_loss: 2.5034028112713713e-06
order_loss: 9.95402479020413e-06
order_loss: 5.6922763178590685e-06
order_loss: 1.2541199794213753e-05
order_loss: 3.0994428357189463e-07

=== Evaluating Model ===
accuracy on Valid 0.5875370919881305

Total valid loss 1.609882728620009
accuracy on Test 0.6023738872403561
Best accuracy on Test 0.7359050445103857

**** Epoch 18/20 ****
order_loss: 7.15256362582295e-07
order_loss: 4.4703509161081456e-07
order_loss: 1.3589873333330615e-06
12/33-(0.148)
order_loss: 5.483630616254231e-07
order_loss: 1.0132795296158292e-06
order_loss: 5.960464477539063e-08
order_loss: 3.5315920285938773e-06
order_loss: 1.9073549992754124e-06
order_loss: 6.457173071794386e-07
order_loss: 4.043202352477238e-06
order_loss: 1.0754518370958976e-05
order_loss: 1.6212492255363031e-06
order_loss: 4.867715119871718e-07
order_loss: 3.132449273834936e-05
order_loss: 2.013316589000169e-06
order_loss: 3.774962067382148e-07
order_loss: 3.576279254957626e-07
order_loss: 5.066397079644958e-07
27/33-(0.216)
order_loss: 1.7285374269704334e-06
order_loss: 6.5714675656636246e-06
order_loss: 4.509276550379582e-05
order_loss: 1.3113040040479973e-06
order_loss: 1.9669557786983205e-06
order_loss: 8.235460882133339e-06
order_loss: 8.195646614694851e-07
order_loss: 5.960466182841628e-07
order_loss: 3.203750509328529e-07
order_loss: 2.5630056370573584e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.112736860406585e-06
order_loss: 4.967056383975432e-07
order_loss: 8.94069742685133e-08
9/33-(0.434)
order_loss: 4.351181360107148e-06
order_loss: 1.3113030945532955e-06
order_loss: 1.132489387600799e-06
order_loss: 1.9868218714691466e-07
order_loss: 1.3232248647909728e-06
order_loss: 2.8461290639825165e-06
order_loss: 2.9683221782761393e-06
order_loss: 1.5894573834884795e-07
order_loss: 1.235825584444683e-05
order_loss: 1.098430402635131e-06
order_loss: 9.23872676139581e-07
order_loss: 1.8298957002116367e-05
order_loss: 5.051538209954742e-06
order_loss: 2.71329718088964e-05
24/33-(0.359)
order_loss: 0.00010744733299361542
order_loss: 1.0768706488306634e-05
order_loss: 3.933941115974449e-06
order_loss: 6.357831807690673e-07
order_loss: 2.3528378733317368e-05
order_loss: 1.6689314179529902e-06
order_loss: 1.0217951285085292e-06
order_loss: 5.438926677925338e-07
order_loss: 3.5762798233918147e-07
order_loss: 3.159055950163747e-06
order_loss: 5.304858404997503e-06
order_loss: 7.450679731846321e-06
order_loss: 1.859698022599332e-05
order_loss: 1.3113034356138087e-06
6/33-(0.263)

=== Evaluating Model ===
accuracy on Valid 0.5519287833827893

Total valid loss 1.829787102612582
accuracy on Test 0.6053412462908012
Best accuracy on Test 0.7359050445103857

**** Epoch 19/20 ****
order_loss: 4.847868240176467e-06
order_loss: 5.414153747551609e-06
order_loss: 1.1920938050025143e-06
order_loss: 1.7062311599147506e-05
order_loss: 1.3709085351365502e-06
order_loss: 2.3990910449356306e-06
order_loss: 5.185638201510301e-06
order_loss: 4.529970283329021e-06
order_loss: 2.4796141588012688e-05
order_loss: 3.039852799702203e-06
order_loss: 2.3841863594498136e-07
order_loss: 6.386263066815445e-06
order_loss: 3.3080673347285483e-06
order_loss: 3.7749623515992425e-07
order_loss: 3.3527735467941966e-06
21/33-(0.082)
order_loss: 5.960467888144194e-07
order_loss: 4.470349495022674e-07
order_loss: 5.629825318465009e-05
order_loss: 3.1789153354111477e-07
Best accuracy on Test 0.7359050445103857

Source domain: 8, Target domain: 8, Cur_fold 3
Corpus: TOEFL
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-spiece.model HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/minghongxia/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Loading embeddings from: xlnet-base-cased
Model: DIS_Simple Avg Plus Max_Min
Encoder: XLNet
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/minghongxia/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Optimizer: adam
Optimizer: adam
**** Training Begins ****
**** Epoch 0/20 ****
Use CrossEntropyLoss
order_loss: 0.6768500804901123
order_loss: 0.3829924762248993
order_loss: 1.1821913719177246
order_loss: 0.4904722273349762
order_loss: 0.8237486481666565
order_loss: 0.5600483417510986
order_loss: 0.5013865232467651
order_loss: 0.4554463326931
order_loss: 0.6643515825271606
order_loss: 0.42836466431617737
order_loss: 0.4357050657272339
order_loss: 0.24586202204227448
order_loss: 0.7598565816879272
order_loss: 0.6960562467575073
order_loss: 0.1443309783935547
15/33-(0.806)
order_loss: 0.41617104411125183
order_loss: 0.8570966720581055
order_loss: 0.5011306405067444
order_loss: 0.4157056212425232
order_loss: 0.6666238307952881
order_loss: 0.4309028089046478
order_loss: 0.47455134987831116
order_loss: 0.4602851867675781
order_loss: 0.37299785017967224
order_loss: 0.1987794041633606
order_loss: 0.3203403651714325
order_loss: 0.377307265996933
order_loss: 0.22852349281311035
order_loss: 0.44286176562309265
order_loss: 0.33254414796829224
30/33-(1.533)
order_loss: 0.17736278474330902
order_loss: 0.16900566220283508
order_loss: 0.20337338745594025
order_loss: 0.1706380546092987
order_loss: 0.07320090383291245
order_loss: 0.07559024542570114
order_loss: 0.04814177006483078
order_loss: 0.0397404283285141
order_loss: 0.029870452359318733
order_loss: 0.03825978562235832
order_loss: 0.02541312202811241
order_loss: 0.014787256717681885
order_loss: 0.0047794547863304615
order_loss: 0.008249815553426743
order_loss: 0.0033660109620541334
12/33-(0.839)
order_loss: 0.000504553725477308
order_loss: 0.23130007088184357
order_loss: 0.0001693698432063684
order_loss: 0.0003056680434383452
order_loss: 0.0003878951247315854
order_loss: 2.9445631298585795e-05
order_loss: 3.8862340261403006e-06
order_loss: 2.4727625714149326e-05
order_loss: 0.0002529823104850948
order_loss: 0.0005298409960232675
order_loss: 0.00016802389291115105
order_loss: 1.1543625078047626e-05
order_loss: 0.0005359385395422578
order_loss: 0.0007423075730912387
order_loss: 3.34427547454834
27/33-(4.395)
order_loss: 0.0022886355873197317
order_loss: 0.00023691068054176867
order_loss: 0.25634172558784485

=== Evaluating Model ===
accuracy on Valid 0.5400593471810089

Best accuracy on Valid 0.5400593471810089
Total valid loss 1.261585758490996
accuracy on Test 0.5252225519287834
Best accuracy on Test 0.5252225519287834

**** Epoch 0/20 ****
order_loss: 0.08531396836042404
order_loss: 0.0008694868884049356
order_loss: 0.002742495620623231
order_loss: 0.003545976709574461
order_loss: 0.0016225960571318865
order_loss: 0.010055432096123695
order_loss: 0.0009799252729862928
order_loss: 0.0002790723810903728
order_loss: 0.0003454661346040666
order_loss: 0.0008639397565275431
order_loss: 0.00011987541802227497
9/33-(0.763)
order_loss: 0.0005228844820521772
order_loss: 0.00043861777521669865
order_loss: 0.00017663236940279603
order_loss: 0.0003759755636565387
order_loss: 0.00047023920342326164
order_loss: 7.36207512090914e-05
order_loss: 0.00025152310263365507
order_loss: 0.0023943278938531876
order_loss: 0.003564529586583376
order_loss: 0.00016510742716491222
order_loss: 0.00029166036983951926
order_loss: 0.027031008154153824
order_loss: 0.0027041977737098932
order_loss: 0.0002801847003865987
order_loss: 8.94715849426575e-05
24/33-(0.751)
order_loss: 1.0877966815314721e-05
order_loss: 1.617290217836853e-05
order_loss: 0.00012122358748456463
order_loss: 9.04386761249043e-05
order_loss: 3.8686255720676854e-05
order_loss: 2.71206608886132e-05
order_loss: 5.3986550483386964e-05
order_loss: 0.0002641357423271984
order_loss: 0.0021100323647260666
order_loss: 4.599601379595697e-05
order_loss: 8.666197390994057e-05
order_loss: 0.0010365141788497567
order_loss: 1.18870075311861e-05
order_loss: 6.596044840989634e-05
order_loss: 2.2280761186266318e-05
6/33-(0.799)
order_loss: 7.69946418586187e-05
order_loss: 0.0010799963492900133
order_loss: 3.910141094820574e-05
order_loss: 0.001631478313356638
order_loss: 0.001561213401146233
order_loss: 0.0003760689578484744
order_loss: 6.366360321408138e-05
order_loss: 2.2755019017495215e-05
order_loss: 2.069180663966108e-05
order_loss: 6.23493324383162e-05
order_loss: 3.33786783812684e-06
order_loss: 1.953397259057965e-05
order_loss: 2.1790094251628034e-05
order_loss: 6.715490599162877e-06
order_loss: 5.869633605470881e-05
21/33-(0.731)
order_loss: 2.607175338198431e-05
order_loss: 4.869340409641154e-05
order_loss: 4.917901969747618e-05
order_loss: 8.672538569953758e-06
order_loss: 7.88772649684688e-06
order_loss: 0.0002945704909507185

=== Evaluating Model ===
accuracy on Valid 0.6468842729970327

Best accuracy on Valid 0.6468842729970327
Total valid loss 0.7167497832666744
accuracy on Test 0.6617210682492581
Best accuracy on Test 0.6617210682492581

**** Epoch 1/20 ****
order_loss: 9.77527815848589e-06
order_loss: 7.152560215217818e-07
order_loss: 1.2894635801785626e-05
order_loss: 1.7017271602526307e-05
order_loss: 2.3841892016207566e-06
order_loss: 3.336884765303694e-05
order_loss: 1.0916340215771925e-05
order_loss: 2.5461760742473416e-05
order_loss: 2.5041246772161685e-05
3/33-(1.084)
order_loss: 2.1228135665296577e-05
order_loss: 7.053261469991412e-06
order_loss: 3.3900083508342505e-05
order_loss: 3.635996472439729e-05
order_loss: 0.0024735056795179844
order_loss: 0.00015142869960982352
order_loss: 0.00029748730594292283
order_loss: 1.652085302339401e-05
order_loss: 0.00011619297583820298
order_loss: 1.602549855306279e-05
order_loss: 7.331467259064084e-06
order_loss: 0.0017830317374318838
order_loss: 0.00010352645040256903
order_loss: 0.00014502782141789794
order_loss: 4.419977267389186e-05
18/33-(1.069)
order_loss: 2.918374775617849e-05
order_loss: 9.792875061975792e-05
order_loss: 5.2011524530826136e-05
order_loss: 3.5166819998266874e-06
order_loss: 1.0013765859184787e-05
order_loss: 2.769761522358749e-05
order_loss: 8.491536573274061e-05
order_loss: 0.0011268312809988856
order_loss: 7.718854249105789e-06
order_loss: 0.0010386686772108078
order_loss: 9.017226693686098e-05
order_loss: 4.440200427779928e-05
order_loss: 0.0035302825272083282
order_loss: 2.1815867512486875e-05
order_loss: 1.2862818948633503e-05
0/33-(0.644)
order_loss: 3.249538713134825e-05
order_loss: 0.00011381787771824747
order_loss: 5.1543625886552036e-05
order_loss: 1.5676294424338266e-05
order_loss: 5.573070666287094e-06
order_loss: 0.00016589058213867247
order_loss: 0.00036706554237753153
order_loss: 0.0002684302453417331
order_loss: 0.00019167213758919388
order_loss: 6.88691798131913e-05
order_loss: 6.416553515009582e-05
order_loss: 0.00012024898751405999
order_loss: 1.3659550859301817e-05
order_loss: 2.146675979020074e-05
order_loss: 5.424529445008375e-05
15/33-(0.540)
order_loss: 0.0011107457103207707
order_loss: 4.857145177084021e-05
order_loss: 0.0001544394326629117
order_loss: 0.012811129912734032
order_loss: 0.0001428469258826226
order_loss: 6.89364387653768e-05
order_loss: 0.002496486296877265
order_loss: 2.3195569156087004e-05
order_loss: 2.26900665438734e-05

=== Evaluating Model ===
accuracy on Valid 0.6646884272997032

Best accuracy on Valid 0.6646884272997032
Total valid loss 0.7375292100689628
accuracy on Test 0.6439169139465876
Best accuracy on Test 0.6617210682492581

**** Epoch 2/20 ****
order_loss: 1.5747138604638167e-05
order_loss: 0.0001450083655072376
order_loss: 7.152560215217818e-07
order_loss: 3.017575181729626e-05
order_loss: 5.522285937331617e-05
order_loss: 2.5711195121402852e-05
30/33-(0.504)
order_loss: 1.6323416275554337e-05
order_loss: 3.645943070296198e-05
order_loss: 0.0001243531733052805
order_loss: 1.156340294983238e-05
order_loss: 0.00010691460920497775
order_loss: 0.00015185686061158776
order_loss: 1.0955428479064722e-05
order_loss: 4.623729910235852e-05
order_loss: 0.0007083312375470996
order_loss: 3.9581151213496923e-05
order_loss: 6.348241731757298e-05
order_loss: 4.30222753493581e-05
order_loss: 8.07650121714687e-06
order_loss: 4.430917397257872e-05
order_loss: 3.865772669087164e-05
12/33-(0.513)
order_loss: 0.00024261960061267018
order_loss: 1.8775489252220723e-06
order_loss: 7.938429189380258e-05
order_loss: 2.054739888990298e-05
order_loss: 2.538236731197685e-05
order_loss: 5.364475782698719e-06
order_loss: 2.1308715076884255e-06
order_loss: 2.6294950657757e-05
order_loss: 1.3959589523437899e-05
order_loss: 3.1582487281411886e-05
order_loss: 3.058639049413614e-05
order_loss: 0.0003048564540222287
order_loss: 0.0008942958666011691
order_loss: 1.4503814327326836e-06
order_loss: 1.3280146049510222e-05
27/33-(0.509)
order_loss: 3.6646535590989515e-05
order_loss: 4.164271740592085e-05
order_loss: 2.1101041056681424e-05
order_loss: 1.4150422430248e-05
order_loss: 2.7757356292568147e-05
order_loss: 1.9103597878711298e-05
order_loss: 2.3952219635248184e-05
order_loss: 1.3311988368513994e-05
order_loss: 6.854537559775054e-07
order_loss: 1.1265403372817673e-05
order_loss: 3.668290810310282e-05
order_loss: 2.0861628513557662e-07
order_loss: 5.8413183978700545e-06
order_loss: 8.598172826168593e-06
order_loss: 8.523535143467598e-06
9/33-(0.324)
order_loss: 0.0002960223064292222
order_loss: 3.582436329452321e-05
order_loss: 3.115161962341517e-05
order_loss: 2.8922067940584384e-05
order_loss: 2.0012597815366462e-05
order_loss: 2.7419089747127146e-05
order_loss: 3.756324804271571e-05
order_loss: 1.6242516721831635e-05
order_loss: 8.10631081549218e-06
order_loss: 5.9387850342318416e-05
order_loss: 8.612942110630684e-06
order_loss: 6.636031230300432e-06

=== Evaluating Model ===
accuracy on Valid 0.6201780415430267

Total valid loss 0.9366229423745112
accuracy on Test 0.6201780415430267
Best accuracy on Test 0.6617210682492581

**** Epoch 3/20 ****
order_loss: 6.0527770983753726e-05
order_loss: 2.074273652397096e-05
order_loss: 4.378239100333303e-05
24/33-(0.853)
order_loss: 2.4437958927592263e-06
order_loss: 1.013279643302667e-06
order_loss: 0.08632450550794601
order_loss: 5.960466751275817e-07
order_loss: 1.2218962410770473e-06
order_loss: 0.00018481703591533005
order_loss: 5.598428469966166e-05
order_loss: 4.256791726220399e-05
order_loss: 3.6104745959164575e-05
order_loss: 4.64917320641689e-06
order_loss: 6.765167199773714e-06
order_loss: 6.198915798449889e-06
order_loss: 7.713782542850822e-05
order_loss: 1.0848104466276709e-05
6/33-(0.382)
order_loss: 8.652701581013389e-06
order_loss: 6.926103651494486e-06
order_loss: 5.37198648089543e-05
order_loss: 7.45058400752896e-07
order_loss: 1.4680002095701639e-05
order_loss: 7.242352148750797e-05
order_loss: 5.059809154772665e-06
order_loss: 2.2888718376634642e-05
order_loss: 1.1782087312894873e-05
order_loss: 7.366023055510595e-05
order_loss: 6.284121354838135e-06
order_loss: 1.1772104699048214e-05
order_loss: 2.289888470841106e-05
order_loss: 6.973824383749161e-06
order_loss: 5.826387678098399e-06
21/33-(0.401)
order_loss: 6.556570042448584e-06
order_loss: 0.0001526890991954133
order_loss: 0.0005298643372952938
order_loss: 0.0023454581387341022
order_loss: 0.005513652227818966
order_loss: 2.7681109713739716e-05
order_loss: 0.0004259427369106561
order_loss: 5.357832833396969e-06
order_loss: 2.4199564450100297e-06
order_loss: 8.654687917442061e-06
order_loss: 5.835234696860425e-05
order_loss: 0.023381421342492104
order_loss: 1.4447062312683556e-05
order_loss: 9.636187314754352e-06
order_loss: 1.3083538760838564e-05
3/33-(0.415)
order_loss: 5.674433396052336e-06
order_loss: 0.0012669132556766272
order_loss: 5.0664211812545545e-06
order_loss: 2.5034009922819678e-06
order_loss: 1.6558509742026217e-05
order_loss: 8.344830348505639e-06
order_loss: 3.528603656377527e-06
order_loss: 8.136164979077876e-06
order_loss: 4.472199361771345e-05
order_loss: 3.7431932469189633e-06
order_loss: 0.0004960105288773775
order_loss: 4.8910344048636034e-05
order_loss: 1.394772516505327e-05
order_loss: 0.00010011057020165026
order_loss: 7.033372639853042e-06
18/33-(0.450)

=== Evaluating Model ===
accuracy on Valid 0.712166172106825

Best accuracy on Valid 0.712166172106825
Total valid loss 0.7320237227461555
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7210682492581603

**** Epoch 4/20 ****
order_loss: 3.860916694975458e-05
order_loss: 8.923856512410566e-06
order_loss: 5.069647158961743e-05
order_loss: 2.667849366844166e-05
order_loss: 6.00023031438468e-06
order_loss: 9.834781167228357e-07
order_loss: 1.1026868378394283e-06
order_loss: 2.741819344009855e-06
order_loss: 4.601769251166843e-05
order_loss: 3.087673394475132e-05
order_loss: 1.3542538908950519e-05
order_loss: 8.027131843846291e-05
order_loss: 4.768372718899627e-07
order_loss: 2.3454995243810117e-05
0/33-(0.548)
order_loss: 2.2571126464754343e-05
order_loss: 8.828310819808394e-05
order_loss: 1.4734558135387488e-05
order_loss: 4.8224050260614604e-05
order_loss: 5.773204975412227e-06
order_loss: 3.913214459316805e-05
order_loss: 1.585509926371742e-05
order_loss: 3.768647002289072e-05
order_loss: 1.3500699424184859e-05
order_loss: 0.00013148284051567316
order_loss: 7.291750080185011e-06
order_loss: 2.3783011783962138e-05
order_loss: 0.019064754247665405
order_loss: 0.0005487393354997039
order_loss: 2.7418222998676356e-06
15/33-(0.543)
order_loss: 0.0002379464276600629
order_loss: 1.5342526239692234e-05
order_loss: 1.4221991477825213e-05
order_loss: 3.415572427911684e-05
order_loss: 7.854055002098903e-05
order_loss: 0.0009695006883703172
order_loss: 6.34794514553505e-06
order_loss: 3.540173565852456e-05
order_loss: 0.0001776387944119051
order_loss: 7.438725333486218e-06
order_loss: 4.39587392975227e-06
order_loss: 0.0001522417296655476
order_loss: 1.521427657280583e-05
order_loss: 0.0005575339309871197
order_loss: 0.00026984920259565115
30/33-(0.600)
order_loss: 1.0728841743912199e-06
order_loss: 3.913295586244203e-05
order_loss: 1.2040163710480556e-06
order_loss: 2.1100266167195514e-05
order_loss: 1.075882937584538e-05
order_loss: 3.218665369786322e-06
order_loss: 3.343876596773043e-05
order_loss: 1.5545072528766468e-05
order_loss: 1.0168683729716577e-05
order_loss: 1.195688219013391e-05
order_loss: 7.152561920520384e-07
order_loss: 2.3841905658628093e-06
order_loss: 1.1488941709103528e-05
order_loss: 6.525620847241953e-05
order_loss: 6.696815398754552e-05
12/33-(0.695)
order_loss: 2.5392377210664563e-05
order_loss: 0.0013178326189517975
order_loss: 1.6689315316398279e-06

=== Evaluating Model ===
accuracy on Valid 0.6973293768545994

Total valid loss 0.7782892449335619
accuracy on Test 0.6528189910979229
Best accuracy on Test 0.7210682492581603

**** Epoch 5/20 ****
order_loss: 8.473174966638908e-05
order_loss: 1.2159612197137903e-05
order_loss: 1.1126378012704663e-05
order_loss: 2.278477950312663e-05
order_loss: 0.0027295206673443317
order_loss: 4.7223515139194205e-05
order_loss: 5.9624770074151456e-05
order_loss: 2.0861705252173124e-06
order_loss: 3.943003321182914e-05
order_loss: 6.767785816919059e-05
27/33-(0.668)
order_loss: 1.7404941900167614e-05
order_loss: 6.250505248317495e-05
order_loss: 2.5705241569085047e-05
order_loss: 2.074280200758949e-05
order_loss: 2.4617151211714372e-05
order_loss: 1.1041877769457642e-05
order_loss: 7.74860836827429e-07
order_loss: 1.4861593626847025e-05
order_loss: 2.0653546016546898e-05
order_loss: 5.334642537491163e-06
order_loss: 9.352473716717213e-05
order_loss: 1.9967590105807176e-06
order_loss: 4.498845009948127e-05
order_loss: 1.6689314179529902e-06
9/33-(0.522)
order_loss: 2.690735300348024e-06
order_loss: 0.00011221828026464209
order_loss: 1.0013677638198715e-05
order_loss: 2.622666215756908e-05
order_loss: 7.152560215217818e-07
order_loss: 4.1506773413857445e-05
order_loss: 3.1308190955314785e-05
order_loss: 2.3603854060638696e-05
order_loss: 0.00014717008161824197
order_loss: 0.005161655601114035
order_loss: 3.6808538425248116e-05
order_loss: 2.5033982637978625e-06
order_loss: 9.735438197822077e-07
order_loss: 7.126118816813687e-06
order_loss: 4.179656025371514e-05
24/33-(0.449)
order_loss: 4.798470763489604e-05
order_loss: 1.1036949217668734e-05
order_loss: 5.453851372294594e-06
order_loss: 1.7226037016371265e-05
order_loss: 7.791198004269972e-05
order_loss: 4.768373287333816e-07
order_loss: 0.00013341297744773328
order_loss: 1.5259134670486674e-05
order_loss: 7.251957413245691e-06
order_loss: 6.271351594477892e-05
order_loss: 1.9051698473049328e-05
order_loss: 4.0847186028258875e-05
order_loss: 3.973644595589576e-07
order_loss: 7.254833690240048e-06
6/33-(1.024)
order_loss: 3.3974749840126606e-06
order_loss: 9.068495273822919e-06
order_loss: 3.963736617151881e-06
order_loss: 0.00014009844744578004
order_loss: 3.576279254957626e-07
order_loss: 5.563128070207313e-06

=== Evaluating Model ===
accuracy on Valid 0.6735905044510386

Total valid loss 0.7689093148166483
accuracy on Test 0.6646884272997032
Best accuracy on Test 0.7210682492581603

**** Epoch 6/20 ****
order_loss: 1.6093289332275162e-06
order_loss: 5.930702627665596e-06
order_loss: 0.03250162675976753
order_loss: 4.358662408776581e-05
order_loss: 2.5619339794502594e-05
order_loss: 4.231938873999752e-06
order_loss: 2.8034817660227418e-05
order_loss: 3.178915619628242e-07
21/33-(0.787)
order_loss: 7.748608936708479e-07
order_loss: 3.7939615140203387e-05
order_loss: 7.102378731360659e-05
order_loss: 1.2171406524430495e-05
order_loss: 3.278269559814362e-06
order_loss: 0.0001226984750246629
order_loss: 6.519397720694542e-05
order_loss: 9.83477548288647e-07
order_loss: 3.5762795391747204e-07
order_loss: 5.4836673371028155e-06
order_loss: 1.3566374946094584e-05
order_loss: 8.404290383623447e-06
order_loss: 3.069760714424774e-05
3/33-(0.588)
order_loss: 0.0007136029307730496
order_loss: 6.735551869496703e-05
order_loss: 7.03259211149998e-05
order_loss: 0.00018735494813881814
order_loss: 2.3841860752327193e-07
order_loss: 3.12734191538766e-05
order_loss: 1.9212791812606156e-05
order_loss: 4.539099245448597e-05
order_loss: 1.4722834748681635e-05
order_loss: 1.0013725841417909e-05
order_loss: 1.6868256352609023e-05
order_loss: 2.300837149959989e-05
order_loss: 6.786219455534592e-05
order_loss: 3.278260919614695e-06
18/33-(0.163)
order_loss: 2.76271857728716e-05
order_loss: 0.00017551011114846915
order_loss: 5.692289960279595e-06
order_loss: 7.748610073576856e-07
order_loss: 5.143089310877258e-06
order_loss: 3.886232207150897e-06
order_loss: 1.3113030945532955e-06
order_loss: 9.820313425734639e-05
order_loss: 1.83586344064679e-05
order_loss: 8.079891267698258e-05
order_loss: 2.6822095833267667e-07
order_loss: 1.2516983360910672e-06
order_loss: 5.51868652109988e-05
order_loss: 4.613665078068152e-05
0/33-(1.058)
order_loss: 5.424037226475775e-06
order_loss: 1.1920930376163597e-07
order_loss: 9.53683593252208e-06
order_loss: 5.3197654779069126e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.285511734749889e-05
order_loss: 2.5082183128688484e-05
order_loss: 1.367947697872296e-05
order_loss: 7.510213436034974e-06

=== Evaluating Model ===
accuracy on Valid 0.6824925816023739

Total valid loss 0.7262689010663466
accuracy on Test 0.6795252225519288
Best accuracy on Test 0.7210682492581603

**** Epoch 7/20 ****
order_loss: 4.84962911286857e-05
order_loss: 0.00023429647262673825
order_loss: 1.5449810234713368e-05
order_loss: 2.2620444724452682e-05
order_loss: 9.951555693987757e-05
15/33-(0.850)
order_loss: 7.943296077428386e-05
order_loss: 9.179172593576368e-06
order_loss: 2.35297811741475e-05
order_loss: 1.9252485799370334e-05
order_loss: 2.086165295622777e-06
order_loss: 5.364419735087722e-07
order_loss: 3.5762877814704552e-06
order_loss: 7.581792488053907e-06
order_loss: 8.524107397533953e-05
order_loss: 3.76516800315585e-05
order_loss: 2.8894048227812164e-05
order_loss: 2.008707815548405e-05
order_loss: 0.00012440804857760668
order_loss: 0.0002036807272816077
30/33-(0.413)
order_loss: 3.8883572415215895e-05
order_loss: 4.246012758812867e-05
order_loss: 1.4603157296733116e-06
order_loss: 7.215706136776134e-05
order_loss: 0.0012179287150502205
order_loss: 1.668931872700341e-06
order_loss: 6.7949526965094265e-06
order_loss: 0.00011140728747704998
order_loss: 3.2664269383531064e-05
order_loss: 3.3737916965037584e-05
order_loss: 1.788139627478813e-07
order_loss: 6.457199560827576e-06
order_loss: 4.544887815427501e-06
12/33-(0.444)
order_loss: 5.034935020375997e-05
order_loss: 1.1098493814643007e-05
order_loss: 9.507009053777438e-06
order_loss: 5.0963270041393116e-05
order_loss: 1.2070078810211271e-05
order_loss: 8.404342224821448e-06
order_loss: 2.3841860752327193e-07
order_loss: 5.0620888941921294e-05
order_loss: 2.607707301649498e-06
order_loss: 2.6623497433320154e-06
order_loss: 1.8656428437680006e-05
order_loss: 4.1128048906102777e-05
order_loss: 2.98023678624304e-06
order_loss: 5.06421311001759e-05
order_loss: 4.6491832108586095e-06
27/33-(0.526)
order_loss: 5.2156115998513997e-05
order_loss: 5.1404738769633695e-05
order_loss: 3.531739639583975e-05
order_loss: 5.94560196987004e-06
order_loss: 3.673812898341566e-05
order_loss: 3.7908746435277862e-06
order_loss: 6.357833512993238e-07
order_loss: 2.965340627270052e-06
order_loss: 0.00011760687630157918
order_loss: 3.5507578104443382e-06
order_loss: 9.536747711536009e-07
order_loss: 6.676132761640474e-05

=== Evaluating Model ===
accuracy on Valid 0.7062314540059347

Total valid loss 0.7762317603284662
accuracy on Test 0.712166172106825
Best accuracy on Test 0.7210682492581603

**** Epoch 8/20 ****
order_loss: 2.5034310965565965e-05
order_loss: 3.57628505298635e-06
order_loss: 2.157734525098931e-05
9/33-(0.553)
order_loss: 8.368638191313948e-06
order_loss: 4.9273407967120875e-06
order_loss: 4.1723265553628153e-07
order_loss: 2.9802417884639e-06
order_loss: 4.005633672932163e-05
order_loss: 5.7816673688648734e-06
order_loss: 4.413917849888094e-05
order_loss: 1.0430818520035245e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1622925057963585e-06
order_loss: 3.059711616515415e-06
order_loss: 9.751380275702104e-06
order_loss: 5.960466751275817e-07
24/33-(1.025)
order_loss: 2.8411648145265644e-06
order_loss: 3.411485522519797e-05
order_loss: 1.4901177110004937e-06
order_loss: 5.409166533354437e-06
order_loss: 6.6161674112663604e-06
order_loss: 3.0325079933390953e-05
order_loss: 4.49023855253472e-06
order_loss: 2.9147096938686445e-05
order_loss: 9.23872676139581e-07
order_loss: 2.8163985916762613e-05
order_loss: 8.344656521330762e-07
order_loss: 2.300792039022781e-05
order_loss: 4.1723259869286267e-07
6/33-(0.202)
order_loss: 7.569818535557715e-06
order_loss: 1.2069963304384146e-06
order_loss: 4.1723265553628153e-07
order_loss: 2.4080893126665615e-05
order_loss: 4.57775458926335e-05
order_loss: 2.9773174901492894e-05
order_loss: 6.556513199029723e-07
order_loss: 9.954059351002797e-06
order_loss: 7.1227959779207595e-06
order_loss: 6.67019048705697e-05
order_loss: 9.698757639853284e-05
order_loss: 4.1723259869286267e-07
order_loss: 0.0012462751474231482
order_loss: 8.654707016830798e-06
21/33-(0.593)
order_loss: 1.0629632015479729e-05
order_loss: 1.6093276826723013e-06
order_loss: 2.5705541702336632e-05
order_loss: 2.9206350973254303e-06
order_loss: 6.19893171460717e-06
order_loss: 0.000349701993400231
order_loss: 3.8684789615217596e-05
order_loss: 2.357402627239935e-05
order_loss: 7.152561920520384e-07
order_loss: 7.140681645978475e-06
order_loss: 1.49011839312152e-06
order_loss: 1.0728893357736524e-05
order_loss: 7.3910559876821935e-06
order_loss: 1.0887861208175309e-05
order_loss: 3.1830379157327116e-05
3/33-(0.683)

=== Evaluating Model ===
accuracy on Valid 0.7299703264094956

Best accuracy on Valid 0.7299703264094956
Total valid loss 0.7177115028554742
accuracy on Test 0.6913946587537092
Best accuracy on Test 0.7210682492581603

**** Epoch 9/20 ****
order_loss: 9.031151421368122e-05
order_loss: 9.024316568684299e-06
order_loss: 1.96998989849817e-05
order_loss: 7.126026321202517e-05
order_loss: 4.5696913275605766e-07
order_loss: 4.053129487147089e-06
order_loss: 1.7524069335195236e-05
order_loss: 7.42571719456464e-05
order_loss: 9.298368240706623e-06
order_loss: 1.0714061318140011e-05
order_loss: 3.195004683220759e-05
order_loss: 2.2888264084031107e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.4538595577469096e-06
18/33-(0.416)
order_loss: 6.318146006378811e-06
order_loss: 5.424037226475775e-06
order_loss: 1.8179442804466817e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.023326710012043e-06
order_loss: 4.1723259869286267e-07
order_loss: 4.726936458609998e-05
order_loss: 9.815037628868595e-06
order_loss: 1.0669344192137942e-05
order_loss: 2.0921788745908998e-05
order_loss: 9.338072004538844e-07
order_loss: 5.364446224120911e-06
order_loss: 4.321339019952575e-07
order_loss: 5.632668035104871e-06
0/33-(0.164)
order_loss: 2.3841860752327193e-07
order_loss: 1.6987538401735947e-05
order_loss: 1.5139877177716698e-05
order_loss: 3.7153636185394134e-06
order_loss: 1.3917799151386134e-05
order_loss: 7.367665239144117e-05
order_loss: 9.596428753866348e-06
order_loss: 9.467403287999332e-06
order_loss: 1.041905034071533e-05
order_loss: 4.768382950715022e-06
order_loss: 1.8954617189592682e-05
order_loss: 1.9073504518019035e-06
order_loss: 2.3245863758347696e-06
order_loss: 4.093077950528823e-05
15/33-(0.182)
order_loss: 4.837948836211581e-06
order_loss: 0.00021610100520774722
order_loss: 6.392649993358646e-06
order_loss: 1.1190995792276226e-05
order_loss: 7.311559784284327e-06
order_loss: 4.529963462118758e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.112733222427778e-06
order_loss: 0.00011147230543429032
order_loss: 2.0698427761089988e-05
order_loss: 1.6913165381993167e-05
order_loss: 5.960464477539063e-08
order_loss: 6.953878255444579e-07
order_loss: 4.112733677175129e-06
order_loss: 1.9868217293605994e-07
30/33-(0.586)
order_loss: 3.7948407225485425e-06
order_loss: 3.814704541582614e-06
order_loss: 6.496927198895719e-06

=== Evaluating Model ===
accuracy on Valid 0.7210682492581603

Total valid loss 0.6410327499563043
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7210682492581603

**** Epoch 10/20 ****
order_loss: 2.0265599687263602e-06
order_loss: 6.824777756264666e-06
order_loss: 0.00010738724085967988
order_loss: 0.01902857795357704
order_loss: 3.3180056107084965e-06
order_loss: 8.88113117980538e-06
order_loss: 1.0132799843631801e-06
order_loss: 1.2636195378945558e-06
order_loss: 3.0636952033091802e-06
12/33-(0.748)
order_loss: 8.940701263782103e-07
order_loss: 3.1789153354111477e-07
order_loss: 7.2717975854175165e-06
order_loss: 5.245234206086025e-06
order_loss: 2.0861648408754263e-06
order_loss: 3.576279254957626e-07
order_loss: 2.0325391233200207e-05
order_loss: 5.960464477539063e-08
order_loss: 3.175070014549419e-05
order_loss: 3.4570828120195074e-06
order_loss: 4.669033160098479e-07
order_loss: 8.344653679159819e-07
order_loss: 3.159060042889905e-06
order_loss: 2.7418175250204513e-06
order_loss: 7.748607231405913e-07
27/33-(0.317)
order_loss: 6.556513199029723e-07
order_loss: 5.960464477539063e-08
order_loss: 1.9868243725795764e-06
order_loss: 1.4543556972057559e-06
order_loss: 6.556513199029723e-07
order_loss: 2.5977180484915152e-05
order_loss: 4.2915362996609474e-07
order_loss: 2.3841860752327193e-07
order_loss: 2.1159680727578234e-06
order_loss: 5.722048967982118e-07
order_loss: 0.0002608521608635783
order_loss: 1.788139627478813e-07
order_loss: 5.722106834582519e-06
9/33-(0.128)
order_loss: 5.736972980230348e-06
order_loss: 7.62940203458129e-07
order_loss: 5.960466182841628e-07
order_loss: 1.2481458725233097e-05
order_loss: 8.344653679159819e-07
order_loss: 7.152560215217818e-07
order_loss: 1.464816705265548e-05
order_loss: 6.357831807690673e-07
order_loss: 9.343148121843114e-06
order_loss: 4.768373287333816e-07
order_loss: 5.364420303521911e-07
order_loss: 2.4735986698942725e-06
order_loss: 2.8371957796480274e-06
order_loss: 3.8743036157029564e-07
order_loss: 2.0265615603420883e-06
24/33-(0.325)
order_loss: 2.801423306664219e-06
order_loss: 1.943114739333396e-06
order_loss: 1.708668605715502e-06
order_loss: 3.844573438982479e-05
order_loss: 3.5564280551625416e-06
order_loss: 3.31710725731682e-05

=== Evaluating Model ===
accuracy on Valid 0.6735905044510386

Total valid loss 1.0928478755734183
accuracy on Test 0.6528189910979229
Best accuracy on Test 0.7210682492581603

**** Epoch 11/20 ****
order_loss: 1.3351529560168274e-05
order_loss: 5.066419817012502e-06
order_loss: 1.326205165241845e-06
order_loss: 2.503395535313757e-07
order_loss: 1.4305131799119408e-06
order_loss: 2.2451185941463336e-06
order_loss: 5.394248091761256e-06
order_loss: 0.0006133986171334982
order_loss: 0.0002106406755046919
6/33-(0.852)
order_loss: 1.6045984011725523e-05
order_loss: 3.874303047268768e-07
order_loss: 3.844511866191169e-06
order_loss: 1.1920930376163597e-07
order_loss: 0.00013701760326512158
order_loss: 4.670133057516068e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.98023280720372e-07
order_loss: 1.0907923751801718e-05
order_loss: 2.0662994302256266e-06
order_loss: 3.3974743018916342e-06
order_loss: 2.3841860752327193e-07
21/33-(0.330)
order_loss: 1.6689344874976086e-06
order_loss: 1.6570135130677954e-06
order_loss: 3.5762798233918147e-07
order_loss: 0.003314564935863018
order_loss: 2.052444870059844e-05
order_loss: 1.2815158697776496e-05
order_loss: 1.6093266594907618e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.907466973236296e-06
order_loss: 7.152559646783629e-07
order_loss: 9.536749985272763e-07
order_loss: 1.3709100130654406e-06
order_loss: 4.1723259869286267e-07
order_loss: 1.7359902813041117e-06
order_loss: 1.1920930376163597e-07
3/33-(0.211)
order_loss: 2.3245838747243397e-06
order_loss: 2.98023280720372e-07
order_loss: 1.2318305380176753e-06
order_loss: 4.768372718899627e-07
order_loss: 3.576290737328236e-06
order_loss: 2.5391725557710743e-06
order_loss: 2.9007687771809287e-06
order_loss: 2.6822095833267667e-07
order_loss: 8.940702969084668e-07
order_loss: 8.687248919159174e-05
order_loss: 2.76168748314376e-06
order_loss: 1.788139627478813e-07
order_loss: 2.5033982637978625e-06
order_loss: 2.046429017354967e-06
order_loss: 2.98023280720372e-07
18/33-(0.398)
order_loss: 8.940700695347914e-07
order_loss: 1.4603169802285265e-06
order_loss: 1.589459657225234e-06
order_loss: 5.960464477539063e-08
order_loss: 4.768372718899627e-07
order_loss: 1.2218974916322622e-06
order_loss: 1.768309812177904e-05
order_loss: 1.2557083209685516e-05

=== Evaluating Model ===
accuracy on Valid 0.6439169139465876

Total valid loss 0.9529672596942295
accuracy on Test 0.6498516320474778
Best accuracy on Test 0.7210682492581603

**** Epoch 12/20 ****
order_loss: 4.6730428948649205e-06
order_loss: 2.106033207383007e-06
order_loss: 2.980233091420814e-07
order_loss: 1.0728844017648953e-06
order_loss: 2.3365293600363657e-05
order_loss: 4.559772150969366e-06
0/33-(1.151)
order_loss: 3.397477257749415e-06
order_loss: 5.543247425521258e-06
order_loss: 1.1920930376163597e-07
order_loss: 8.94069742685133e-08
order_loss: 6.599098560400307e-05
order_loss: 2.98023280720372e-07
order_loss: 1.6331714505213313e-06
order_loss: 2.8610309072973905e-06
order_loss: 3.3378611874468334e-07
order_loss: 1.624230435481877e-06
order_loss: 4.1723268395799096e-07
order_loss: 1.1920930376163597e-07
15/33-(0.241)
order_loss: 2.4437933916487964e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.53319797138829e-07
order_loss: 2.5014944185386412e-05
order_loss: 4.18847739638295e-05
order_loss: 6.556513199029723e-07
order_loss: 2.3841860752327193e-07
order_loss: 7.450585144397337e-07
order_loss: 2.18550411545948e-07
order_loss: 9.238727898264187e-07
order_loss: 1.817944166759844e-06
order_loss: 1.0728841743912199e-06
order_loss: 2.3841860752327193e-07
30/33-(0.708)
order_loss: 3.695494797284482e-06
order_loss: 1.102687406273617e-06
order_loss: 5.960466182841628e-07
order_loss: 2.980245881190058e-06
order_loss: 1.3868151654605754e-05
order_loss: 6.109480636951048e-07
order_loss: 4.967055815541244e-07
order_loss: 1.5348225588240894e-06
order_loss: 4.4256585169932805e-06
order_loss: 2.98023280720372e-07
order_loss: 2.920631914093974e-06
order_loss: 2.8809015475417254e-06
order_loss: 5.364419735087722e-07
12/33-(0.341)
order_loss: 4.053124484926229e-06
order_loss: 3.8147113627928775e-06
order_loss: 2.2351789539243327e-06
order_loss: 9.775256330613047e-06
order_loss: 3.4272684956704325e-07
order_loss: 2.344453150726622e-06
order_loss: 6.775124347768724e-06
order_loss: 5.364419166653533e-07
order_loss: 1.1722446288331412e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.0861648408754263e-06

=== Evaluating Model ===
accuracy on Valid 0.7151335311572701

Total valid loss 0.7883902964266863
accuracy on Test 0.6913946587537092
Best accuracy on Test 0.7210682492581603

**** Epoch 13/20 ****
order_loss: 9.53675112214114e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.206995762004226e-06
27/33-(0.284)
order_loss: 1.326204710494494e-06
order_loss: 2.7418236641096883e-06
order_loss: 1.2119628536311211e-06
order_loss: 6.059859060769668e-06
order_loss: 2.324584556845366e-06
order_loss: 3.6656974771176465e-06
order_loss: 3.445260153966956e-05
order_loss: 1.0728854249464348e-06
order_loss: 4.768372718899627e-07
order_loss: 1.788139627478813e-07
order_loss: 7.152560215217818e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.6027879357570782e-05
9/33-(0.476)
order_loss: 7.1824110818852205e-06
order_loss: 3.6955002542526927e-06
order_loss: 2.622607780722319e-06
order_loss: 6.556513199029723e-07
order_loss: 8.94069742685133e-08
order_loss: 1.4960877706471365e-05
order_loss: 1.3907752816066932e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.894190740538761e-06
order_loss: 2.7815505632133863e-07
order_loss: 2.8808979095629184e-06
24/33-(0.253)
order_loss: 1.5894573834884795e-07
order_loss: 4.529955219823023e-07
order_loss: 4.768372718899627e-07
order_loss: 3.576279254957626e-07
order_loss: 4.947208708472317e-06
order_loss: 1.2636199926419067e-06
order_loss: 7.903642654127907e-06
order_loss: 4.768373287333816e-07
order_loss: 5.165737775314483e-07
order_loss: 7.927449587441515e-06
order_loss: 2.980233091420814e-07
order_loss: 9.934108646802997e-08
order_loss: 7.748609505142667e-07
order_loss: 3.278260919614695e-06
order_loss: 1.4156120187180932e-06
6/33-(0.515)
order_loss: 2.98023678624304e-06
order_loss: 4.027727118227631e-05
order_loss: 5.960464477539063e-08
order_loss: 1.3093386769469362e-05
order_loss: 1.1920930376163597e-07
order_loss: 4.380959580885246e-06
order_loss: 1.0401068720966578e-05
order_loss: 6.172090797917917e-05
order_loss: 5.364420303521911e-07
order_loss: 2.413991069261101e-06
order_loss: 4.1723259869286267e-07
order_loss: 1.341106553809368e-06
order_loss: 7.351251269938075e-07
order_loss: 1.4901162614933128e-07
21/33-(0.095)

=== Evaluating Model ===
accuracy on Valid 0.7062314540059347

Total valid loss 0.8298886282877489
accuracy on Test 0.7151335311572701
Best accuracy on Test 0.7210682492581603

**** Epoch 14/20 ****
order_loss: 5.960466182841628e-07
order_loss: 4.5001611397310626e-06
order_loss: 7.351242743425246e-07
order_loss: 1.9073534076596843e-06
order_loss: 1.0331484645575983e-06
order_loss: 4.788252681464655e-06
order_loss: 1.0863133866223507e-05
order_loss: 4.768372718899627e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.788139627478813e-07
3/33-(0.242)
order_loss: 3.576279254957626e-07
order_loss: 1.390775139498146e-07
order_loss: 3.9082613511709496e-05
order_loss: 4.7683934099040926e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.410753263073275e-06
order_loss: 7.947286206899662e-08
order_loss: 2.0861628513557662e-07
order_loss: 1.788139485370266e-07
order_loss: 2.622616420921986e-06
order_loss: 7.152564762691327e-07
order_loss: 6.556570497195935e-06
order_loss: 1.1920930376163597e-07
18/33-(0.289)
order_loss: 1.1523578677952173e-06
order_loss: 1.3411060990620172e-06
order_loss: 3.1590534490533173e-06
order_loss: 4.172327123797004e-07
order_loss: 6.258491112021147e-07
order_loss: 2.98023280720372e-07
order_loss: 4.434608399606077e-06
order_loss: 1.2318303106439998e-06
order_loss: 0.0003699827357195318
order_loss: 1.6689314179529902e-06
order_loss: 1.7434387018511188e-06
order_loss: 4.768373287333816e-07
order_loss: 3.874303047268768e-07
order_loss: 2.205375949415611e-06
order_loss: 5.960467888144194e-07
0/33-(0.262)
order_loss: 1.4901162614933128e-07
order_loss: 5.5134587455540895e-06
order_loss: 2.3245838747243397e-06
order_loss: 7.569834451714996e-06
order_loss: 8.94069742685133e-08
order_loss: 3.7252914353302913e-07
order_loss: 2.2053761767892865e-06
order_loss: 6.506921636173502e-06
order_loss: 2.7120170216221595e-06
order_loss: 3.0280527425929904e-05
order_loss: 1.1920930376163597e-07
order_loss: 0.00025916838785633445
order_loss: 2.4139912966347765e-06
order_loss: 7.256940989464056e-06
order_loss: 3.427268211453338e-07
15/33-(0.225)
order_loss: 4.64917320641689e-06
order_loss: 1.1920930376163597e-07

=== Evaluating Model ===
accuracy on Valid 0.6142433234421365

Total valid loss 1.2437782660126686
accuracy on Test 0.5964391691394659
Best accuracy on Test 0.7210682492581603

**** Epoch 15/20 ****
order_loss: 3.178915619628242e-07
order_loss: 3.973644595589576e-07
order_loss: 4.410745475524891e-07
order_loss: 5.324701760400785e-06
order_loss: 8.94070240065048e-07
order_loss: 2.6226130103168543e-06
order_loss: 7.23207358532818e-06
order_loss: 8.344656521330762e-07
order_loss: 3.516680180837284e-06
order_loss: 4.1723265553628153e-07
order_loss: 2.4437933916487964e-06
order_loss: 1.0430993825139012e-05
30/33-(0.417)
order_loss: 4.828018518310273e-06
order_loss: 3.5166840461897664e-06
order_loss: 1.156341841124231e-05
order_loss: 1.3709252925764304e-05
order_loss: 1.9073668227065355e-05
order_loss: 1.0192496119998395e-05
order_loss: 3.099446303167497e-06
order_loss: 1.3560074876295403e-06
order_loss: 5.960464477539063e-08
order_loss: 5.513434189197142e-07
order_loss: 2.245113591925474e-06
order_loss: 9.934121862897882e-07
order_loss: 6.55655276204925e-06
12/33-(0.414)
order_loss: 8.94069742685133e-08
order_loss: 8.245314120358671e-07
order_loss: 3.427268211453338e-07
order_loss: 7.778466169838794e-06
order_loss: 6.675724648630421e-07
order_loss: 1.2516990182120935e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.622607780722319e-06
order_loss: 1.3907752816066932e-07
order_loss: 9.387741783939418e-07
order_loss: 7.510213436034974e-06
order_loss: 1.6093276826723013e-06
order_loss: 3.5762795391747204e-07
order_loss: 3.645830247478443e-06
order_loss: 9.179157132166438e-06
27/33-(0.050)
order_loss: 2.3841860752327193e-07
order_loss: 0.00019547482952475548
order_loss: 8.940700695347914e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.768373287333816e-07
order_loss: 5.960464477539063e-08
order_loss: 2.3841860752327193e-07
order_loss: 1.0579838090052363e-06
order_loss: 1.2993979908060282e-05
order_loss: 3.337860903229739e-07
order_loss: 2.3643224267289042e-06
order_loss: 2.339490038139047e-06
9/33-(0.105)
order_loss: 6.357833512993238e-07
order_loss: 7.867874046496581e-06
order_loss: 4.172333774477011e-06
order_loss: 2.6822095833267667e-07
order_loss: 4.231938873999752e-06

=== Evaluating Model ===
accuracy on Valid 0.6824925816023739

Total valid loss 1.1847900626334278
accuracy on Test 0.6735905044510386
Best accuracy on Test 0.7210682492581603

**** Epoch 16/20 ****
order_loss: 2.3841860752327193e-07
order_loss: 1.013280439110531e-06
order_loss: 8.046630455282866e-07
order_loss: 6.516817848023493e-06
order_loss: 1.698733967714361e-06
order_loss: 1.6987341950880364e-06
order_loss: 1.1920930376163597e-07
24/33-(0.079)
order_loss: 8.94069742685133e-08
order_loss: 1.8477488765711314e-06
order_loss: 1.5795251329109306e-06
order_loss: 8.89614693733165e-06
order_loss: 1.7583425915290718e-06
order_loss: 1.1026868378394283e-06
order_loss: 4.1127309486910235e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.443795665385551e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.3411060990620172e-06
order_loss: 1.8278803963767132e-06
order_loss: 3.706542702275328e-05
6/33-(0.482)
order_loss: 1.1126207937195431e-06
order_loss: 3.417349034862127e-06
order_loss: 1.4901162614933128e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.1324891602271236e-06
order_loss: 1.4901162614933128e-07
order_loss: 5.960464477539063e-08
order_loss: 1.788139627478813e-07
order_loss: 5.6624726312293205e-06
order_loss: 1.3907774700783193e-06
order_loss: 3.5762803918260033e-07
order_loss: 6.556516609634855e-07
order_loss: 5.622729986498598e-06
order_loss: 1.1026868378394283e-06
21/33-(0.165)
order_loss: 1.4305140894066426e-06
order_loss: 3.5762795391747204e-07
order_loss: 4.494210315897362e-06
order_loss: 3.904118784703314e-06
order_loss: 5.761786496805144e-07
order_loss: 1.7750893675838597e-05
order_loss: 1.788139627478813e-07
order_loss: 1.9490977138048038e-05
order_loss: 5.453873200167436e-06
order_loss: 6.25848997515277e-07
order_loss: 3.2186644602916203e-06
order_loss: 1.9868217293605994e-07
order_loss: 6.7155228862247895e-06
3/33-(0.626)
order_loss: 2.831229039657046e-06
order_loss: 8.79169192558038e-07
order_loss: 1.1920930376163597e-07
order_loss: 2.065328590106219e-05
order_loss: 5.096222594147548e-06
order_loss: 2.98023280720372e-07
order_loss: 3.4868778584495885e-06
order_loss: 8.046716175158508e-06
order_loss: 2.98023280720372e-07

=== Evaluating Model ===
accuracy on Valid 0.6528189910979229

Total valid loss 1.13626489314166
accuracy on Test 0.6765578635014837
Best accuracy on Test 0.7210682492581603

**** Epoch 17/20 ****
order_loss: 8.195704140234739e-06
order_loss: 7.152560215217818e-07
order_loss: 2.5034014470293187e-06
order_loss: 2.98023280720372e-07
order_loss: 2.3841860752327193e-07
order_loss: 3.278256031080673e-07
18/33-(0.207)
order_loss: 2.5332035420433385e-06
order_loss: 1.1920936913156766e-06
order_loss: 5.018735009798547e-06
order_loss: 5.185617737879511e-06
order_loss: 1.1523574130478664e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.788139485370266e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.771776613983093e-06
order_loss: 1.0460711564519443e-05
order_loss: 1.19209551030508e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.4156119050312554e-06
order_loss: 6.556513199029723e-07
order_loss: 4.073006948601687e-06
0/33-(0.341)
order_loss: 1.1920930376163597e-07
order_loss: 4.470349495022674e-07
order_loss: 1.6093266594907618e-06
order_loss: 5.662443527398864e-07
order_loss: 3.993526661361102e-06
order_loss: 3.874303047268768e-07
order_loss: 2.7716223485185765e-06
order_loss: 3.36768289344036e-06
order_loss: 5.841258712280251e-07
order_loss: 1.1324891602271236e-06
order_loss: 1.1166252079419792e-05
order_loss: 3.0528604838764295e-05
order_loss: 6.25848997515277e-07
15/33-(0.544)
order_loss: 1.147391230915673e-06
order_loss: 6.854537559775054e-07
order_loss: 3.218656047465629e-06
order_loss: 6.288348686211975e-06
order_loss: 7.748667485429905e-06
order_loss: 5.67737470191787e-06
order_loss: 6.556515472766478e-07
order_loss: 2.086167796733207e-06
order_loss: 4.410759629536187e-06
order_loss: 1.1920930376163597e-07
order_loss: 9.934115041687619e-07
order_loss: 2.42000533035025e-05
order_loss: 1.1920930376163597e-07
30/33-(0.191)
order_loss: 2.980233091420814e-07
order_loss: 1.1265462489973288e-05
order_loss: 2.0563643374771345e-06
order_loss: 4.9471991587779485e-06
order_loss: 1.3907776974519948e-06
order_loss: 3.844509592454415e-06
order_loss: 7.927449587441515e-06
order_loss: 7.301575237761426e-07
order_loss: 1.8000642967308522e-06
order_loss: 8.821499477562611e-07
order_loss: 2.4040618882281706e-06
order_loss: 5.960464477539063e-08

=== Evaluating Model ===
accuracy on Valid 0.7062314540059347

Total valid loss 0.8521104380488396
accuracy on Test 0.6973293768545994
Best accuracy on Test 0.7210682492581603

**** Epoch 18/20 ****
order_loss: 9.139384928857908e-07
order_loss: 1.2516983360910672e-06
12/33-(0.575)
order_loss: 3.973644595589576e-07
order_loss: 3.3974704365391517e-06
order_loss: 3.2782565995148616e-07
order_loss: 2.6027460080513265e-06
order_loss: 5.9306967159500346e-06
order_loss: 2.8133442810940323e-06
order_loss: 1.0430867405375466e-05
order_loss: 1.758342477842234e-06
order_loss: 5.900879841647111e-06
order_loss: 1.6093276826723013e-06
order_loss: 0.00023557913664262742
order_loss: 1.1920930376163597e-07
order_loss: 2.7815505632133863e-07
order_loss: 3.933922471333062e-06
27/33-(0.750)
order_loss: 1.788139627478813e-07
order_loss: 4.470349495022674e-07
order_loss: 1.788139627478813e-07
order_loss: 4.30349473390379e-06
order_loss: 1.0927534503935021e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.0563672933349153e-06
order_loss: 1.3202585250837728e-05
order_loss: 0.0002637853322084993
order_loss: 7.187153096310794e-05
order_loss: 1.1920930376163597e-07
order_loss: 9.934115041687619e-07
9/33-(0.082)
order_loss: 7.420882411679486e-06
order_loss: 2.6822095833267667e-07
order_loss: 2.6822095833267667e-07
order_loss: 1.788139485370266e-07
order_loss: 1.5497220147153712e-06
order_loss: 2.458699100316153e-06
order_loss: 4.1723265553628153e-07
order_loss: 1.4901162614933128e-07
order_loss: 3.03985643768101e-06
order_loss: 1.6689303095063224e-07
order_loss: 2.0861659777438035e-06
order_loss: 1.1920930376163597e-07
order_loss: 9.536747711536009e-07
order_loss: 8.344653679159819e-07
order_loss: 1.788139485370266e-07
24/33-(0.053)
order_loss: 6.258490543586959e-07
order_loss: 2.0265615603420883e-06
order_loss: 5.960466182841628e-07
order_loss: 7.152560215217818e-07
order_loss: 2.0861628513557662e-07
order_loss: 2.98023280720372e-07
order_loss: 2.4239275262516458e-06
order_loss: 2.0265599687263602e-06
order_loss: 4.569691895994765e-07
order_loss: 5.66244523270143e-07
order_loss: 4.768372718899627e-07
order_loss: 9.536749985272763e-07
order_loss: 5.364419735087722e-07
6/33-(0.047)

=== Evaluating Model ===
accuracy on Valid 0.712166172106825

Total valid loss 1.02729371054606
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7210682492581603

**** Epoch 19/20 ****
order_loss: 5.364419735087722e-07
order_loss: 1.0132795296158292e-06
order_loss: 4.1723259869286267e-07
order_loss: 1.9073504518019035e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.1920930376163597e-07
order_loss: 5.662444095833052e-07
order_loss: 5.245228294370463e-06
order_loss: 3.5762795391747204e-07
order_loss: 2.3841860752327193e-07
order_loss: 5.543262886931188e-06
order_loss: 2.3841860752327193e-07
21/33-(0.864)
order_loss: 1.788139627478813e-07
order_loss: 6.392635441443417e-06
order_loss: 1.519920033388189e-06
order_loss: 1.1235596502956469e-05
Best accuracy on Test 0.7210682492581603

Source domain: 8, Target domain: 8, Cur_fold 4
Corpus: TOEFL
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-spiece.model HTTP/1.1" 200 0
loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/minghongxia/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Loading these models for language: en (English):
=======================
| Processor | Package |
-----------------------
| tokenize  | ewt     |
=======================

Use device: gpu
Loading: tokenize
Done loading processors!
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Loading embeddings from: xlnet-base-cased
Model: DIS_Simple Avg Plus Max_Min
Encoder: XLNet
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin HTTP/1.1" 200 0
loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/minghongxia/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac
Starting new HTTPS connection (1): s3.amazonaws.com:443
https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/xlnet-base-cased-config.json HTTP/1.1" 200 0
loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/minghongxia/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.69e5e35e0b798cab5e473f253752f8bf4d280ee37682281a23eed80f6e2d09c6
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 3072,
  "d_model": 768,
  "do_sample": false,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "ff_activation": "gelu",
  "finetuning_task": null,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 12,
  "n_layer": 12,
  "num_beams": 1,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 5,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "untie_r": true,
  "use_bfloat16": false,
  "vocab_size": 32000
}

Optimizer: adam
Optimizer: adam
**** Training Begins ****
**** Epoch 0/20 ****
Use CrossEntropyLoss
order_loss: 0.6453573703765869
order_loss: 0.6932634711265564
order_loss: 0.6515505909919739
order_loss: 0.5455111265182495
order_loss: 0.47212743759155273
order_loss: 0.5694365501403809
order_loss: 0.3543335497379303
order_loss: 0.3142029941082001
order_loss: 0.08038333803415298
order_loss: 1.3871098756790161
order_loss: 0.03507869318127632
order_loss: 1.2391021251678467
order_loss: 0.46597594022750854
order_loss: 0.32251259684562683
order_loss: 0.3446132242679596
15/33-(1.252)
order_loss: 0.46484020352363586
order_loss: 0.5391183495521545
order_loss: 0.5807864665985107
order_loss: 0.4950847029685974
order_loss: 0.4233623445034027
order_loss: 0.2900766134262085
order_loss: 0.1322883516550064
order_loss: 0.3368229866027832
order_loss: 0.5433006286621094
order_loss: 0.2077152281999588
order_loss: 0.2168087214231491
order_loss: 0.20191426575183868
order_loss: 0.40674763917922974
order_loss: 0.2767253816127777
order_loss: 0.11958958208560944
30/33-(1.152)
order_loss: 0.041108038276433945
order_loss: 0.05392158031463623
order_loss: 0.3680797517299652
order_loss: 0.001606878126040101
order_loss: 0.008033041842281818
order_loss: 0.007376004010438919
order_loss: 0.08396833389997482
order_loss: 0.005739040672779083
order_loss: 0.0192403681576252
order_loss: 0.00627364544197917
order_loss: 0.1179189682006836
order_loss: 0.003196427598595619
order_loss: 0.0007018843316473067
order_loss: 0.00402501504868269
order_loss: 0.003013353096321225
12/33-(1.054)
order_loss: 0.000260733999311924
order_loss: 0.0011079094838351011
order_loss: 0.0010973893804475665
order_loss: 0.8362321257591248
order_loss: 0.0010628411546349525
order_loss: 0.006748780142515898
order_loss: 0.00010455741721671075
order_loss: 0.01073303259909153
order_loss: 6.599256448680535e-05
order_loss: 0.0007893810980021954
order_loss: 0.002390060340985656
order_loss: 0.0014287205412983894
order_loss: 0.0036214846186339855
order_loss: 0.00042563938768580556
order_loss: 0.00028629304142668843
27/33-(0.635)
order_loss: 0.008926985785365105
order_loss: 0.001177622121758759
order_loss: 0.001335015520453453

=== Evaluating Model ===
accuracy on Valid 0.6666666666666666

Best accuracy on Valid 0.6666666666666666
Total valid loss 0.8936213065277446
accuracy on Test 0.6112759643916914
Best accuracy on Test 0.6112759643916914

**** Epoch 0/20 ****
order_loss: 7.844279025448486e-05
order_loss: 0.00039025142905302346
order_loss: 0.00015715957852080464
order_loss: 4.902028013020754e-05
order_loss: 0.00019168593280483037
order_loss: 0.00015773704217281193
order_loss: 0.00024110593949444592
order_loss: 0.0029696321580559015
order_loss: 0.0002967296168208122
order_loss: 0.002999016549438238
order_loss: 0.00022256463125813752
order_loss: 0.00015340032405219972
9/33-(0.880)
order_loss: 0.00010225449659628794
order_loss: 2.8517797545646317e-05
order_loss: 0.00023745576618239284
order_loss: 8.04670708021149e-06
order_loss: 4.3678548536263406e-05
order_loss: 0.4116519093513489
order_loss: 6.143417704151943e-05
order_loss: 0.000631056260317564
order_loss: 0.0006856074905954301
order_loss: 4.6519497118424624e-05
order_loss: 5.420584056992084e-05
order_loss: 0.00010045713861472905
order_loss: 4.857797648583073e-06
order_loss: 0.00032202430884353817
order_loss: 0.00858201365917921
24/33-(0.731)
order_loss: 0.014558621682226658
order_loss: 2.709507680265233e-05
order_loss: 0.0026517543010413647
order_loss: 0.0013001044280827045
order_loss: 0.048846535384655
order_loss: 0.0003962406481150538
order_loss: 6.484565528808162e-05
order_loss: 7.569847639388172e-06
order_loss: 2.2252438611758407e-06
order_loss: 6.542597839143127e-05
order_loss: 2.2459671527030878e-05
order_loss: 0.000467062956886366
order_loss: 0.00022363864991348237
order_loss: 6.802681309636682e-05
order_loss: 0.02239680476486683
6/33-(1.518)
order_loss: 5.11434736836236e-05
order_loss: 0.0033924109302461147
order_loss: 5.135366882313974e-05
order_loss: 0.00011406716657802463
order_loss: 0.00019094636081717908
order_loss: 0.0006857932894490659
order_loss: 0.0004702270671259612
order_loss: 2.075285738101229e-05
order_loss: 5.003319893148728e-05
order_loss: 0.00024831219343468547
order_loss: 0.000571291078813374
order_loss: 6.47130364086479e-05
order_loss: 4.4219515984877944e-05
order_loss: 0.00035068942815996706
order_loss: 9.796545054996386e-05
21/33-(0.731)
order_loss: 0.00016914359002839774
order_loss: 5.164106551092118e-05
order_loss: 0.00012054933176841587
order_loss: 0.0003171789867337793
order_loss: 2.5964398446376435e-05
order_loss: 2.8949760235263966e-05

=== Evaluating Model ===
accuracy on Valid 0.6160714285714286

Total valid loss 1.0503507852554321
accuracy on Test 0.5608308605341247
Best accuracy on Test 0.6112759643916914

**** Epoch 1/20 ****
order_loss: 3.9022248529363424e-05
order_loss: 3.1193194445222616e-06
order_loss: 2.1152134650037624e-05
order_loss: 5.464087735163048e-05
order_loss: 2.2252459075389197e-06
order_loss: 1.9470876395644154e-06
order_loss: 2.4594175556558184e-05
order_loss: 1.23679865282611e-06
3/33-(0.374)
order_loss: 5.702197995560709e-06
order_loss: 7.132726295822067e-06
order_loss: 5.326871178112924e-05
order_loss: 3.240654768887907e-05
order_loss: 4.8160795813601e-06
order_loss: 0.0023673733230680227
order_loss: 0.00013346537889447063
order_loss: 1.7077083612093702e-05
order_loss: 2.6623508802003926e-06
order_loss: 0.0002878113300539553
order_loss: 2.2263149730861187e-05
order_loss: 0.015095464885234833
order_loss: 5.4497242672368884e-05
order_loss: 1.5259043721016496e-05
order_loss: 4.610080213751644e-05
18/33-(0.598)
order_loss: 2.682222202565754e-06
order_loss: 0.00024051021318882704
order_loss: 2.3841921574785374e-06
order_loss: 0.00013768761709798127
order_loss: 8.195703230740037e-06
order_loss: 2.98023280720372e-07
order_loss: 1.901424184325151e-05
order_loss: 5.4450334573630244e-05
order_loss: 0.00014838554488960654
order_loss: 0.000873491691891104
order_loss: 1.9550388969946653e-06
order_loss: 7.113066385500133e-05
order_loss: 3.957762146455934e-06
0/33-(0.621)
order_loss: 1.5363266356871463e-05
order_loss: 7.410900252580177e-06
order_loss: 3.7612117012031376e-05
order_loss: 0.00020819029305130243
order_loss: 0.00022221395920496434
order_loss: 4.992256799596362e-05
order_loss: 2.741822527241311e-06
order_loss: 0.000183073352673091
order_loss: 4.013405487057753e-06
order_loss: 4.51428750238847e-05
order_loss: 1.0609752280288376e-05
order_loss: 2.7895697712665424e-05
order_loss: 6.163455691421404e-05
order_loss: 3.606087830121396e-06
order_loss: 2.2202812033356167e-06
15/33-(0.611)
order_loss: 2.3305687136598863e-05
order_loss: 0.00019334301759954542
order_loss: 4.25181087848614e-06
order_loss: 2.2053766315366374e-06
order_loss: 0.00020798649347852916
order_loss: 3.791150083998218e-05
order_loss: 1.7523976566735655e-05
order_loss: 5.5514123232569546e-05
order_loss: 5.722292553400621e-05

=== Evaluating Model ===
accuracy on Valid 0.6755952380952381

Best accuracy on Valid 0.6755952380952381
Total valid loss 0.7501807294108651
accuracy on Test 0.6439169139465876
Best accuracy on Test 0.6439169139465876

**** Epoch 2/20 ****
order_loss: 2.98023678624304e-06
order_loss: 0.00012076630082447082
order_loss: 2.7597456210060045e-05
order_loss: 9.353260247735307e-05
order_loss: 1.487149165768642e-05
30/33-(0.610)
order_loss: 3.5911928080167854e-06
order_loss: 7.343562174355611e-05
order_loss: 7.635646761627868e-05
order_loss: 3.60614612873178e-05
order_loss: 6.556513199029723e-07
order_loss: 0.0003507757210172713
order_loss: 2.6077639631694183e-05
order_loss: 0.00017139248666353524
order_loss: 1.5843112123548053e-05
order_loss: 5.644873090204783e-05
order_loss: 5.1655006245709956e-05
order_loss: 5.364420303521911e-07
order_loss: 3.379672489245422e-05
order_loss: 5.722078640246764e-06
order_loss: 3.1150953873293474e-05
12/33-(0.653)
order_loss: 0.000459132541436702
order_loss: 1.0281858521921095e-05
order_loss: 4.047237234772183e-05
order_loss: 0.0004280552384443581
order_loss: 1.484166659793118e-05
order_loss: 2.3782809876138344e-05
order_loss: 4.029506089864299e-05
order_loss: 2.4140426830854267e-05
order_loss: 8.035332575673237e-05
order_loss: 2.570547985669691e-05
order_loss: 7.430771802319214e-06
order_loss: 2.8948734325240366e-05
order_loss: 1.8608829122968018e-05
order_loss: 4.1522220271872357e-05
order_loss: 6.228723577805795e-06
27/33-(0.712)
order_loss: 5.960466751275817e-07
order_loss: 1.5159781469264999e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.0538196875131689e-05
order_loss: 5.662494459102163e-06
order_loss: 6.90742235747166e-05
order_loss: 8.583116141380742e-06
order_loss: 8.742023283048184e-07
order_loss: 6.1889877542853355e-06
order_loss: 5.362846059142612e-05
order_loss: 1.6689316453266656e-06
order_loss: 1.3113037766743219e-06
order_loss: 1.5199206018223776e-06
order_loss: 7.599664058943745e-06
order_loss: 0.0001250774075742811
9/33-(0.988)
order_loss: 3.428959098528139e-05
order_loss: 8.622006134828553e-05
order_loss: 3.668798308353871e-05
order_loss: 5.461705950438045e-05
order_loss: 1.1920930376163597e-07
order_loss: 5.537576726055704e-05
order_loss: 4.827988050237764e-06
order_loss: 3.1263494747690856e-05
order_loss: 6.228879647096619e-05
order_loss: 2.786528057185933e-06
order_loss: 4.081634324393235e-05
order_loss: 1.1920930376163597e-07

=== Evaluating Model ===
accuracy on Valid 0.7023809523809523

Best accuracy on Valid 0.7023809523809523
Total valid loss 0.7798749669031664
accuracy on Test 0.685459940652819
Best accuracy on Test 0.685459940652819

**** Epoch 3/20 ****
order_loss: 0.0004742317833006382
order_loss: 0.0025891598779708147
order_loss: 1.4603153886127984e-06
24/33-(0.345)
order_loss: 7.569818535557715e-06
order_loss: 9.857539407676086e-05
order_loss: 2.3841860752327193e-07
order_loss: 5.659925227519125e-05
order_loss: 6.943971129658166e-06
order_loss: 0.00010370119707658887
order_loss: 5.197587142902194e-06
order_loss: 1.8954309553009807e-06
order_loss: 9.42732731346041e-05
order_loss: 2.0265617877157638e-06
order_loss: 1.033148237183923e-06
order_loss: 2.0295687136240304e-05
order_loss: 3.993519385403488e-06
order_loss: 0.00015249388525262475
order_loss: 0.0011649597436189651
6/33-(0.549)
order_loss: 7.15256362582295e-07
order_loss: 5.801560291729402e-06
order_loss: 2.0265620150894392e-06
order_loss: 8.784573583398014e-05
order_loss: 6.0606893384829164e-05
order_loss: 0.00011057528899982572
order_loss: 4.762524622492492e-05
order_loss: 2.926630804722663e-05
order_loss: 0.00024883876903913915
order_loss: 1.5795390936546028e-05
order_loss: 9.327440056949854e-05
order_loss: 1.0728841743912199e-06
order_loss: 0.0004527736164163798
order_loss: 0.0009092448162846267
order_loss: 5.980359674140345e-06
21/33-(0.581)
order_loss: 8.642678608339338e-07
order_loss: 1.0848104466276709e-05
order_loss: 5.007039726478979e-05
order_loss: 0.00015868977061472833
order_loss: 0.00014258961891755462
order_loss: 0.0003851201618090272
order_loss: 4.773212276631966e-05
order_loss: 2.3841860752327193e-07
order_loss: 0.001127119641751051
order_loss: 8.146038453560323e-06
order_loss: 1.0907859177677892e-05
order_loss: 1.9868510207743384e-05
order_loss: 7.858384924475104e-05
order_loss: 0.00013705894525628537
order_loss: 2.4636672151245875e-06
3/33-(0.453)
order_loss: 1.5378191164927557e-05
order_loss: 1.8974569684360176e-05
order_loss: 1.311303321926971e-06
order_loss: 5.0569586164783686e-05
order_loss: 5.781674190075137e-06
order_loss: 0.0003084274067077786
order_loss: 1.61414918693481e-05
order_loss: 5.209959272178821e-05
order_loss: 6.934038083272753e-06
order_loss: 6.729739834554493e-05
order_loss: 0.0018556038849055767
order_loss: 4.0829354475135915e-06
18/33-(0.746)

=== Evaluating Model ===
accuracy on Valid 0.7708333333333334

Best accuracy on Valid 0.7708333333333334
Total valid loss 0.6927694854411212
accuracy on Test 0.7181008902077152
Best accuracy on Test 0.7181008902077152

**** Epoch 4/20 ****
order_loss: 5.7477576774545014e-05
order_loss: 6.500243762275204e-05
order_loss: 7.1328013291349635e-06
order_loss: 8.991931281343568e-06
order_loss: 1.842802157625556e-05
order_loss: 3.614167508203536e-05
order_loss: 2.3543884708487894e-06
order_loss: 1.9292438082629815e-05
order_loss: 3.874316462315619e-06
order_loss: 7.450656084984075e-06
order_loss: 3.7691301258746535e-05
order_loss: 3.090589234489016e-05
order_loss: 8.20525165181607e-05
order_loss: 4.330445153755136e-05
0/33-(0.652)
order_loss: 2.145769485650817e-06
order_loss: 2.2054115106584504e-05
order_loss: 1.535847331979312e-05
order_loss: 4.768373855768004e-07
order_loss: 2.3245838747243397e-06
order_loss: 2.4139942524925573e-06
order_loss: 6.556513199029723e-07
order_loss: 4.440576958586462e-06
order_loss: 3.536555595928803e-06
order_loss: 1.8567188817542046e-05
order_loss: 2.443796802253928e-06
order_loss: 6.953917818464106e-06
order_loss: 1.4722455489390995e-05
order_loss: 3.3380132663296536e-05
15/33-(0.821)
order_loss: 1.0132930583495181e-05
order_loss: 1.519920033388189e-06
order_loss: 1.9312430595164187e-05
order_loss: 8.344658226633328e-07
order_loss: 0.00012780744873452932
order_loss: 5.6190699979197234e-05
order_loss: 2.1378451492637396e-05
order_loss: 0.00015124224592000246
order_loss: 1.1920930376163597e-07
order_loss: 0.00015448925842065364
order_loss: 4.039287887280807e-05
order_loss: 2.3841860752327193e-07
order_loss: 0.00019718515977729112
order_loss: 4.214221553411335e-05
30/33-(0.368)
order_loss: 1.1920930376163597e-07
order_loss: 3.6835861010331428e-06
order_loss: 5.2452264753810596e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.343876596773043e-05
order_loss: 1.6177260476979427e-05
order_loss: 2.801422169795842e-06
order_loss: 1.4662943613075186e-05
order_loss: 5.7816673688648734e-06
order_loss: 2.3841901111154584e-06
order_loss: 1.1523575267347042e-06
order_loss: 4.480437928577885e-05
order_loss: 4.393054769025184e-05
12/33-(0.462)
order_loss: 5.543247425521258e-06
order_loss: 8.127512410283089e-05
order_loss: 1.62722008099081e-05

=== Evaluating Model ===
accuracy on Valid 0.7529761904761905

Total valid loss 0.7994461235674944
accuracy on Test 0.7240356083086054
Best accuracy on Test 0.7240356083086054

**** Epoch 5/20 ****
order_loss: 8.245373464887962e-06
order_loss: 4.678985987993656e-06
order_loss: 1.1831667507067323e-05
order_loss: 1.7583422504685586e-06
order_loss: 6.362869953591144e-06
order_loss: 1.2189304470666684e-05
order_loss: 2.3841863594498136e-07
order_loss: 4.634288416127674e-06
order_loss: 1.788139627478813e-07
order_loss: 2.2202775653568096e-06
order_loss: 0.0003885652986355126
27/33-(0.840)
order_loss: 2.6345298920205096e-06
order_loss: 4.66875899292063e-05
order_loss: 2.3841860752327193e-07
order_loss: 5.761785928370955e-07
order_loss: 0.00011633392568910494
order_loss: 0.002656900091096759
order_loss: 7.593693680973956e-06
order_loss: 1.1235588317504153e-05
order_loss: 5.364446224120911e-06
order_loss: 5.960466751275817e-07
order_loss: 1.2516983360910672e-06
order_loss: 1.949929810507456e-06
order_loss: 3.099447440035874e-06
order_loss: 2.7219537059863796e-06
9/33-(0.365)
order_loss: 1.2919452274218202e-05
order_loss: 1.6272302673314698e-05
order_loss: 1.668969343882054e-05
order_loss: 2.21139780478552e-05
order_loss: 9.620840137358755e-05
order_loss: 3.576279254957626e-07
order_loss: 8.761950084590353e-06
order_loss: 1.3327809938346036e-05
order_loss: 6.2386498029809445e-06
order_loss: 7.947292033350095e-07
order_loss: 7.641607226105407e-05
order_loss: 3.6756362078449456e-06
order_loss: 6.0381327784853056e-05
order_loss: 1.3965119251224678e-05
order_loss: 2.920631914093974e-06
24/33-(0.410)
order_loss: 1.7484060208516894e-06
order_loss: 7.569864010292804e-06
order_loss: 2.7358906663721427e-05
order_loss: 7.43573036743328e-06
order_loss: 6.437348019971978e-06
order_loss: 6.184585072332993e-05
order_loss: 3.355797889526002e-05
order_loss: 2.980244971695356e-06
order_loss: 5.006815172237111e-06
order_loss: 1.4314190593722742e-05
order_loss: 4.559772150969366e-06
order_loss: 4.1723265553628153e-07
order_loss: 6.80174125591293e-05
order_loss: 5.573071121034445e-06
6/33-(0.399)
order_loss: 0.00011136621469631791
order_loss: 1.788139627478813e-07
order_loss: 5.9390942624304444e-05
order_loss: 0.0001432998396921903
order_loss: 1.1920930376163597e-07
order_loss: 0.00012322550173848867

=== Evaluating Model ===
accuracy on Valid 0.625

Total valid loss 0.9214979288252917
accuracy on Test 0.6231454005934718
Best accuracy on Test 0.7240356083086054

**** Epoch 6/20 ****
order_loss: 1.6689314179529902e-06
order_loss: 2.2789256036048755e-05
order_loss: 3.159115294693038e-05
order_loss: 5.165737775314483e-07
order_loss: 7.291707333934028e-06
order_loss: 3.492858013487421e-06
order_loss: 9.377861715620384e-06
order_loss: 2.384190338489134e-06
21/33-(0.645)
order_loss: 2.1398374883574434e-05
order_loss: 8.940701832216291e-07
order_loss: 0.000701305631082505
order_loss: 2.062362909782678e-05
order_loss: 1.4174168427416589e-05
order_loss: 3.024945954166469e-06
order_loss: 6.318099963209534e-07
order_loss: 8.300075933220796e-06
order_loss: 2.6942439944832586e-05
order_loss: 3.0994528970040847e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.1920931797249068e-07
order_loss: 8.952788448368665e-06
order_loss: 3.457291313679889e-05
order_loss: 9.298370059696026e-06
3/33-(0.605)
order_loss: 2.995139539052616e-06
order_loss: 4.2120791476918384e-06
order_loss: 2.0504208805505186e-05
order_loss: 1.7889446098706685e-05
order_loss: 3.755099669433548e-06
order_loss: 1.1026920219592284e-05
order_loss: 2.392186434008181e-05
order_loss: 6.056015263311565e-05
order_loss: 8.344653679159819e-07
order_loss: 1.8199769328930415e-05
order_loss: 0.00010209809261141345
order_loss: 5.56310226329515e-07
order_loss: 0.00017639780708122998
order_loss: 4.967056383975432e-07
18/33-(0.256)
order_loss: 2.1755733996542403e-06
order_loss: 4.7565637942170724e-05
order_loss: 5.364420303521911e-07
order_loss: 7.629439096490387e-06
order_loss: 2.0166285139566753e-06
order_loss: 3.659920912468806e-05
order_loss: 3.099454715993488e-06
order_loss: 3.477992140688002e-05
order_loss: 3.079581802012399e-06
order_loss: 8.940704674387234e-07
order_loss: 1.0411082257633097e-05
order_loss: 2.092190698022023e-05
order_loss: 1.1285296750429552e-05
order_loss: 2.3841860752327193e-07
0/33-(0.932)
order_loss: 6.258516805246472e-06
order_loss: 4.619370884029195e-06
order_loss: 1.0401075996924192e-05
order_loss: 6.6757625063473824e-06
order_loss: 8.344659363501705e-07
order_loss: 1.1523577541083796e-06
order_loss: 1.3709085351365502e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07

=== Evaluating Model ===
accuracy on Valid 0.7440476190476191

Total valid loss 0.6725614748217843
accuracy on Test 0.6943620178041543
Best accuracy on Test 0.7240356083086054

**** Epoch 7/20 ****
order_loss: 1.1920930376163597e-07
order_loss: 2.1159680727578234e-06
order_loss: 8.404316758969799e-06
order_loss: 3.5762795391747204e-07
order_loss: 1.5497228105232352e-06
order_loss: 1.1667723811115138e-05
15/33-(0.750)
order_loss: 1.2636313840630464e-05
order_loss: 1.746431371429935e-05
order_loss: 1.7881668100017123e-05
order_loss: 1.6272331777145155e-05
order_loss: 3.5762859624810517e-06
order_loss: 9.536810466670431e-06
order_loss: 1.4702495718665887e-06
order_loss: 6.58635235595284e-06
order_loss: 1.0728846291385707e-06
order_loss: 7.248035672091646e-06
order_loss: 1.1484010428830516e-05
order_loss: 7.271818503795657e-06
order_loss: 0.00013554476026911288
order_loss: 2.7716232580132782e-06
30/33-(0.617)
order_loss: 1.4305353033705615e-05
order_loss: 3.486891955617466e-06
order_loss: 6.675760232610628e-06
order_loss: 3.412380692680017e-06
order_loss: 7.152560215217818e-07
order_loss: 4.634282049664762e-06
order_loss: 8.94069742685133e-08
order_loss: 2.3976746888365597e-05
order_loss: 1.4901174836268183e-06
order_loss: 8.649010851513594e-05
order_loss: 9.000364116218407e-06
order_loss: 7.19520994607592e-06
order_loss: 4.907467882730998e-06
order_loss: 9.80505774350604e-06
12/33-(0.404)
order_loss: 9.735431376611814e-07
order_loss: 4.339232873462606e-06
order_loss: 5.602867531706579e-06
order_loss: 4.366073881101329e-06
order_loss: 4.70880331704393e-06
order_loss: 1.2823799806938041e-05
order_loss: 8.761924618738703e-06
order_loss: 4.783295935339993e-06
order_loss: 8.642678608339338e-07
order_loss: 2.2649805941910017e-06
order_loss: 5.891005457669962e-06
order_loss: 1.1324947081448045e-05
order_loss: 1.5795249055372551e-06
order_loss: 1.8576805587144918e-06
order_loss: 1.4156123597786063e-06
27/33-(0.730)
order_loss: 9.298368240706623e-06
order_loss: 1.934207284648437e-05
order_loss: 2.2888965759193525e-05
order_loss: 1.4563695003744215e-05
order_loss: 2.92063759843586e-06
order_loss: 4.529987108981004e-06
order_loss: 4.291564891900634e-06
order_loss: 1.5771955077070743e-05
order_loss: 8.217793219955638e-05
order_loss: 4.6253717300714925e-06
order_loss: 6.413543360395124e-06
order_loss: 8.046680704865139e-06

=== Evaluating Model ===
accuracy on Valid 0.6577380952380952

Total valid loss 0.7008351372046904
accuracy on Test 0.6676557863501483
Best accuracy on Test 0.7240356083086054

**** Epoch 8/20 ****
order_loss: 3.874303047268768e-07
order_loss: 4.3511518015293404e-06
order_loss: 7.748610073576856e-07
9/33-(0.475)
order_loss: 1.1324889328534482e-06
order_loss: 6.318132363958284e-06
order_loss: 1.2516995866462821e-06
order_loss: 1.1185892617504578e-05
order_loss: 2.304719600942917e-06
order_loss: 4.664088919525966e-06
order_loss: 8.742061254451983e-06
order_loss: 1.9729806808754802e-05
order_loss: 4.005456048616907e-06
order_loss: 3.6358928809931967e-06
order_loss: 1.6356119886040688e-05
order_loss: 0.000205171323614195
order_loss: 2.4795651825115783e-06
order_loss: 1.1920999895664863e-05
24/33-(0.547)
order_loss: 8.082542080956046e-06
order_loss: 4.351170900918078e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.324586148461094e-06
order_loss: 2.592808186818729e-06
order_loss: 2.0861843950115144e-05
order_loss: 1.0967266916850349e-06
order_loss: 3.9239921534317546e-06
order_loss: 2.2500812519865576e-06
order_loss: 6.794933256060176e-07
order_loss: 4.142541911278386e-06
order_loss: 1.9888664610334672e-05
order_loss: 5.5929722293512896e-06
order_loss: 1.966956006071996e-06
order_loss: 1.0311699043086264e-05
6/33-(0.498)
order_loss: 1.947089458553819e-06
order_loss: 1.5288851500372402e-05
order_loss: 8.344656521330762e-07
order_loss: 1.922252977237804e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.1019509656762239e-05
order_loss: 8.046631592151243e-07
order_loss: 3.576279254957626e-07
order_loss: 5.254421921563335e-05
order_loss: 4.37100823091896e-07
order_loss: 8.312279533129185e-05
order_loss: 3.2784115319373086e-05
order_loss: 3.576279254957626e-07
order_loss: 5.364419735087722e-07
order_loss: 2.23517460540279e-07
21/33-(0.508)
order_loss: 1.6888006939552724e-06
order_loss: 6.1542295952676795e-06
order_loss: 3.576279254957626e-07
order_loss: 4.470349495022674e-07
order_loss: 2.6822095833267667e-07
order_loss: 4.768372718899627e-07
order_loss: 1.1324899560349877e-06
order_loss: 3.576279254957626e-07
order_loss: 5.662444664267241e-07
order_loss: 0.0002513887593522668
order_loss: 2.3841860752327193e-07
order_loss: 9.089717423194088e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.430641638464294e-06
3/33-(0.322)

=== Evaluating Model ===
accuracy on Valid 0.7529761904761905

Total valid loss 0.6474408073858782
accuracy on Test 0.7091988130563798
Best accuracy on Test 0.7240356083086054

**** Epoch 9/20 ****
order_loss: 1.1920930376163597e-07
order_loss: 3.0696471640112577e-06
order_loss: 4.649190941563575e-06
order_loss: 2.235179181298008e-06
order_loss: 2.18550411545948e-07
order_loss: 1.6451202100142837e-05
order_loss: 0.000221492417040281
order_loss: 6.210846095200395e-06
order_loss: 3.2186721909965854e-06
order_loss: 3.963722519984003e-06
order_loss: 9.139389476331417e-07
order_loss: 4.038236511405557e-06
order_loss: 2.890890209528152e-05
order_loss: 7.738762178632896e-06
order_loss: 2.6624851670931093e-05
18/33-(0.721)
order_loss: 4.64918366560596e-06
order_loss: 4.756483122037025e-06
order_loss: 2.5987699245888507e-06
order_loss: 7.520238796132617e-06
order_loss: 2.8610309072973905e-06
order_loss: 8.642683724247036e-07
order_loss: 3.5166826819477137e-06
order_loss: 1.229365989274811e-05
order_loss: 2.156521259166766e-05
order_loss: 4.460445779841393e-06
order_loss: 4.045407331432216e-05
order_loss: 2.3841860752327193e-07
order_loss: 4.9273367039859295e-06
order_loss: 1.1920941460630274e-06
0/33-(0.378)
order_loss: 2.086165750370128e-06
order_loss: 2.1636722522089258e-05
order_loss: 0.0003385245508980006
order_loss: 2.6822126528713852e-06
order_loss: 4.142536909057526e-06
order_loss: 2.5183057914546225e-06
order_loss: 2.566044349805452e-05
order_loss: 2.145773123629624e-06
order_loss: 1.941177833941765e-05
order_loss: 1.2815020227208151e-06
order_loss: 5.483642325998517e-06
order_loss: 2.211370156146586e-05
order_loss: 9.735432513480191e-07
15/33-(0.265)
order_loss: 2.980233091420814e-07
order_loss: 6.3578681874787435e-06
order_loss: 4.86773251395789e-06
order_loss: 1.1523576404215419e-06
order_loss: 1.4305134072856163e-06
order_loss: 6.794974069634918e-06
order_loss: 2.1457708498928696e-06
order_loss: 7.728779564786237e-06
order_loss: 1.1920930376163597e-07
order_loss: 1.606383011676371e-05
order_loss: 4.685142994276248e-05
order_loss: 7.152560783652007e-07
order_loss: 7.748611778879422e-07
order_loss: 0.00011499646643642336
order_loss: 6.159149847917433e-07
30/33-(0.363)
order_loss: 3.4272852644789964e-06
order_loss: 6.854537559775054e-07
order_loss: 2.5213392291334458e-05

=== Evaluating Model ===
accuracy on Valid 0.7172619047619048

Total valid loss 0.773255810818889
accuracy on Test 0.7091988130563798
Best accuracy on Test 0.7240356083086054

**** Epoch 10/20 ****
order_loss: 5.1458987400110345e-06
order_loss: 5.960464477539063e-08
order_loss: 1.5695944739491097e-06
order_loss: 1.9669589619297767e-06
order_loss: 0.00020872119057457894
order_loss: 2.2665244614472613e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.788139627478813e-07
order_loss: 4.744576926896116e-06
order_loss: 1.5199195786408382e-06
order_loss: 8.622862878837623e-06
12/33-(0.252)
order_loss: 7.152560783652007e-07
order_loss: 3.322973725516931e-06
order_loss: 0.00013583617692347616
order_loss: 2.253064394608373e-06
order_loss: 1.6291954807456932e-06
order_loss: 1.788139627478813e-07
order_loss: 4.231946149957366e-06
order_loss: 2.3842141672503203e-05
order_loss: 3.218753045075573e-05
order_loss: 2.8956763344467618e-05
order_loss: 3.019979658347438e-06
order_loss: 2.3722702735540224e-06
order_loss: 1.2934295227751136e-05
order_loss: 1.69279555848334e-05
order_loss: 1.3510411918105092e-06
27/33-(0.603)
order_loss: 1.51992048813554e-06
order_loss: 1.0281819413648918e-06
order_loss: 3.2037610253610183e-06
order_loss: 2.98023280720372e-07
order_loss: 3.18885440719896e-06
order_loss: 1.2010584214294795e-05
order_loss: 1.8477456933396752e-06
order_loss: 4.923585584037937e-05
order_loss: 7.669215847272426e-06
order_loss: 3.2335694868379505e-06
order_loss: 9.06005243450636e-06
order_loss: 3.0547453206963837e-06
order_loss: 1.1920928955078125e-07
order_loss: 2.3245838747243397e-06
order_loss: 2.6424827410664875e-06
9/33-(0.196)
order_loss: 1.2248867278685793e-05
order_loss: 3.5762798233918147e-07
order_loss: 1.9868218714691466e-07
order_loss: 4.291549430490704e-06
order_loss: 1.7151673091575503e-05
order_loss: 8.45210797706386e-06
order_loss: 1.4901181657478446e-06
order_loss: 1.0530161489441525e-06
order_loss: 7.748607231405913e-07
order_loss: 4.142536909057526e-06
order_loss: 2.4437952106382e-06
order_loss: 2.3841860752327193e-07
order_loss: 2.6226161935483105e-06
order_loss: 3.5762966490437975e-06
order_loss: 4.609450115822256e-06
24/33-(0.656)
order_loss: 9.735433650348568e-07
order_loss: 7.748611778879422e-07
order_loss: 1.4901182794346823e-06
order_loss: 2.7180270990356803e-05
order_loss: 2.8755330276908353e-05
order_loss: 8.344654816028196e-07

=== Evaluating Model ===
accuracy on Valid 0.7321428571428571

Total valid loss 0.8263713988390836
accuracy on Test 0.6765578635014837
Best accuracy on Test 0.7240356083086054

**** Epoch 11/20 ****
order_loss: 5.451343167806044e-05
order_loss: 4.398843884700909e-06
order_loss: 1.3113035493006464e-06
order_loss: 2.2053745851735584e-06
order_loss: 1.2358159438008443e-05
order_loss: 3.6756355257239193e-06
order_loss: 1.2318305380176753e-06
order_loss: 2.2053750399209093e-06
order_loss: 5.293362119118683e-05
6/33-(0.891)
order_loss: 3.576279254957626e-07
order_loss: 3.1292444191421964e-07
order_loss: 8.641803287900984e-05
order_loss: 1.794140916899778e-05
order_loss: 4.783303211297607e-06
order_loss: 1.811997572076507e-05
order_loss: 5.036612037656596e-06
order_loss: 4.1723378672031686e-06
order_loss: 1.1533725228218827e-05
order_loss: 2.5749327505764086e-06
order_loss: 1.668933123255556e-06
order_loss: 3.556427827788866e-06
order_loss: 7.152560215217818e-07
21/33-(0.426)
order_loss: 7.967215424287133e-06
order_loss: 1.0490472959645558e-05
order_loss: 1.653074286878109e-05
order_loss: 5.155826329428237e-06
order_loss: 3.691830352181569e-05
order_loss: 1.0430906513647642e-05
order_loss: 8.940702969084668e-07
order_loss: 1.2516983360910672e-06
order_loss: 9.522737673250958e-05
order_loss: 4.669052941608243e-06
order_loss: 3.459601430222392e-05
order_loss: 5.960466751275817e-07
order_loss: 4.768372718899627e-07
order_loss: 4.619380888470914e-06
order_loss: 6.006694457028061e-05
3/33-(0.611)
order_loss: 3.0597136628784938e-06
order_loss: 4.3852405724464916e-06
order_loss: 2.622611191327451e-06
order_loss: 8.742019872443052e-07
order_loss: 3.5464847769617336e-06
order_loss: 8.404311302001588e-06
order_loss: 3.1789153354111477e-07
order_loss: 5.215408123149246e-07
order_loss: 8.94069742685133e-08
order_loss: 2.3841860752327193e-07
order_loss: 6.692271563224494e-05
order_loss: 2.980233091420814e-07
order_loss: 1.450382455914223e-06
18/33-(0.210)
order_loss: 4.410761448525591e-06
order_loss: 8.732155947654974e-06
order_loss: 5.3199968533590436e-05
order_loss: 1.2755407396980445e-06
order_loss: 2.2451145014201757e-06
order_loss: 7.897621117081144e-07

=== Evaluating Model ===
accuracy on Valid 0.7172619047619048

Total valid loss 0.9959704740480944
accuracy on Test 0.7240356083086054
Best accuracy on Test 0.7240356083086054

**** Epoch 12/20 ****
order_loss: 3.5762798233918147e-07
order_loss: 1.4762407772650477e-05
order_loss: 3.814704541582614e-06
order_loss: 3.576279254957626e-07
0/33-(0.484)
order_loss: 7.152560215217818e-07
order_loss: 9.7354370609537e-07
order_loss: 2.0384866274980595e-06
order_loss: 2.3841860752327193e-07
order_loss: 4.023329438496148e-06
order_loss: 1.8179438256993308e-06
order_loss: 1.01626937976107e-05
order_loss: 5.960466182841628e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.1723583308339585e-06
order_loss: 7.152561352086195e-07
order_loss: 1.0530161489441525e-06
order_loss: 3.2186608223128133e-06
order_loss: 4.798195732291788e-06
15/33-(0.722)
order_loss: 0.00010774182737804949
order_loss: 1.8974213844558108e-06
order_loss: 6.809867954871152e-06
order_loss: 1.2278578651603311e-06
order_loss: 9.894465620163828e-06
order_loss: 7.73377269069897e-06
order_loss: 2.348427869947045e-06
order_loss: 1.3262201719044242e-05
order_loss: 5.811456276205718e-07
order_loss: 2.9802333756379085e-07
order_loss: 1.1920930376163597e-07
order_loss: 7.581780664622784e-06
order_loss: 4.935311608278425e-06
order_loss: 5.21430883964058e-05
30/33-(0.547)
order_loss: 4.422684469318483e-06
order_loss: 1.180178969661938e-05
order_loss: 1.3843554370396305e-05
order_loss: 0.0001678447297308594
order_loss: 3.010045020346297e-06
order_loss: 1.6987346498353872e-06
order_loss: 6.000251232762821e-06
order_loss: 2.3394891286443453e-06
order_loss: 2.344452695979271e-06
order_loss: 1.2469417015381623e-05
order_loss: 4.470358362596016e-06
order_loss: 3.57628505298635e-06
order_loss: 1.3828293958795257e-06
order_loss: 6.9737675403303e-06
order_loss: 4.827988050237764e-06
12/33-(0.246)
order_loss: 5.9008771131630056e-06
order_loss: 0.00022427630028687418
order_loss: 2.0861628513557662e-07
order_loss: 3.576279254957626e-07
order_loss: 8.662651453050785e-06
order_loss: 0.00013908564869780093
order_loss: 1.9074002921115607e-05
order_loss: 1.937153911057976e-06
order_loss: 6.854620096419239e-06
order_loss: 7.152560215217818e-07
order_loss: 4.768373287333816e-07
order_loss: 1.2954234080098104e-05

=== Evaluating Model ===
accuracy on Valid 0.7529761904761905

Total valid loss 0.8435428562489423
accuracy on Test 0.7270029673590505
Best accuracy on Test 0.7270029673590505

**** Epoch 13/20 ****
order_loss: 2.582875595180667e-06
order_loss: 2.1815349100506864e-06
order_loss: 4.212073235976277e-06
27/33-(0.278)
order_loss: 1.6093266594907618e-06
order_loss: 3.218656047465629e-06
order_loss: 1.096736014005728e-05
order_loss: 4.440563770913286e-06
order_loss: 2.6882056772592478e-05
order_loss: 5.364419735087722e-07
order_loss: 1.0331478961234097e-06
order_loss: 1.7166166799142957e-06
order_loss: 1.788139627478813e-07
order_loss: 1.1920930376163597e-07
order_loss: 3.5762795391747204e-07
order_loss: 9.223913366440684e-06
order_loss: 1.8477456933396752e-06
order_loss: 9.536747711536009e-07
9/33-(0.121)
order_loss: 1.7166570614790544e-05
order_loss: 1.564624767524947e-06
order_loss: 1.0430834436192526e-06
order_loss: 9.310379937232938e-06
order_loss: 3.85048861062387e-06
order_loss: 2.0066941033292096e-06
order_loss: 1.9371512394172896e-07
order_loss: 6.25848997515277e-07
order_loss: 7.45058400752896e-07
order_loss: 1.0132799843631801e-06
order_loss: 1.0371402822784148e-05
order_loss: 3.5762795391747204e-07
order_loss: 2.880892395751289e-07
order_loss: 7.152560215217818e-07
order_loss: 6.119448698882479e-06
24/33-(0.922)
order_loss: 4.768372718899627e-07
order_loss: 2.4735966235311935e-06
order_loss: 8.165901817847043e-06
order_loss: 2.3444549697160255e-06
order_loss: 3.7551044442807324e-06
order_loss: 5.364420303521911e-07
order_loss: 2.98023280720372e-07
order_loss: 5.265095296635991e-06
order_loss: 4.1723259869286267e-07
order_loss: 3.111426849500276e-05
order_loss: 5.960466751275817e-07
order_loss: 5.960464477539063e-08
order_loss: 3.814716819761088e-06
order_loss: 4.1723424146766774e-06
6/33-(0.126)
order_loss: 1.4503809779853327e-06
order_loss: 4.1723259869286267e-07
order_loss: 1.3113034356138087e-06
order_loss: 2.0861628513557662e-07
order_loss: 1.3411056443146663e-06
order_loss: 8.106264431262389e-06
order_loss: 1.3907752816066932e-07
order_loss: 6.755242338840617e-06
order_loss: 2.831226993293967e-06
order_loss: 1.1920930376163597e-07
order_loss: 4.4586253352463245e-05
order_loss: 5.662442958964675e-07
order_loss: 4.649177753890399e-06
order_loss: 1.9868218714691466e-07
21/33-(0.152)

=== Evaluating Model ===
accuracy on Valid 0.7083333333333334

Total valid loss 0.7728580810468305
accuracy on Test 0.7537091988130564
Best accuracy on Test 0.7537091988130564

**** Epoch 14/20 ****
order_loss: 4.3710351746995e-06
order_loss: 1.6689314179529902e-06
order_loss: 6.5565143358981e-07
order_loss: 2.997270030391519e-06
order_loss: 4.172326271145721e-07
order_loss: 3.37759814783567e-07
order_loss: 1.5616454902556143e-06
order_loss: 6.556514904332289e-07
order_loss: 1.1920930376163597e-07
order_loss: 9.894383765640669e-07
order_loss: 1.9868218714691466e-07
order_loss: 5.9371152019593865e-05
order_loss: 7.599691343784798e-06
3/33-(0.020)
order_loss: 1.2715668162854854e-06
order_loss: 3.973644311372482e-07
order_loss: 5.960464477539063e-08
order_loss: 2.0861628513557662e-07
order_loss: 2.0464296994759934e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.6226089175906964e-06
order_loss: 4.589590389514342e-06
order_loss: 1.6093632439151406e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.1855038312423858e-07
order_loss: 1.0430901056679431e-05
order_loss: 4.768373287333816e-07
order_loss: 2.4080400180537254e-06
order_loss: 1.966955096577294e-06
18/33-(0.169)
order_loss: 1.1563316775209387e-06
order_loss: 1.1920930376163597e-07
order_loss: 5.662444095833052e-07
order_loss: 2.503404175513424e-06
order_loss: 3.57628505298635e-06
order_loss: 1.3858093552698847e-06
order_loss: 7.1168660724652e-06
order_loss: 8.58308283113729e-07
order_loss: 6.25852590019349e-06
order_loss: 0.0006454875110648572
order_loss: 1.847746602834377e-06
order_loss: 3.5762795391747204e-07
order_loss: 1.788139627478813e-07
order_loss: 2.7815505632133863e-07
order_loss: 2.98023280720372e-07
0/33-(0.210)
order_loss: 6.9022630668769125e-06
order_loss: 2.6822095833267667e-07
order_loss: 1.788139627478813e-07
order_loss: 1.8179446215071948e-06
order_loss: 1.1920930376163597e-07
order_loss: 8.344654247594008e-07
order_loss: 1.6391292092521326e-06
order_loss: 9.834774346018094e-07
order_loss: 7.092987289070152e-06
order_loss: 4.1723265553628153e-07
order_loss: 4.142532361584017e-06
order_loss: 6.586355084436946e-06
order_loss: 9.65604431257816e-06
order_loss: 1.1920930376163597e-07
15/33-(0.281)
order_loss: 1.3907778111388325e-06
order_loss: 2.781559260256472e-06

=== Evaluating Model ===
accuracy on Valid 0.7172619047619048

Total valid loss 1.2071073014627804
accuracy on Test 0.712166172106825
Best accuracy on Test 0.7537091988130564

**** Epoch 15/20 ****
order_loss: 5.051513198850444e-06
order_loss: 3.170978743582964e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.2782563152977673e-07
order_loss: 1.0728841743912199e-06
order_loss: 3.4272676430191495e-07
order_loss: 5.344591045286506e-06
order_loss: 0.00033579289447516203
order_loss: 2.6068108127219602e-05
order_loss: 1.1920930376163597e-07
order_loss: 2.145769485650817e-06
30/33-(0.047)
order_loss: 3.2782563152977673e-07
order_loss: 2.3841860752327193e-07
order_loss: 1.9073504518019035e-06
order_loss: 5.960464477539063e-08
order_loss: 2.1457708498928696e-06
order_loss: 1.1920930376163597e-07
order_loss: 7.947292033350095e-07
order_loss: 3.099448349530576e-06
order_loss: 4.470361545827473e-06
order_loss: 1.8358399756834842e-05
order_loss: 1.1920930376163597e-07
order_loss: 1.3113030945532955e-06
order_loss: 2.98023280720372e-07
12/33-(0.021)
order_loss: 0.00020588692859746516
order_loss: 2.3841860752327193e-07
order_loss: 7.152561920520384e-07
order_loss: 2.6822095833267667e-07
order_loss: 5.364419735087722e-07
order_loss: 3.178915619628242e-07
order_loss: 4.768372718899627e-07
order_loss: 6.258507710299455e-06
order_loss: 3.3974704365391517e-06
order_loss: 3.1888628200249514e-06
order_loss: 5.960464477539063e-08
27/33-(0.251)
order_loss: 2.582868603440147e-07
order_loss: 1.9868218714691466e-07
order_loss: 5.960464477539063e-08
order_loss: 1.0530166036915034e-06
order_loss: 9.93411845229275e-07
order_loss: 5.960464477539063e-08
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 1.1920930376163597e-07
order_loss: 0.00010780660522868857
order_loss: 1.1920930376163597e-07
9/33-(0.503)
order_loss: 3.8743027630516735e-07
order_loss: 8.344658795067517e-07
order_loss: 4.967055247107055e-07
order_loss: 1.6391300050599966e-06
order_loss: 2.1755740817752667e-06

=== Evaluating Model ===
accuracy on Valid 0.7113095238095238

Total valid loss 1.1628709333864125
accuracy on Test 0.7151335311572701
Best accuracy on Test 0.7537091988130564

**** Epoch 16/20 ****
order_loss: 1.9868218714691466e-07
order_loss: 3.874303331485862e-07
order_loss: 3.4570753086882178e-06
order_loss: 3.1292529456550255e-06
order_loss: 1.8060532966046594e-05
order_loss: 3.973644595589576e-07
order_loss: 2.920631914093974e-06
order_loss: 2.98023280720372e-07
order_loss: 1.0728841743912199e-06
24/33-(0.105)
order_loss: 5.960464477539063e-08
order_loss: 1.341104507446289e-07
order_loss: 1.3113034356138087e-06
order_loss: 1.1920930376163597e-07
order_loss: 3.129253173028701e-06
order_loss: 5.30484112459817e-06
order_loss: 1.788139485370266e-07
order_loss: 7.331412234634627e-06
order_loss: 1.788139485370266e-07
order_loss: 5.960464477539063e-08
6/33-(0.195)
order_loss: 3.576279254957626e-07
order_loss: 1.400711084897921e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.788139485370266e-07
order_loss: 1.4141580322757363e-05
order_loss: 1.1473911172288354e-06
order_loss: 2.995146360262879e-06
order_loss: 7.75813969084993e-05
order_loss: 4.4852736209577415e-06
order_loss: 2.3444558792107273e-06
21/33-(0.423)
order_loss: 4.529963462118758e-06
order_loss: 1.788139627478813e-07
order_loss: 1.0728841743912199e-06
order_loss: 2.4437961201329017e-06
order_loss: 1.439472362108063e-05
order_loss: 4.768372718899627e-07
order_loss: 8.642679745207715e-07
order_loss: 2.18550411545948e-07
order_loss: 3.576279254957626e-07
order_loss: 9.954073902918026e-06
order_loss: 1.7285374269704334e-06
order_loss: 1.0430824204377132e-06
order_loss: 3.1789284093974857e-06
3/33-(0.063)
order_loss: 1.6540318483748706e-06
order_loss: 9.536747711536009e-07
order_loss: 7.450585712831526e-07
order_loss: 9.238726192961622e-07
order_loss: 5.72204839954793e-07
order_loss: 1.1026870652131038e-06
order_loss: 2.908715714511345e-06

=== Evaluating Model ===
accuracy on Valid 0.6428571428571429

Total valid loss 1.7965017381039532
accuracy on Test 0.6320474777448071
Best accuracy on Test 0.7537091988130564

**** Epoch 17/20 ****
order_loss: 1.0927533367066644e-06
order_loss: 7.3016012720472645e-06
order_loss: 3.0795815746387234e-06
order_loss: 3.774961783165054e-07
order_loss: 5.126024916535243e-06
order_loss: 1.6272322682198137e-05
18/33-(0.789)
order_loss: 1.788139485370266e-07
order_loss: 8.940700695347914e-07
order_loss: 5.364419166653533e-07
order_loss: 7.152560215217818e-07
order_loss: 4.136647839914076e-05
order_loss: 3.45723019563593e-05
order_loss: 0.00017516424122732133
order_loss: 5.006792207495891e-07
order_loss: 1.3709077393286861e-06
order_loss: 5.165737775314483e-07
order_loss: 1.8676153104024706e-06
order_loss: 5.960466182841628e-07
order_loss: 6.854538696643431e-07
0/33-(0.070)
order_loss: 1.1920930376163597e-07
order_loss: 1.0520318028284237e-05
order_loss: 2.205374357799883e-06
order_loss: 2.5033982637978625e-06
order_loss: 3.129253173028701e-06
order_loss: 9.753918129717931e-05
order_loss: 7.2916918725240976e-06
order_loss: 7.301572395590483e-07
order_loss: 3.373781146365218e-05
order_loss: 1.887482881102187e-06
order_loss: 4.5696910433434823e-07
order_loss: 1.2666009752138052e-06
order_loss: 2.026560423473711e-06
order_loss: 1.9868217293605994e-07
order_loss: 8.046632160585432e-07
15/33-(0.246)
order_loss: 1.0073301382362843e-05
order_loss: 8.195643772523908e-07
order_loss: 6.755198569408094e-07
order_loss: 1.6888006939552724e-06
order_loss: 2.175601002818439e-05
order_loss: 3.963721610489301e-06
order_loss: 8.821602023090236e-06
order_loss: 2.7815505632133863e-07
order_loss: 1.1920930376163597e-07
order_loss: 4.8876040636969265e-06
order_loss: 8.94069742685133e-08
order_loss: 8.94069742685133e-08
order_loss: 3.576279254957626e-07
30/33-(0.116)
order_loss: 4.768372718899627e-07
order_loss: 5.364420303521911e-07
order_loss: 3.377597295184387e-07
order_loss: 5.960464477539063e-08
order_loss: 3.0597175282309763e-06
order_loss: 1.0132798706763424e-06
order_loss: 2.3841860752327193e-07
order_loss: 4.0233146592072444e-07
order_loss: 2.652413513715146e-06
order_loss: 1.788139485370266e-07
order_loss: 1.5497230378969107e-06
order_loss: 1.3709080803891993e-06

=== Evaluating Model ===
accuracy on Valid 0.6815476190476191

Total valid loss 1.4531194743784992
accuracy on Test 0.6884272997032641
Best accuracy on Test 0.7537091988130564

**** Epoch 18/20 ****
order_loss: 2.38870779867284e-05
order_loss: 3.576279254957626e-07
order_loss: 9.238727898264187e-07
12/33-(0.096)
order_loss: 2.0861648408754263e-06
order_loss: 7.181878027040511e-05
order_loss: 5.960464477539063e-08
order_loss: 4.1723265553628153e-07
order_loss: 1.7881409348774469e-06
order_loss: 3.774961783165054e-07
order_loss: 3.5762798233918147e-07
order_loss: 4.768372718899627e-07
order_loss: 2.3841863594498136e-07
order_loss: 1.7881411622511223e-06
order_loss: 4.768374424202193e-07
order_loss: 5.960466182841628e-07
order_loss: 8.543337912669813e-07
order_loss: 1.5358480595750734e-05
27/33-(0.807)
order_loss: 3.3577393878658768e-06
order_loss: 5.833918294229079e-06
order_loss: 2.3841860752327193e-07
order_loss: 1.2904570212413091e-05
order_loss: 8.94069742685133e-08
order_loss: 2.3841860752327193e-07
order_loss: 1.5199202607618645e-06
order_loss: 1.788139627478813e-07
order_loss: 1.3709093309444143e-06
order_loss: 2.503407813492231e-06
order_loss: 5.722070454794448e-06
order_loss: 8.94069742685133e-08
order_loss: 1.5497219010285335e-06
9/33-(0.097)
order_loss: 4.553835424303543e-06
order_loss: 7.897621685515333e-07
order_loss: 3.337865791763761e-06
order_loss: 4.768382950715022e-06
order_loss: 1.1920930376163597e-07
order_loss: 2.523268221921171e-06
order_loss: 6.258491112021147e-07
order_loss: 1.788139627478813e-07
order_loss: 5.960466182841628e-07
order_loss: 5.960464477539063e-08
order_loss: 4.6491832108586095e-06
order_loss: 6.5565143358981e-07
order_loss: 2.6822095833267667e-07
order_loss: 5.960467888144194e-07
order_loss: 1.5894573834884795e-07
24/33-(0.213)
order_loss: 3.874303331485862e-07
order_loss: 2.354387788727763e-06
order_loss: 5.960464477539063e-08
order_loss: 1.5497222420890466e-06
order_loss: 1.4901162614933128e-07
order_loss: 5.960464477539063e-08
order_loss: 1.788139627478813e-07
order_loss: 5.960464477539063e-08
order_loss: 1.1920930376163597e-07
order_loss: 1.9669553239509696e-06
order_loss: 1.788139485370266e-07
order_loss: 2.0861628513557662e-07
6/33-(0.202)

=== Evaluating Model ===
accuracy on Valid 0.6964285714285714

Total valid loss 1.778553836386312
accuracy on Test 0.7210682492581603
Best accuracy on Test 0.7537091988130564

**** Epoch 19/20 ****
order_loss: 4.768372718899627e-07
order_loss: 1.6391411918448284e-05
order_loss: 2.3841860752327193e-07
order_loss: 2.5033958195308514e-07
order_loss: 1.454354787711054e-06
order_loss: 4.768372718899627e-07
order_loss: 1.4618410205002874e-05
order_loss: 1.1324892739139614e-06
order_loss: 7.808295777067542e-06
order_loss: 2.6822095833267667e-07
order_loss: 8.981229620985687e-05
order_loss: 1.1920930376163597e-07
order_loss: 4.172326271145721e-07
order_loss: 1.4066890798858367e-05
21/33-(0.126)
order_loss: 2.384189883741783e-06
order_loss: 1.6689314179529902e-06
order_loss: 1.1424354852351826e-05
Best accuracy on Test 0.7537091988130564

Final k-fold valid 0.7201250529885546
[0.7023809523809523, 0.7537091988130564, 0.7240356083086054, 0.712166172106825, 0.7083333333333334]
Final k-fold eval 0.7302317366115585
[0.7261904761904762, 0.7142857142857143, 0.7359050445103857, 0.7210682492581603, 0.7537091988130564]
